{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c2e503b-cf1c-45e8-8a70-3a64d1c440d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna \n",
    "import torch\n",
    "import os\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from DataEncoder import encode_pad_event, encode_pad_sequence, scale_time_differences, label_encode_y\n",
    "from OneLevelGCN import prepare_data, CustomDataset, train, evaluate, EarlyStopping, GCNModel, objective, load_model\n",
    "from utils import plot_training_history, print_best_hp_gcn, best_trial_path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9ca11d3-4dd7-4cbe-a91d-7ac790aa854b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#event = pd.read_csv(\"D:/Research in UAE/sequence/output/BPI12af_Combin_Feature.csv\")\n",
    "#sequence = event[['case:concept:name','case:AMOUNT_REQ','result']].groupby(['case:concept:name']).first()\n",
    "#sequence = sequence.reset_index()\n",
    "event = pd.read_csv(\"D:/Research in UAE/sequence/output/Event_Feature_pro.csv\")\n",
    "sequence = pd.read_csv(\"D:/Research in UAE/sequence/output/Sequence_Feature_pro.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8926759a-23f2-429b-87e1-5de2f112c48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_col = sequence.result\n",
    "y_encode = label_encode_y(y_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74cf2a41-dcda-4228-99de-fa9c7dcfea59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat_col_event = ['activity_verb', 'activity_dec', 'StartRes', 'CompleteRes']\n",
    "#num_col_event = ['Duration']\n",
    "#case_index = 'case:concept:name'\n",
    "\n",
    "cat_col_event = ['Activity_verb', 'Activity_Dec', 'Resource', 'outcome', \"stopcode\"]\n",
    "num_col_event = ['net_promotor_score', 'creditscore', 'rate_charged', 'duration']\n",
    "case_index = 'Case ID'\n",
    "\n",
    "event_encode = encode_pad_event(event, cat_col_event, num_col_event, case_index, cat_mask = True, num_mask = True, eos = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "645d6220-b167-4f29-a0e6-f3d6b5bc4140",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat_col_seq = []\n",
    "#num_col_seq = ['case:AMOUNT_REQ']\n",
    "cat_col_seq = ['plan']\n",
    "num_col_seq = ['age', 'coverage_numeric', 'length_of_stay']\n",
    "sequence_encode = encode_pad_sequence(sequence, cat_col_seq, num_col_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2164d309-ff41-435d-9466-b1fdc3c36bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#start_time_col = 'StartTime'\n",
    "start_time_col = 'Start Timestamp'\n",
    "scaled_time_diffs = scale_time_differences(event, sequence, start_time_col, case_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24951e07-7064-4410-80d8-2d7bba01b7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sequences = event_encode.shape[0]\n",
    "max_num_events = event_encode.shape[1]\n",
    "num_event_features = event_encode.shape[2]\n",
    "num_sequence_features = sequence_encode.shape[1]\n",
    "\n",
    "# Expand sequence features to match the shape of event features\n",
    "sequence_features_expanded = np.expand_dims(sequence_encode, axis=1)\n",
    "sequence_features_expanded = np.repeat(sequence_features_expanded, max_num_events, axis=1)\n",
    "\n",
    "# Combine event and sequence features\n",
    "combined_features = np.concatenate((event_encode, sequence_features_expanded), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c76843ed-5ae1-4c3c-9066-d657a66bb331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preparation is done as described above\n",
    "event_feature_list = prepare_data(combined_features, scaled_time_diffs, torch.float)\n",
    "y_encode = torch.tensor(y_encode, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34d6369b-2bb3-4486-baa3-d9766b7ab81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split indices for train and test\n",
    "train_indices, test_indices = train_test_split(range(len(event_feature_list)), test_size=0.2, stratify=y_encode.numpy(), random_state=42)\n",
    "\n",
    "# Split the data\n",
    "train_event_features = [event_feature_list[i] for i in train_indices]\n",
    "test_event_features = [event_feature_list[i] for i in test_indices]\n",
    "\n",
    "train_y = y_encode[train_indices]\n",
    "test_y = y_encode[test_indices]\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = CustomDataset(train_event_features, train_y)\n",
    "test_dataset = CustomDataset(test_event_features, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89654cc3-714a-480d-8032-e5cb99b6b74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "num_comb_features = combined_features.shape[2]  # Number of features per node\n",
    "output_dim = len(np.unique(y_encode))\n",
    "epochs = 200 # Increase epochs to allow for early stopping\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Create an Optuna study and optimize the objective function\n",
    "patience = 30\n",
    "model_save_folder = '../output/model_hp/1levelGCN/'\n",
    "#model_save_folder = '../output/model_hp/1levelGCN_bpi12o/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3345115b-e024-48f2-8d2b-58f89ee55222",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 12:57:08,480] A new study created in memory with name: no-name-f89b130c-1520-4f6d-b5c1-dc9ee462e407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.6752, Accuracy: 0.6408, Test Loss: 0.7186, Test Accuracy: 0.7196\n",
      "Epoch 2, Loss: 2.1017, Accuracy: 0.7079, Test Loss: 0.8206, Test Accuracy: 0.7500\n",
      "Epoch 3, Loss: 1.8428, Accuracy: 0.7015, Test Loss: 1.3622, Test Accuracy: 0.4579\n",
      "Epoch 4, Loss: 1.5734, Accuracy: 0.6916, Test Loss: 0.7947, Test Accuracy: 0.5093\n",
      "Epoch 5, Loss: 1.2963, Accuracy: 0.7488, Test Loss: 0.7756, Test Accuracy: 0.7734\n",
      "Epoch 6, Loss: 1.3542, Accuracy: 0.7062, Test Loss: 0.7915, Test Accuracy: 0.7150\n",
      "Epoch 7, Loss: 1.2353, Accuracy: 0.7360, Test Loss: 0.5673, Test Accuracy: 0.8061\n",
      "Epoch 8, Loss: 1.1524, Accuracy: 0.7617, Test Loss: 0.5852, Test Accuracy: 0.7921\n",
      "Epoch 9, Loss: 1.1268, Accuracy: 0.7453, Test Loss: 0.6722, Test Accuracy: 0.8084\n",
      "Epoch 10, Loss: 1.0406, Accuracy: 0.7745, Test Loss: 0.7324, Test Accuracy: 0.7079\n",
      "Epoch 11, Loss: 1.0723, Accuracy: 0.7623, Test Loss: 0.7515, Test Accuracy: 0.5958\n",
      "Epoch 12, Loss: 1.0191, Accuracy: 0.7629, Test Loss: 0.5691, Test Accuracy: 0.8061\n",
      "Epoch 13, Loss: 1.0022, Accuracy: 0.7482, Test Loss: 0.6153, Test Accuracy: 0.7710\n",
      "Epoch 14, Loss: 1.0434, Accuracy: 0.7447, Test Loss: 0.6900, Test Accuracy: 0.8061\n",
      "Epoch 15, Loss: 0.9880, Accuracy: 0.7634, Test Loss: 0.6117, Test Accuracy: 0.7360\n",
      "Epoch 16, Loss: 0.9636, Accuracy: 0.7477, Test Loss: 0.6368, Test Accuracy: 0.8014\n",
      "Epoch 17, Loss: 1.0256, Accuracy: 0.7687, Test Loss: 0.6334, Test Accuracy: 0.7290\n",
      "Epoch 18, Loss: 0.9410, Accuracy: 0.7658, Test Loss: 0.5792, Test Accuracy: 0.7921\n",
      "Epoch 19, Loss: 0.9739, Accuracy: 0.7588, Test Loss: 0.6080, Test Accuracy: 0.8084\n",
      "Epoch 20, Loss: 1.0181, Accuracy: 0.7453, Test Loss: 0.6632, Test Accuracy: 0.6916\n",
      "Epoch 21, Loss: 1.0864, Accuracy: 0.7634, Test Loss: 0.5833, Test Accuracy: 0.7897\n",
      "Epoch 22, Loss: 1.0705, Accuracy: 0.7576, Test Loss: 0.5692, Test Accuracy: 0.7407\n",
      "Epoch 23, Loss: 1.0236, Accuracy: 0.7471, Test Loss: 0.5970, Test Accuracy: 0.8084\n",
      "Epoch 24, Loss: 1.0163, Accuracy: 0.7687, Test Loss: 0.6084, Test Accuracy: 0.7944\n",
      "Epoch 25, Loss: 1.0239, Accuracy: 0.7366, Test Loss: 0.5190, Test Accuracy: 0.8084\n",
      "Epoch 26, Loss: 1.0777, Accuracy: 0.7307, Test Loss: 0.5940, Test Accuracy: 0.8061\n",
      "Epoch 27, Loss: 0.9854, Accuracy: 0.7699, Test Loss: 0.5660, Test Accuracy: 0.8014\n",
      "Epoch 28, Loss: 0.9970, Accuracy: 0.7617, Test Loss: 0.6166, Test Accuracy: 0.7850\n",
      "Epoch 29, Loss: 1.0326, Accuracy: 0.7593, Test Loss: 0.6676, Test Accuracy: 0.7453\n",
      "Epoch 30, Loss: 0.9923, Accuracy: 0.7541, Test Loss: 0.6065, Test Accuracy: 0.8037\n",
      "Epoch 31, Loss: 0.9927, Accuracy: 0.7336, Test Loss: 0.6258, Test Accuracy: 0.7757\n",
      "Epoch 32, Loss: 0.9700, Accuracy: 0.7745, Test Loss: 0.5929, Test Accuracy: 0.7921\n",
      "Epoch 33, Loss: 0.9887, Accuracy: 0.7371, Test Loss: 0.6723, Test Accuracy: 0.7780\n",
      "Epoch 34, Loss: 0.9619, Accuracy: 0.7704, Test Loss: 0.7151, Test Accuracy: 0.7360\n",
      "Epoch 35, Loss: 0.9683, Accuracy: 0.7745, Test Loss: 0.5240, Test Accuracy: 0.8061\n",
      "Epoch 36, Loss: 0.9471, Accuracy: 0.7646, Test Loss: 0.5701, Test Accuracy: 0.7687\n",
      "Epoch 37, Loss: 1.0127, Accuracy: 0.7547, Test Loss: 0.5376, Test Accuracy: 0.8061\n",
      "Epoch 38, Loss: 1.0441, Accuracy: 0.7208, Test Loss: 0.5508, Test Accuracy: 0.8107\n",
      "Epoch 39, Loss: 1.0171, Accuracy: 0.7710, Test Loss: 0.5459, Test Accuracy: 0.8061\n",
      "Epoch 40, Loss: 1.1045, Accuracy: 0.7284, Test Loss: 0.5408, Test Accuracy: 0.7757\n",
      "Epoch 41, Loss: 1.0842, Accuracy: 0.7442, Test Loss: 0.5354, Test Accuracy: 0.8014\n",
      "Epoch 42, Loss: 1.0456, Accuracy: 0.7576, Test Loss: 0.7219, Test Accuracy: 0.7687\n",
      "Epoch 43, Loss: 0.9884, Accuracy: 0.7576, Test Loss: 0.5533, Test Accuracy: 0.8061\n",
      "Epoch 44, Loss: 0.9524, Accuracy: 0.7704, Test Loss: 0.6297, Test Accuracy: 0.7897\n",
      "Epoch 45, Loss: 1.0514, Accuracy: 0.7377, Test Loss: 0.6251, Test Accuracy: 0.7056\n",
      "Epoch 46, Loss: 1.0147, Accuracy: 0.7447, Test Loss: 0.7037, Test Accuracy: 0.4930\n",
      "Epoch 47, Loss: 0.9120, Accuracy: 0.7658, Test Loss: 0.5442, Test Accuracy: 0.7944\n",
      "Epoch 48, Loss: 0.9633, Accuracy: 0.7518, Test Loss: 0.5901, Test Accuracy: 0.7687\n",
      "Epoch 49, Loss: 1.0258, Accuracy: 0.7553, Test Loss: 0.6681, Test Accuracy: 0.7196\n",
      "Epoch 50, Loss: 1.1192, Accuracy: 0.7617, Test Loss: 0.5299, Test Accuracy: 0.7967\n",
      "Epoch 51, Loss: 1.0068, Accuracy: 0.7664, Test Loss: 0.6691, Test Accuracy: 0.7850\n",
      "Epoch 52, Loss: 0.9802, Accuracy: 0.7576, Test Loss: 0.6380, Test Accuracy: 0.7921\n",
      "Epoch 53, Loss: 0.9798, Accuracy: 0.7512, Test Loss: 0.5515, Test Accuracy: 0.8037\n",
      "Epoch 54, Loss: 0.9590, Accuracy: 0.7728, Test Loss: 0.7955, Test Accuracy: 0.7126\n",
      "Epoch 55, Loss: 1.0039, Accuracy: 0.7582, Test Loss: 0.6432, Test Accuracy: 0.7430\n",
      "Epoch 56, Loss: 1.0484, Accuracy: 0.7471, Test Loss: 0.5735, Test Accuracy: 0.7967\n",
      "Epoch 57, Loss: 1.0617, Accuracy: 0.7541, Test Loss: 0.5830, Test Accuracy: 0.7664\n",
      "Epoch 58, Loss: 1.0053, Accuracy: 0.7652, Test Loss: 0.5716, Test Accuracy: 0.8061\n",
      "Epoch 59, Loss: 0.9954, Accuracy: 0.7675, Test Loss: 0.5467, Test Accuracy: 0.8061\n",
      "Epoch 60, Loss: 0.9628, Accuracy: 0.7605, Test Loss: 0.5332, Test Accuracy: 0.8084\n",
      "Epoch 61, Loss: 1.2460, Accuracy: 0.7033, Test Loss: 0.6940, Test Accuracy: 0.7687\n",
      "Epoch 62, Loss: 1.1464, Accuracy: 0.7757, Test Loss: 0.5494, Test Accuracy: 0.8061\n",
      "Epoch 63, Loss: 1.1200, Accuracy: 0.7518, Test Loss: 0.6384, Test Accuracy: 0.8061\n",
      "Epoch 64, Loss: 1.0907, Accuracy: 0.7664, Test Loss: 0.5787, Test Accuracy: 0.7360\n",
      "Epoch 65, Loss: 1.0103, Accuracy: 0.7582, Test Loss: 0.6049, Test Accuracy: 0.8014\n",
      "Epoch 66, Loss: 0.9811, Accuracy: 0.7518, Test Loss: 0.6050, Test Accuracy: 0.7944\n",
      "Epoch 67, Loss: 1.0187, Accuracy: 0.7418, Test Loss: 0.5213, Test Accuracy: 0.8037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 12:58:39,528] Trial 0 finished with value: 0.8107476635514018 and parameters: {'batch_size': 64, 'num_gcn_layers': 2, 'gcn_hidden_dim_0': 66, 'gcn_hidden_dim_1': 212, 'num_fc_layers': 2, 'fc_hidden_dim_0': 143, 'fc_hidden_dim_1': 251, 'learning_rate': 8.433196984279278e-05, 'weight_decay': 0.0007112754364303059, 'pooling_method': 'max', 'gcn_batch_norm_flag_0': True, 'gcn_batch_norm_flag_1': True, 'gcn_momentum_0': 0.7038701838517988, 'gcn_momentum_1': 0.310587831843982, 'gcn_eps_0': 0.0033770772465246445, 'gcn_eps_1': 0.007209262927665726, 'gcn_dropout_flag_0': True, 'gcn_dropout_flag_1': False, 'gcn_dropout_rate_0': 0.2560831727327573, 'gcn_activation_0': 'softplus', 'gcn_activation_1': 'leaky_relu', 'fc_batch_norm_flag_0': False, 'fc_batch_norm_flag_1': True, 'fc_momentum_1': 0.5883307572916927, 'fc_eps_1': 0.00485273324038575, 'fc_dropout_flag_0': False, 'fc_dropout_flag_1': False, 'fc_activation_0': 'tanh', 'fc_activation_1': 'softplus', 'gcn_skip_connections_0': True, 'gcn_skip_connections_1': True, 'l1_lambda': 0.00028218026256517196, 'optimizer': 'RMSprop', 'alpha': 0.8549946178011593, 'momentum_rms': 0.9780723124066592, 'eps_rms': 1.66581697406341e-08, 'lr_scheduler': 'OneCycleLR', 'max_lr_1': 0.0454410973488044, 'pct_start': 0.3879973765586405, 'loss_function': 'CrossEntropy'}. Best is trial 0 with value: 0.8107476635514018.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68, Loss: 0.8996, Accuracy: 0.7821, Test Loss: 0.5544, Test Accuracy: 0.8084\n",
      "Early stopping triggered\n",
      "Epoch 1, Loss: 6.3669, Accuracy: 0.1449, Test Loss: 1.7213, Test Accuracy: 0.2430\n",
      "Epoch 2, Loss: 6.3719, Accuracy: 0.1396, Test Loss: 1.7241, Test Accuracy: 0.2430\n",
      "Epoch 3, Loss: 6.3659, Accuracy: 0.1583, Test Loss: 1.7265, Test Accuracy: 0.2430\n",
      "Epoch 4, Loss: 6.3695, Accuracy: 0.1454, Test Loss: 1.7199, Test Accuracy: 0.2430\n",
      "Epoch 5, Loss: 6.3711, Accuracy: 0.1349, Test Loss: 1.7130, Test Accuracy: 0.2430\n",
      "Epoch 6, Loss: 6.3664, Accuracy: 0.1384, Test Loss: 1.7269, Test Accuracy: 0.2430\n",
      "Epoch 7, Loss: 6.3649, Accuracy: 0.1606, Test Loss: 1.7189, Test Accuracy: 0.2430\n",
      "Epoch 8, Loss: 6.3689, Accuracy: 0.1560, Test Loss: 1.7204, Test Accuracy: 0.2430\n",
      "Epoch 9, Loss: 6.3662, Accuracy: 0.1577, Test Loss: 1.7160, Test Accuracy: 0.2430\n",
      "Epoch 10, Loss: 6.3678, Accuracy: 0.1338, Test Loss: 1.7192, Test Accuracy: 0.2430\n",
      "Epoch 11, Loss: 6.3658, Accuracy: 0.1600, Test Loss: 1.7247, Test Accuracy: 0.2500\n",
      "Epoch 12, Loss: 6.3659, Accuracy: 0.1577, Test Loss: 1.7281, Test Accuracy: 0.2430\n",
      "Epoch 13, Loss: 6.3659, Accuracy: 0.1373, Test Loss: 1.7254, Test Accuracy: 0.2430\n",
      "Epoch 14, Loss: 6.3632, Accuracy: 0.1583, Test Loss: 1.7221, Test Accuracy: 0.2430\n",
      "Epoch 15, Loss: 6.3721, Accuracy: 0.1268, Test Loss: 1.7240, Test Accuracy: 0.2430\n",
      "Epoch 16, Loss: 6.3650, Accuracy: 0.1484, Test Loss: 1.7227, Test Accuracy: 0.2430\n",
      "Epoch 17, Loss: 6.3679, Accuracy: 0.1478, Test Loss: 1.7146, Test Accuracy: 0.2430\n",
      "Epoch 18, Loss: 6.3668, Accuracy: 0.1525, Test Loss: 1.7213, Test Accuracy: 0.2453\n",
      "Epoch 19, Loss: 6.3681, Accuracy: 0.1513, Test Loss: 1.7221, Test Accuracy: 0.2430\n",
      "Epoch 20, Loss: 6.3679, Accuracy: 0.1449, Test Loss: 1.7198, Test Accuracy: 0.2430\n",
      "Epoch 21, Loss: 6.3693, Accuracy: 0.1349, Test Loss: 1.7211, Test Accuracy: 0.2430\n",
      "Epoch 22, Loss: 6.3645, Accuracy: 0.1513, Test Loss: 1.7216, Test Accuracy: 0.2430\n",
      "Epoch 23, Loss: 6.3650, Accuracy: 0.1314, Test Loss: 1.7195, Test Accuracy: 0.2430\n",
      "Epoch 24, Loss: 6.3701, Accuracy: 0.1303, Test Loss: 1.7194, Test Accuracy: 0.2430\n",
      "Epoch 25, Loss: 6.3651, Accuracy: 0.1571, Test Loss: 1.7227, Test Accuracy: 0.2430\n",
      "Epoch 26, Loss: 6.3659, Accuracy: 0.1548, Test Loss: 1.7216, Test Accuracy: 0.2430\n",
      "Epoch 27, Loss: 6.3654, Accuracy: 0.1431, Test Loss: 1.7184, Test Accuracy: 0.2430\n",
      "Epoch 28, Loss: 6.3682, Accuracy: 0.1402, Test Loss: 1.7276, Test Accuracy: 0.2430\n",
      "Epoch 29, Loss: 6.3668, Accuracy: 0.1536, Test Loss: 1.7187, Test Accuracy: 0.2430\n",
      "Epoch 30, Loss: 6.3699, Accuracy: 0.1361, Test Loss: 1.7263, Test Accuracy: 0.2430\n",
      "Epoch 31, Loss: 6.3712, Accuracy: 0.1390, Test Loss: 1.7228, Test Accuracy: 0.2430\n",
      "Epoch 32, Loss: 6.3705, Accuracy: 0.1419, Test Loss: 1.7190, Test Accuracy: 0.2430\n",
      "Epoch 33, Loss: 6.3686, Accuracy: 0.1314, Test Loss: 1.7208, Test Accuracy: 0.2430\n",
      "Epoch 34, Loss: 6.3670, Accuracy: 0.1472, Test Loss: 1.7258, Test Accuracy: 0.2430\n",
      "Epoch 35, Loss: 6.3617, Accuracy: 0.1659, Test Loss: 1.7194, Test Accuracy: 0.2430\n",
      "Epoch 36, Loss: 6.3683, Accuracy: 0.1472, Test Loss: 1.7245, Test Accuracy: 0.2430\n",
      "Epoch 37, Loss: 6.3700, Accuracy: 0.1390, Test Loss: 1.7232, Test Accuracy: 0.2430\n",
      "Epoch 38, Loss: 6.3667, Accuracy: 0.1437, Test Loss: 1.7179, Test Accuracy: 0.2430\n",
      "Epoch 39, Loss: 6.3674, Accuracy: 0.1425, Test Loss: 1.7244, Test Accuracy: 0.2430\n",
      "Epoch 40, Loss: 6.3641, Accuracy: 0.1542, Test Loss: 1.7201, Test Accuracy: 0.2430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 12:59:15,315] Trial 1 finished with value: 0.25 and parameters: {'batch_size': 128, 'num_gcn_layers': 4, 'gcn_hidden_dim_0': 135, 'gcn_hidden_dim_1': 150, 'gcn_hidden_dim_2': 33, 'gcn_hidden_dim_3': 143, 'num_fc_layers': 2, 'fc_hidden_dim_0': 119, 'fc_hidden_dim_1': 213, 'learning_rate': 2.5355627357780624e-05, 'weight_decay': 0.0008697059719576678, 'pooling_method': 'mean', 'gcn_batch_norm_flag_0': False, 'gcn_batch_norm_flag_1': False, 'gcn_batch_norm_flag_2': False, 'gcn_batch_norm_flag_3': True, 'gcn_momentum_3': 0.8971247313890054, 'gcn_eps_3': 0.002279643476007351, 'gcn_dropout_flag_0': True, 'gcn_dropout_flag_1': True, 'gcn_dropout_flag_2': True, 'gcn_dropout_flag_3': True, 'gcn_dropout_rate_0': 0.3728816547550239, 'gcn_dropout_rate_1': 0.2327596105484723, 'gcn_dropout_rate_2': 0.36315561538330243, 'gcn_dropout_rate_3': 0.10563730545907402, 'gcn_activation_0': 'gelu', 'gcn_activation_1': 'relu', 'gcn_activation_2': 'gelu', 'gcn_activation_3': 'relu', 'fc_batch_norm_flag_0': True, 'fc_batch_norm_flag_1': False, 'fc_momentum_0': 0.4892149352162702, 'fc_eps_0': 0.009289918470966172, 'fc_dropout_flag_0': False, 'fc_dropout_flag_1': True, 'fc_dropout_rate_1': 0.19490094219427379, 'fc_activation_0': 'tanh', 'fc_activation_1': 'gelu', 'gcn_skip_connections_0': True, 'gcn_skip_connections_1': False, 'gcn_skip_connections_2': False, 'gcn_skip_connections_3': False, 'l1_lambda': 0.0008407261982868231, 'optimizer': 'SGD', 'momentum': 0.5877750244353166, 'lr_scheduler': 'ExponentialLR', 'exLRgamma': 0.8582200417930036, 'loss_function': 'CrossEntropy'}. Best is trial 0 with value: 0.8107476635514018.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41, Loss: 6.3664, Accuracy: 0.1466, Test Loss: 1.7205, Test Accuracy: 0.2430\n",
      "Early stopping triggered\n",
      "Epoch 1, Loss: 2.9619, Accuracy: 0.5666, Test Loss: 0.7940, Test Accuracy: 0.7383\n",
      "Epoch 2, Loss: 2.0830, Accuracy: 0.7296, Test Loss: 0.6564, Test Accuracy: 0.7500\n",
      "Epoch 3, Loss: 1.8307, Accuracy: 0.7430, Test Loss: 0.6313, Test Accuracy: 0.7500\n",
      "Epoch 4, Loss: 1.6347, Accuracy: 0.7482, Test Loss: 0.6361, Test Accuracy: 0.7477\n",
      "Epoch 5, Loss: 1.4871, Accuracy: 0.7488, Test Loss: 0.6539, Test Accuracy: 0.7360\n",
      "Epoch 6, Loss: 1.3943, Accuracy: 0.7669, Test Loss: 0.6011, Test Accuracy: 0.7710\n",
      "Epoch 7, Loss: 1.3060, Accuracy: 0.7687, Test Loss: 0.5800, Test Accuracy: 0.7874\n",
      "Epoch 8, Loss: 1.2242, Accuracy: 0.7839, Test Loss: 0.5572, Test Accuracy: 0.7780\n",
      "Epoch 9, Loss: 1.1559, Accuracy: 0.7874, Test Loss: 0.5755, Test Accuracy: 0.8014\n",
      "Epoch 10, Loss: 1.1031, Accuracy: 0.7862, Test Loss: 0.5368, Test Accuracy: 0.7944\n",
      "Epoch 11, Loss: 1.0612, Accuracy: 0.7886, Test Loss: 0.5231, Test Accuracy: 0.7921\n",
      "Epoch 12, Loss: 1.0471, Accuracy: 0.7921, Test Loss: 0.5195, Test Accuracy: 0.7944\n",
      "Epoch 13, Loss: 0.9912, Accuracy: 0.8008, Test Loss: 0.4975, Test Accuracy: 0.7967\n",
      "Epoch 14, Loss: 0.9655, Accuracy: 0.7996, Test Loss: 0.5729, Test Accuracy: 0.7921\n",
      "Epoch 15, Loss: 0.9567, Accuracy: 0.7961, Test Loss: 0.4850, Test Accuracy: 0.8061\n",
      "Epoch 16, Loss: 0.9339, Accuracy: 0.8008, Test Loss: 0.5243, Test Accuracy: 0.8154\n",
      "Epoch 17, Loss: 0.8846, Accuracy: 0.8148, Test Loss: 0.5009, Test Accuracy: 0.8084\n",
      "Epoch 18, Loss: 0.8867, Accuracy: 0.8008, Test Loss: 0.4644, Test Accuracy: 0.8131\n",
      "Epoch 19, Loss: 0.8607, Accuracy: 0.8084, Test Loss: 0.4944, Test Accuracy: 0.8131\n",
      "Epoch 20, Loss: 0.8478, Accuracy: 0.8026, Test Loss: 0.4927, Test Accuracy: 0.8154\n",
      "Epoch 21, Loss: 0.8207, Accuracy: 0.8107, Test Loss: 0.4839, Test Accuracy: 0.8037\n",
      "Epoch 22, Loss: 0.7901, Accuracy: 0.8224, Test Loss: 0.4548, Test Accuracy: 0.8154\n",
      "Epoch 23, Loss: 0.7715, Accuracy: 0.8131, Test Loss: 0.4827, Test Accuracy: 0.8178\n",
      "Epoch 24, Loss: 0.7653, Accuracy: 0.8213, Test Loss: 0.4767, Test Accuracy: 0.8107\n",
      "Epoch 25, Loss: 0.7447, Accuracy: 0.8224, Test Loss: 0.4525, Test Accuracy: 0.8131\n",
      "Epoch 26, Loss: 0.7365, Accuracy: 0.8195, Test Loss: 0.4373, Test Accuracy: 0.8248\n",
      "Epoch 27, Loss: 0.7331, Accuracy: 0.8148, Test Loss: 0.4469, Test Accuracy: 0.8224\n",
      "Epoch 28, Loss: 0.7126, Accuracy: 0.8207, Test Loss: 0.4405, Test Accuracy: 0.8201\n",
      "Epoch 29, Loss: 0.7001, Accuracy: 0.8189, Test Loss: 0.4338, Test Accuracy: 0.8341\n",
      "Epoch 30, Loss: 0.6855, Accuracy: 0.8289, Test Loss: 0.4187, Test Accuracy: 0.8271\n",
      "Epoch 31, Loss: 0.6842, Accuracy: 0.8224, Test Loss: 0.4130, Test Accuracy: 0.8318\n",
      "Epoch 32, Loss: 0.6734, Accuracy: 0.8294, Test Loss: 0.4525, Test Accuracy: 0.8224\n",
      "Epoch 33, Loss: 0.6764, Accuracy: 0.8242, Test Loss: 0.4130, Test Accuracy: 0.8364\n",
      "Epoch 34, Loss: 0.6527, Accuracy: 0.8283, Test Loss: 0.4612, Test Accuracy: 0.8201\n",
      "Epoch 35, Loss: 0.6518, Accuracy: 0.8277, Test Loss: 0.4370, Test Accuracy: 0.8201\n",
      "Epoch 36, Loss: 0.6392, Accuracy: 0.8306, Test Loss: 0.4264, Test Accuracy: 0.8201\n",
      "Epoch 37, Loss: 0.6433, Accuracy: 0.8283, Test Loss: 0.3983, Test Accuracy: 0.8341\n",
      "Epoch 38, Loss: 0.6305, Accuracy: 0.8324, Test Loss: 0.4391, Test Accuracy: 0.8248\n",
      "Epoch 39, Loss: 0.6243, Accuracy: 0.8306, Test Loss: 0.4243, Test Accuracy: 0.8458\n",
      "Epoch 40, Loss: 0.6153, Accuracy: 0.8370, Test Loss: 0.3983, Test Accuracy: 0.8481\n",
      "Epoch 41, Loss: 0.6444, Accuracy: 0.8224, Test Loss: 0.4205, Test Accuracy: 0.8435\n",
      "Epoch 42, Loss: 0.6065, Accuracy: 0.8347, Test Loss: 0.4176, Test Accuracy: 0.8271\n",
      "Epoch 43, Loss: 0.6091, Accuracy: 0.8324, Test Loss: 0.4024, Test Accuracy: 0.8388\n",
      "Epoch 44, Loss: 0.6025, Accuracy: 0.8283, Test Loss: 0.3865, Test Accuracy: 0.8435\n",
      "Epoch 45, Loss: 0.5882, Accuracy: 0.8376, Test Loss: 0.3925, Test Accuracy: 0.8364\n",
      "Epoch 46, Loss: 0.5894, Accuracy: 0.8370, Test Loss: 0.3941, Test Accuracy: 0.8341\n",
      "Epoch 47, Loss: 0.5884, Accuracy: 0.8382, Test Loss: 0.3948, Test Accuracy: 0.8435\n",
      "Epoch 48, Loss: 0.5723, Accuracy: 0.8446, Test Loss: 0.3975, Test Accuracy: 0.8364\n",
      "Epoch 49, Loss: 0.5696, Accuracy: 0.8417, Test Loss: 0.3944, Test Accuracy: 0.8388\n",
      "Epoch 50, Loss: 0.5628, Accuracy: 0.8411, Test Loss: 0.3847, Test Accuracy: 0.8505\n",
      "Epoch 51, Loss: 0.5822, Accuracy: 0.8341, Test Loss: 0.4014, Test Accuracy: 0.8481\n",
      "Epoch 52, Loss: 0.5675, Accuracy: 0.8364, Test Loss: 0.4027, Test Accuracy: 0.8318\n",
      "Epoch 53, Loss: 0.5599, Accuracy: 0.8400, Test Loss: 0.4066, Test Accuracy: 0.8294\n",
      "Epoch 54, Loss: 0.5530, Accuracy: 0.8487, Test Loss: 0.4299, Test Accuracy: 0.8318\n",
      "Epoch 55, Loss: 0.5715, Accuracy: 0.8300, Test Loss: 0.4137, Test Accuracy: 0.8318\n",
      "Epoch 56, Loss: 0.5534, Accuracy: 0.8435, Test Loss: 0.4042, Test Accuracy: 0.8294\n",
      "Epoch 57, Loss: 0.5487, Accuracy: 0.8417, Test Loss: 0.3872, Test Accuracy: 0.8481\n",
      "Epoch 58, Loss: 0.5433, Accuracy: 0.8429, Test Loss: 0.3822, Test Accuracy: 0.8411\n",
      "Epoch 59, Loss: 0.5429, Accuracy: 0.8440, Test Loss: 0.4042, Test Accuracy: 0.8364\n",
      "Epoch 60, Loss: 0.5681, Accuracy: 0.8318, Test Loss: 0.3868, Test Accuracy: 0.8551\n",
      "Epoch 61, Loss: 0.5565, Accuracy: 0.8364, Test Loss: 0.3807, Test Accuracy: 0.8505\n",
      "Epoch 62, Loss: 0.5451, Accuracy: 0.8388, Test Loss: 0.4147, Test Accuracy: 0.8271\n",
      "Epoch 63, Loss: 0.5499, Accuracy: 0.8411, Test Loss: 0.3871, Test Accuracy: 0.8435\n",
      "Epoch 64, Loss: 0.5377, Accuracy: 0.8446, Test Loss: 0.3961, Test Accuracy: 0.8388\n",
      "Epoch 65, Loss: 0.5304, Accuracy: 0.8458, Test Loss: 0.4011, Test Accuracy: 0.8435\n",
      "Epoch 66, Loss: 0.5432, Accuracy: 0.8353, Test Loss: 0.3843, Test Accuracy: 0.8458\n",
      "Epoch 67, Loss: 0.5330, Accuracy: 0.8429, Test Loss: 0.3779, Test Accuracy: 0.8411\n",
      "Epoch 68, Loss: 0.5298, Accuracy: 0.8394, Test Loss: 0.3804, Test Accuracy: 0.8505\n",
      "Epoch 69, Loss: 0.5280, Accuracy: 0.8458, Test Loss: 0.3933, Test Accuracy: 0.8341\n",
      "Epoch 70, Loss: 0.5325, Accuracy: 0.8394, Test Loss: 0.3797, Test Accuracy: 0.8481\n",
      "Epoch 71, Loss: 0.5216, Accuracy: 0.8435, Test Loss: 0.3958, Test Accuracy: 0.8318\n",
      "Epoch 72, Loss: 0.5224, Accuracy: 0.8458, Test Loss: 0.3737, Test Accuracy: 0.8481\n",
      "Epoch 73, Loss: 0.5165, Accuracy: 0.8481, Test Loss: 0.3850, Test Accuracy: 0.8388\n",
      "Epoch 74, Loss: 0.5194, Accuracy: 0.8429, Test Loss: 0.3717, Test Accuracy: 0.8645\n",
      "Epoch 75, Loss: 0.5204, Accuracy: 0.8411, Test Loss: 0.3793, Test Accuracy: 0.8505\n",
      "Epoch 76, Loss: 0.5225, Accuracy: 0.8452, Test Loss: 0.3700, Test Accuracy: 0.8575\n",
      "Epoch 77, Loss: 0.5219, Accuracy: 0.8435, Test Loss: 0.3873, Test Accuracy: 0.8435\n",
      "Epoch 78, Loss: 0.5103, Accuracy: 0.8464, Test Loss: 0.3746, Test Accuracy: 0.8551\n",
      "Epoch 79, Loss: 0.5208, Accuracy: 0.8452, Test Loss: 0.4134, Test Accuracy: 0.8364\n",
      "Epoch 80, Loss: 0.5104, Accuracy: 0.8487, Test Loss: 0.4373, Test Accuracy: 0.8107\n",
      "Epoch 81, Loss: 0.5035, Accuracy: 0.8516, Test Loss: 0.3733, Test Accuracy: 0.8528\n",
      "Epoch 82, Loss: 0.4971, Accuracy: 0.8534, Test Loss: 0.3760, Test Accuracy: 0.8528\n",
      "Epoch 83, Loss: 0.5201, Accuracy: 0.8400, Test Loss: 0.3869, Test Accuracy: 0.8481\n",
      "Epoch 84, Loss: 0.5045, Accuracy: 0.8405, Test Loss: 0.3873, Test Accuracy: 0.8505\n",
      "Epoch 85, Loss: 0.5089, Accuracy: 0.8464, Test Loss: 0.3805, Test Accuracy: 0.8411\n",
      "Epoch 86, Loss: 0.5241, Accuracy: 0.8411, Test Loss: 0.3861, Test Accuracy: 0.8435\n",
      "Epoch 87, Loss: 0.5168, Accuracy: 0.8382, Test Loss: 0.3738, Test Accuracy: 0.8481\n",
      "Epoch 88, Loss: 0.5127, Accuracy: 0.8411, Test Loss: 0.3794, Test Accuracy: 0.8505\n",
      "Epoch 89, Loss: 0.5038, Accuracy: 0.8446, Test Loss: 0.3777, Test Accuracy: 0.8575\n",
      "Epoch 90, Loss: 0.5185, Accuracy: 0.8411, Test Loss: 0.3720, Test Accuracy: 0.8505\n",
      "Epoch 91, Loss: 0.5044, Accuracy: 0.8475, Test Loss: 0.3783, Test Accuracy: 0.8481\n",
      "Epoch 92, Loss: 0.4980, Accuracy: 0.8487, Test Loss: 0.3752, Test Accuracy: 0.8505\n",
      "Epoch 93, Loss: 0.4897, Accuracy: 0.8505, Test Loss: 0.3754, Test Accuracy: 0.8551\n",
      "Epoch 94, Loss: 0.4866, Accuracy: 0.8522, Test Loss: 0.3619, Test Accuracy: 0.8621\n",
      "Epoch 95, Loss: 0.4971, Accuracy: 0.8475, Test Loss: 0.4093, Test Accuracy: 0.8318\n",
      "Epoch 96, Loss: 0.4927, Accuracy: 0.8464, Test Loss: 0.3742, Test Accuracy: 0.8575\n",
      "Epoch 97, Loss: 0.4981, Accuracy: 0.8429, Test Loss: 0.3681, Test Accuracy: 0.8598\n",
      "Epoch 98, Loss: 0.4950, Accuracy: 0.8487, Test Loss: 0.3845, Test Accuracy: 0.8505\n",
      "Epoch 99, Loss: 0.4866, Accuracy: 0.8493, Test Loss: 0.3654, Test Accuracy: 0.8551\n",
      "Epoch 100, Loss: 0.4888, Accuracy: 0.8493, Test Loss: 0.3774, Test Accuracy: 0.8551\n",
      "Epoch 101, Loss: 0.4950, Accuracy: 0.8435, Test Loss: 0.3673, Test Accuracy: 0.8598\n",
      "Epoch 102, Loss: 0.4936, Accuracy: 0.8458, Test Loss: 0.3697, Test Accuracy: 0.8528\n",
      "Epoch 103, Loss: 0.4816, Accuracy: 0.8481, Test Loss: 0.3734, Test Accuracy: 0.8458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:05:56,873] Trial 2 finished with value: 0.8644859813084113 and parameters: {'batch_size': 32, 'num_gcn_layers': 5, 'gcn_hidden_dim_0': 155, 'gcn_hidden_dim_1': 102, 'gcn_hidden_dim_2': 37, 'gcn_hidden_dim_3': 207, 'gcn_hidden_dim_4': 123, 'num_fc_layers': 3, 'fc_hidden_dim_0': 56, 'fc_hidden_dim_1': 227, 'fc_hidden_dim_2': 148, 'learning_rate': 0.0007798969774858066, 'weight_decay': 0.0006009188938414947, 'pooling_method': 'mean', 'gcn_batch_norm_flag_0': True, 'gcn_batch_norm_flag_1': True, 'gcn_batch_norm_flag_2': True, 'gcn_batch_norm_flag_3': True, 'gcn_batch_norm_flag_4': True, 'gcn_momentum_0': 0.3684324188118387, 'gcn_momentum_1': 0.06544643190398108, 'gcn_momentum_2': 0.7071670804326776, 'gcn_momentum_3': 0.9340832011682417, 'gcn_momentum_4': 0.31437065432372063, 'gcn_eps_0': 0.007417610124405724, 'gcn_eps_1': 0.00907406442927574, 'gcn_eps_2': 0.0015304669638898408, 'gcn_eps_3': 0.009927772239656808, 'gcn_eps_4': 0.009993878315519476, 'gcn_dropout_flag_0': False, 'gcn_dropout_flag_1': False, 'gcn_dropout_flag_2': True, 'gcn_dropout_flag_3': False, 'gcn_dropout_flag_4': False, 'gcn_dropout_rate_2': 0.22096228667945736, 'gcn_activation_0': 'elu', 'gcn_activation_1': 'softplus', 'gcn_activation_2': 'elu', 'gcn_activation_3': 'gelu', 'gcn_activation_4': 'relu', 'fc_batch_norm_flag_0': False, 'fc_batch_norm_flag_1': False, 'fc_batch_norm_flag_2': False, 'fc_dropout_flag_0': False, 'fc_dropout_flag_1': False, 'fc_dropout_flag_2': False, 'fc_activation_0': 'elu', 'fc_activation_1': 'leaky_relu', 'fc_activation_2': 'leaky_relu', 'gcn_skip_connections_0': True, 'gcn_skip_connections_1': True, 'gcn_skip_connections_2': True, 'gcn_skip_connections_3': True, 'gcn_skip_connections_4': True, 'l1_lambda': 0.00020223892405747023, 'optimizer': 'Adam', 'beta1': 0.9646643720238194, 'beta2': 0.9989610464563805, 'lr_scheduler': 'PolynomialLR', 'power': 0.15293892624146557, 'total_iters': 259, 'loss_function': 'CrossEntropy'}. Best is trial 2 with value: 0.8644859813084113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104, Loss: 0.4803, Accuracy: 0.8557, Test Loss: 0.3682, Test Accuracy: 0.8528\n",
      "Early stopping triggered\n",
      "Epoch 1, Loss: 1.4084, Accuracy: 0.4077, Test Loss: 0.3511, Test Accuracy: 0.5257\n",
      "Epoch 2, Loss: 1.1401, Accuracy: 0.5491, Test Loss: 0.2783, Test Accuracy: 0.5257\n",
      "Epoch 3, Loss: 1.0834, Accuracy: 0.5707, Test Loss: 0.2760, Test Accuracy: 0.5748\n",
      "Epoch 4, Loss: 1.0312, Accuracy: 0.6162, Test Loss: 0.2628, Test Accuracy: 0.5748\n",
      "Epoch 5, Loss: 0.9624, Accuracy: 0.6805, Test Loss: 0.2386, Test Accuracy: 0.5864\n",
      "Epoch 6, Loss: 0.9093, Accuracy: 0.6840, Test Loss: 0.2214, Test Accuracy: 0.6472\n",
      "Epoch 7, Loss: 0.8594, Accuracy: 0.6904, Test Loss: 0.2090, Test Accuracy: 0.7009\n",
      "Epoch 8, Loss: 0.8096, Accuracy: 0.6945, Test Loss: 0.2000, Test Accuracy: 0.7009\n",
      "Epoch 9, Loss: 0.7561, Accuracy: 0.6933, Test Loss: 0.1932, Test Accuracy: 0.7103\n",
      "Epoch 10, Loss: 0.7115, Accuracy: 0.7004, Test Loss: 0.1810, Test Accuracy: 0.7196\n",
      "Epoch 11, Loss: 0.6632, Accuracy: 0.7044, Test Loss: 0.1719, Test Accuracy: 0.7383\n",
      "Epoch 12, Loss: 0.6202, Accuracy: 0.7126, Test Loss: 0.1691, Test Accuracy: 0.7360\n",
      "Epoch 13, Loss: 0.5775, Accuracy: 0.7220, Test Loss: 0.1661, Test Accuracy: 0.7360\n",
      "Epoch 14, Loss: 0.5378, Accuracy: 0.7249, Test Loss: 0.1612, Test Accuracy: 0.7453\n",
      "Epoch 15, Loss: 0.5026, Accuracy: 0.7284, Test Loss: 0.1568, Test Accuracy: 0.7547\n",
      "Epoch 16, Loss: 0.4701, Accuracy: 0.7395, Test Loss: 0.1505, Test Accuracy: 0.7547\n",
      "Epoch 17, Loss: 0.4382, Accuracy: 0.7360, Test Loss: 0.1451, Test Accuracy: 0.7547\n",
      "Epoch 18, Loss: 0.4134, Accuracy: 0.7424, Test Loss: 0.1423, Test Accuracy: 0.7547\n",
      "Epoch 19, Loss: 0.3857, Accuracy: 0.7389, Test Loss: 0.1364, Test Accuracy: 0.7804\n",
      "Epoch 20, Loss: 0.3624, Accuracy: 0.7529, Test Loss: 0.1323, Test Accuracy: 0.7827\n",
      "Epoch 21, Loss: 0.3413, Accuracy: 0.7593, Test Loss: 0.1222, Test Accuracy: 0.7897\n",
      "Epoch 22, Loss: 0.3278, Accuracy: 0.7693, Test Loss: 0.1295, Test Accuracy: 0.7991\n",
      "Epoch 23, Loss: 0.3108, Accuracy: 0.7658, Test Loss: 0.1221, Test Accuracy: 0.8014\n",
      "Epoch 24, Loss: 0.2970, Accuracy: 0.7804, Test Loss: 0.1231, Test Accuracy: 0.8061\n",
      "Epoch 25, Loss: 0.2862, Accuracy: 0.7821, Test Loss: 0.1226, Test Accuracy: 0.8061\n",
      "Epoch 26, Loss: 0.2725, Accuracy: 0.7903, Test Loss: 0.1225, Test Accuracy: 0.8061\n",
      "Epoch 27, Loss: 0.2620, Accuracy: 0.7944, Test Loss: 0.1139, Test Accuracy: 0.8061\n",
      "Epoch 28, Loss: 0.2530, Accuracy: 0.7996, Test Loss: 0.1082, Test Accuracy: 0.8061\n",
      "Epoch 29, Loss: 0.2497, Accuracy: 0.7921, Test Loss: 0.1100, Test Accuracy: 0.8061\n",
      "Epoch 30, Loss: 0.2450, Accuracy: 0.7961, Test Loss: 0.1090, Test Accuracy: 0.8084\n",
      "Epoch 31, Loss: 0.2374, Accuracy: 0.7950, Test Loss: 0.1008, Test Accuracy: 0.8084\n",
      "Epoch 32, Loss: 0.2336, Accuracy: 0.7985, Test Loss: 0.1009, Test Accuracy: 0.8084\n",
      "Epoch 33, Loss: 0.2287, Accuracy: 0.8008, Test Loss: 0.1080, Test Accuracy: 0.8084\n",
      "Epoch 34, Loss: 0.2267, Accuracy: 0.7961, Test Loss: 0.0976, Test Accuracy: 0.8061\n",
      "Epoch 35, Loss: 0.2235, Accuracy: 0.7985, Test Loss: 0.0971, Test Accuracy: 0.8061\n",
      "Epoch 36, Loss: 0.2187, Accuracy: 0.7985, Test Loss: 0.0973, Test Accuracy: 0.8061\n",
      "Epoch 37, Loss: 0.2152, Accuracy: 0.7996, Test Loss: 0.1003, Test Accuracy: 0.8061\n",
      "Epoch 38, Loss: 0.2126, Accuracy: 0.7961, Test Loss: 0.0989, Test Accuracy: 0.8061\n",
      "Epoch 39, Loss: 0.2070, Accuracy: 0.7967, Test Loss: 0.0963, Test Accuracy: 0.8061\n",
      "Epoch 40, Loss: 0.2086, Accuracy: 0.7967, Test Loss: 0.0970, Test Accuracy: 0.8084\n",
      "Epoch 41, Loss: 0.2041, Accuracy: 0.7996, Test Loss: 0.0981, Test Accuracy: 0.8084\n",
      "Epoch 42, Loss: 0.2016, Accuracy: 0.8014, Test Loss: 0.0982, Test Accuracy: 0.8061\n",
      "Epoch 43, Loss: 0.2012, Accuracy: 0.8002, Test Loss: 0.0966, Test Accuracy: 0.8061\n",
      "Epoch 44, Loss: 0.1967, Accuracy: 0.8020, Test Loss: 0.0948, Test Accuracy: 0.8061\n",
      "Epoch 45, Loss: 0.1960, Accuracy: 0.8020, Test Loss: 0.0954, Test Accuracy: 0.8061\n",
      "Epoch 46, Loss: 0.1939, Accuracy: 0.7985, Test Loss: 0.0975, Test Accuracy: 0.8061\n",
      "Epoch 47, Loss: 0.1921, Accuracy: 0.7979, Test Loss: 0.0942, Test Accuracy: 0.8084\n",
      "Epoch 48, Loss: 0.1915, Accuracy: 0.7979, Test Loss: 0.0938, Test Accuracy: 0.8084\n",
      "Epoch 49, Loss: 0.1910, Accuracy: 0.7991, Test Loss: 0.0942, Test Accuracy: 0.8061\n",
      "Epoch 50, Loss: 0.1898, Accuracy: 0.7991, Test Loss: 0.0942, Test Accuracy: 0.8061\n",
      "Epoch 51, Loss: 0.1875, Accuracy: 0.8032, Test Loss: 0.0974, Test Accuracy: 0.8084\n",
      "Epoch 52, Loss: 0.1856, Accuracy: 0.7973, Test Loss: 0.0968, Test Accuracy: 0.8061\n",
      "Epoch 53, Loss: 0.1865, Accuracy: 0.7979, Test Loss: 0.0945, Test Accuracy: 0.8061\n",
      "Epoch 54, Loss: 0.1828, Accuracy: 0.7996, Test Loss: 0.0993, Test Accuracy: 0.8061\n",
      "Epoch 55, Loss: 0.1846, Accuracy: 0.7991, Test Loss: 0.0939, Test Accuracy: 0.8061\n",
      "Epoch 56, Loss: 0.1809, Accuracy: 0.8014, Test Loss: 0.0964, Test Accuracy: 0.8061\n",
      "Epoch 57, Loss: 0.1779, Accuracy: 0.7973, Test Loss: 0.0963, Test Accuracy: 0.8061\n",
      "Epoch 58, Loss: 0.1772, Accuracy: 0.8032, Test Loss: 0.0954, Test Accuracy: 0.8061\n",
      "Epoch 59, Loss: 0.1777, Accuracy: 0.8008, Test Loss: 0.0948, Test Accuracy: 0.8061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:06:53,265] Trial 3 finished with value: 0.8084112149532711 and parameters: {'batch_size': 256, 'num_gcn_layers': 3, 'gcn_hidden_dim_0': 157, 'gcn_hidden_dim_1': 93, 'gcn_hidden_dim_2': 52, 'num_fc_layers': 1, 'fc_hidden_dim_0': 43, 'learning_rate': 0.0014329203617871806, 'weight_decay': 0.00047570422118518884, 'pooling_method': 'max', 'gcn_batch_norm_flag_0': False, 'gcn_batch_norm_flag_1': True, 'gcn_batch_norm_flag_2': True, 'gcn_momentum_1': 0.13428046008271424, 'gcn_momentum_2': 0.061174214688726206, 'gcn_eps_1': 0.008324207142507794, 'gcn_eps_2': 0.008728043275143487, 'gcn_dropout_flag_0': True, 'gcn_dropout_flag_1': True, 'gcn_dropout_flag_2': True, 'gcn_dropout_rate_0': 0.3545814526599419, 'gcn_dropout_rate_1': 0.11694675043321001, 'gcn_dropout_rate_2': 0.4241188633218478, 'gcn_activation_0': 'elu', 'gcn_activation_1': 'elu', 'gcn_activation_2': 'tanh', 'fc_batch_norm_flag_0': False, 'fc_dropout_flag_0': True, 'fc_dropout_rate_0': 0.32442680014055825, 'fc_activation_0': 'tanh', 'gcn_skip_connections_0': True, 'gcn_skip_connections_1': True, 'gcn_skip_connections_2': True, 'l1_lambda': 0.00022332255465405337, 'optimizer': 'Adam', 'beta1': 0.9567055804885297, 'beta2': 0.9739605057688483, 'lr_scheduler': 'StepLR', 'step_size': 27, 'stepLRgamma': 0.5876474147110187, 'loss_function': 'MultiMargin'}. Best is trial 2 with value: 0.8644859813084113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60, Loss: 0.1776, Accuracy: 0.8020, Test Loss: 0.0937, Test Accuracy: 0.8061\n",
      "Early stopping triggered\n",
      "Epoch 1, Loss: 7.6489, Accuracy: 0.1519, Test Loss: 1.8049, Test Accuracy: 0.1215\n",
      "Epoch 2, Loss: 7.6266, Accuracy: 0.1501, Test Loss: 1.7791, Test Accuracy: 0.1869\n",
      "Epoch 3, Loss: 7.6207, Accuracy: 0.1653, Test Loss: 1.8360, Test Accuracy: 0.1565\n",
      "Epoch 4, Loss: 7.6273, Accuracy: 0.1589, Test Loss: 1.8212, Test Accuracy: 0.1145\n",
      "Epoch 5, Loss: 7.6029, Accuracy: 0.1729, Test Loss: 1.8249, Test Accuracy: 0.1425\n",
      "Epoch 6, Loss: 7.6082, Accuracy: 0.1665, Test Loss: 1.7738, Test Accuracy: 0.1752\n",
      "Epoch 7, Loss: 7.5857, Accuracy: 0.1793, Test Loss: 1.8081, Test Accuracy: 0.1612\n",
      "Epoch 8, Loss: 7.5953, Accuracy: 0.1817, Test Loss: 1.8067, Test Accuracy: 0.1589\n",
      "Epoch 9, Loss: 7.5952, Accuracy: 0.1676, Test Loss: 1.7366, Test Accuracy: 0.2617\n",
      "Epoch 10, Loss: 7.5938, Accuracy: 0.1641, Test Loss: 1.7594, Test Accuracy: 0.1939\n",
      "Epoch 11, Loss: 7.5866, Accuracy: 0.1811, Test Loss: 1.7666, Test Accuracy: 0.1682\n",
      "Epoch 12, Loss: 7.5796, Accuracy: 0.1782, Test Loss: 1.7451, Test Accuracy: 0.2360\n",
      "Epoch 13, Loss: 7.5669, Accuracy: 0.1893, Test Loss: 1.7611, Test Accuracy: 0.2033\n",
      "Epoch 14, Loss: 7.5628, Accuracy: 0.2009, Test Loss: 1.7841, Test Accuracy: 0.1776\n",
      "Epoch 15, Loss: 7.5581, Accuracy: 0.2126, Test Loss: 1.7631, Test Accuracy: 0.1332\n",
      "Epoch 16, Loss: 7.5612, Accuracy: 0.1904, Test Loss: 1.6797, Test Accuracy: 0.3364\n",
      "Epoch 17, Loss: 7.5479, Accuracy: 0.2079, Test Loss: 1.7499, Test Accuracy: 0.2103\n",
      "Epoch 18, Loss: 7.5440, Accuracy: 0.2255, Test Loss: 1.7103, Test Accuracy: 0.2593\n",
      "Epoch 19, Loss: 7.5274, Accuracy: 0.2231, Test Loss: 1.7160, Test Accuracy: 0.2710\n",
      "Epoch 20, Loss: 7.5166, Accuracy: 0.2348, Test Loss: 1.7150, Test Accuracy: 0.3131\n",
      "Epoch 21, Loss: 7.5224, Accuracy: 0.2261, Test Loss: 1.7015, Test Accuracy: 0.2967\n",
      "Epoch 22, Loss: 7.5057, Accuracy: 0.2395, Test Loss: 1.6846, Test Accuracy: 0.3551\n",
      "Epoch 23, Loss: 7.5166, Accuracy: 0.2301, Test Loss: 1.7206, Test Accuracy: 0.2944\n",
      "Epoch 24, Loss: 7.4961, Accuracy: 0.2494, Test Loss: 1.6856, Test Accuracy: 0.3481\n",
      "Epoch 25, Loss: 7.5014, Accuracy: 0.2541, Test Loss: 1.7142, Test Accuracy: 0.2827\n",
      "Epoch 26, Loss: 7.4979, Accuracy: 0.2634, Test Loss: 1.6523, Test Accuracy: 0.4439\n",
      "Epoch 27, Loss: 7.4937, Accuracy: 0.2576, Test Loss: 1.6432, Test Accuracy: 0.4393\n",
      "Epoch 28, Loss: 7.4980, Accuracy: 0.2436, Test Loss: 1.6743, Test Accuracy: 0.3692\n",
      "Epoch 29, Loss: 7.4819, Accuracy: 0.2687, Test Loss: 1.6422, Test Accuracy: 0.4626\n",
      "Epoch 30, Loss: 7.4810, Accuracy: 0.2734, Test Loss: 1.6364, Test Accuracy: 0.4252\n",
      "Epoch 31, Loss: 7.4732, Accuracy: 0.2605, Test Loss: 1.7115, Test Accuracy: 0.2850\n",
      "Epoch 32, Loss: 7.4655, Accuracy: 0.2728, Test Loss: 1.6675, Test Accuracy: 0.3481\n",
      "Epoch 33, Loss: 7.4512, Accuracy: 0.2950, Test Loss: 1.6414, Test Accuracy: 0.3925\n",
      "Epoch 34, Loss: 7.4542, Accuracy: 0.2804, Test Loss: 1.6142, Test Accuracy: 0.5093\n",
      "Epoch 35, Loss: 7.4394, Accuracy: 0.3002, Test Loss: 1.6260, Test Accuracy: 0.4766\n",
      "Epoch 36, Loss: 7.4395, Accuracy: 0.3026, Test Loss: 1.6399, Test Accuracy: 0.4486\n",
      "Epoch 37, Loss: 7.4318, Accuracy: 0.3055, Test Loss: 1.6382, Test Accuracy: 0.4486\n",
      "Epoch 38, Loss: 7.4459, Accuracy: 0.2926, Test Loss: 1.6236, Test Accuracy: 0.5327\n",
      "Epoch 39, Loss: 7.4359, Accuracy: 0.3061, Test Loss: 1.5807, Test Accuracy: 0.5631\n",
      "Epoch 40, Loss: 7.4272, Accuracy: 0.3224, Test Loss: 1.6303, Test Accuracy: 0.4579\n",
      "Epoch 41, Loss: 7.4036, Accuracy: 0.3294, Test Loss: 1.5997, Test Accuracy: 0.5701\n",
      "Epoch 42, Loss: 7.4031, Accuracy: 0.3400, Test Loss: 1.6268, Test Accuracy: 0.4112\n",
      "Epoch 43, Loss: 7.4154, Accuracy: 0.3341, Test Loss: 1.6293, Test Accuracy: 0.4416\n",
      "Epoch 44, Loss: 7.4194, Accuracy: 0.3154, Test Loss: 1.5953, Test Accuracy: 0.5350\n",
      "Epoch 45, Loss: 7.4036, Accuracy: 0.3347, Test Loss: 1.5903, Test Accuracy: 0.5444\n",
      "Epoch 46, Loss: 7.4050, Accuracy: 0.3370, Test Loss: 1.6169, Test Accuracy: 0.4393\n",
      "Epoch 47, Loss: 7.3907, Accuracy: 0.3435, Test Loss: 1.5974, Test Accuracy: 0.5374\n",
      "Epoch 48, Loss: 7.4003, Accuracy: 0.3394, Test Loss: 1.6462, Test Accuracy: 0.3551\n",
      "Epoch 49, Loss: 7.3725, Accuracy: 0.3610, Test Loss: 1.5971, Test Accuracy: 0.4766\n",
      "Epoch 50, Loss: 7.3922, Accuracy: 0.3499, Test Loss: 1.5947, Test Accuracy: 0.5748\n",
      "Epoch 51, Loss: 7.3759, Accuracy: 0.3721, Test Loss: 1.6036, Test Accuracy: 0.4883\n",
      "Epoch 52, Loss: 7.3769, Accuracy: 0.3797, Test Loss: 1.5956, Test Accuracy: 0.5654\n",
      "Epoch 53, Loss: 7.3751, Accuracy: 0.3697, Test Loss: 1.5339, Test Accuracy: 0.5397\n",
      "Epoch 54, Loss: 7.3479, Accuracy: 0.3954, Test Loss: 1.5792, Test Accuracy: 0.5491\n",
      "Epoch 55, Loss: 7.3608, Accuracy: 0.3791, Test Loss: 1.5519, Test Accuracy: 0.5794\n",
      "Epoch 56, Loss: 7.3461, Accuracy: 0.3984, Test Loss: 1.5611, Test Accuracy: 0.5701\n",
      "Epoch 57, Loss: 7.3466, Accuracy: 0.3978, Test Loss: 1.5743, Test Accuracy: 0.5397\n",
      "Epoch 58, Loss: 7.3410, Accuracy: 0.4071, Test Loss: 1.5601, Test Accuracy: 0.5935\n",
      "Epoch 59, Loss: 7.3389, Accuracy: 0.4077, Test Loss: 1.5513, Test Accuracy: 0.6005\n",
      "Epoch 60, Loss: 7.3292, Accuracy: 0.3949, Test Loss: 1.5768, Test Accuracy: 0.5537\n",
      "Epoch 61, Loss: 7.3329, Accuracy: 0.4071, Test Loss: 1.5534, Test Accuracy: 0.6168\n",
      "Epoch 62, Loss: 7.3328, Accuracy: 0.4083, Test Loss: 1.5851, Test Accuracy: 0.5654\n",
      "Epoch 63, Loss: 7.3197, Accuracy: 0.4159, Test Loss: 1.5409, Test Accuracy: 0.5981\n",
      "Epoch 64, Loss: 7.3085, Accuracy: 0.4188, Test Loss: 1.5209, Test Accuracy: 0.6098\n",
      "Epoch 65, Loss: 7.3101, Accuracy: 0.4393, Test Loss: 1.5272, Test Accuracy: 0.5841\n",
      "Epoch 66, Loss: 7.3207, Accuracy: 0.4130, Test Loss: 1.5065, Test Accuracy: 0.6145\n",
      "Epoch 67, Loss: 7.3113, Accuracy: 0.4159, Test Loss: 1.4845, Test Accuracy: 0.6028\n",
      "Epoch 68, Loss: 7.3062, Accuracy: 0.4264, Test Loss: 1.4803, Test Accuracy: 0.6005\n",
      "Epoch 69, Loss: 7.3110, Accuracy: 0.4340, Test Loss: 1.5326, Test Accuracy: 0.6005\n",
      "Epoch 70, Loss: 7.3096, Accuracy: 0.4188, Test Loss: 1.5235, Test Accuracy: 0.5841\n",
      "Epoch 71, Loss: 7.3025, Accuracy: 0.4246, Test Loss: 1.4901, Test Accuracy: 0.6192\n",
      "Epoch 72, Loss: 7.2959, Accuracy: 0.4398, Test Loss: 1.4837, Test Accuracy: 0.6145\n",
      "Epoch 73, Loss: 7.2943, Accuracy: 0.4311, Test Loss: 1.5003, Test Accuracy: 0.6285\n",
      "Epoch 74, Loss: 7.2843, Accuracy: 0.4410, Test Loss: 1.5056, Test Accuracy: 0.6051\n",
      "Epoch 75, Loss: 7.2863, Accuracy: 0.4416, Test Loss: 1.5091, Test Accuracy: 0.6285\n",
      "Epoch 76, Loss: 7.2767, Accuracy: 0.4632, Test Loss: 1.4934, Test Accuracy: 0.6355\n",
      "Epoch 77, Loss: 7.2803, Accuracy: 0.4568, Test Loss: 1.4855, Test Accuracy: 0.6145\n",
      "Epoch 78, Loss: 7.2706, Accuracy: 0.4609, Test Loss: 1.4627, Test Accuracy: 0.6168\n",
      "Epoch 79, Loss: 7.2628, Accuracy: 0.4667, Test Loss: 1.4674, Test Accuracy: 0.6192\n",
      "Epoch 80, Loss: 7.2669, Accuracy: 0.4632, Test Loss: 1.4860, Test Accuracy: 0.6075\n",
      "Epoch 81, Loss: 7.2485, Accuracy: 0.4685, Test Loss: 1.4877, Test Accuracy: 0.5911\n",
      "Epoch 82, Loss: 7.2624, Accuracy: 0.4632, Test Loss: 1.4895, Test Accuracy: 0.5888\n",
      "Epoch 83, Loss: 7.2587, Accuracy: 0.4790, Test Loss: 1.4764, Test Accuracy: 0.6168\n",
      "Epoch 84, Loss: 7.2488, Accuracy: 0.4854, Test Loss: 1.4746, Test Accuracy: 0.6005\n",
      "Epoch 85, Loss: 7.2371, Accuracy: 0.4848, Test Loss: 1.4813, Test Accuracy: 0.6238\n",
      "Epoch 86, Loss: 7.2438, Accuracy: 0.4714, Test Loss: 1.4728, Test Accuracy: 0.6192\n",
      "Epoch 87, Loss: 7.2421, Accuracy: 0.4720, Test Loss: 1.4846, Test Accuracy: 0.6332\n",
      "Epoch 88, Loss: 7.2413, Accuracy: 0.4731, Test Loss: 1.4816, Test Accuracy: 0.6168\n",
      "Epoch 89, Loss: 7.2344, Accuracy: 0.4924, Test Loss: 1.4375, Test Accuracy: 0.6425\n",
      "Epoch 90, Loss: 7.2217, Accuracy: 0.5111, Test Loss: 1.4724, Test Accuracy: 0.6145\n",
      "Epoch 91, Loss: 7.2189, Accuracy: 0.5029, Test Loss: 1.4769, Test Accuracy: 0.6308\n",
      "Epoch 92, Loss: 7.2276, Accuracy: 0.4912, Test Loss: 1.4207, Test Accuracy: 0.6168\n",
      "Epoch 93, Loss: 7.2182, Accuracy: 0.5111, Test Loss: 1.4561, Test Accuracy: 0.6285\n",
      "Epoch 94, Loss: 7.2149, Accuracy: 0.4918, Test Loss: 1.3926, Test Accuracy: 0.6355\n",
      "Epoch 95, Loss: 7.2051, Accuracy: 0.4982, Test Loss: 1.3968, Test Accuracy: 0.6238\n",
      "Epoch 96, Loss: 7.2150, Accuracy: 0.5064, Test Loss: 1.4488, Test Accuracy: 0.6519\n",
      "Epoch 97, Loss: 7.2165, Accuracy: 0.4947, Test Loss: 1.4578, Test Accuracy: 0.6355\n",
      "Epoch 98, Loss: 7.2193, Accuracy: 0.5012, Test Loss: 1.3795, Test Accuracy: 0.6379\n",
      "Epoch 99, Loss: 7.2099, Accuracy: 0.5000, Test Loss: 1.4280, Test Accuracy: 0.6308\n",
      "Epoch 100, Loss: 7.1943, Accuracy: 0.5239, Test Loss: 1.4379, Test Accuracy: 0.6238\n",
      "Epoch 101, Loss: 7.2038, Accuracy: 0.5228, Test Loss: 1.4182, Test Accuracy: 0.6192\n",
      "Epoch 102, Loss: 7.2051, Accuracy: 0.5123, Test Loss: 1.4180, Test Accuracy: 0.6285\n",
      "Epoch 103, Loss: 7.1958, Accuracy: 0.5082, Test Loss: 1.4529, Test Accuracy: 0.6308\n",
      "Epoch 104, Loss: 7.1836, Accuracy: 0.5164, Test Loss: 1.4458, Test Accuracy: 0.6121\n",
      "Epoch 105, Loss: 7.1714, Accuracy: 0.5315, Test Loss: 1.4492, Test Accuracy: 0.6495\n",
      "Epoch 106, Loss: 7.1788, Accuracy: 0.5391, Test Loss: 1.4143, Test Accuracy: 0.6355\n",
      "Epoch 107, Loss: 7.1679, Accuracy: 0.5275, Test Loss: 1.3922, Test Accuracy: 0.6659\n",
      "Epoch 108, Loss: 7.1758, Accuracy: 0.5263, Test Loss: 1.3925, Test Accuracy: 0.6472\n",
      "Epoch 109, Loss: 7.1725, Accuracy: 0.5310, Test Loss: 1.3690, Test Accuracy: 0.6495\n",
      "Epoch 110, Loss: 7.1835, Accuracy: 0.5134, Test Loss: 1.3846, Test Accuracy: 0.6636\n",
      "Epoch 111, Loss: 7.1690, Accuracy: 0.5386, Test Loss: 1.4126, Test Accuracy: 0.6262\n",
      "Epoch 112, Loss: 7.1707, Accuracy: 0.5286, Test Loss: 1.3802, Test Accuracy: 0.6589\n",
      "Epoch 113, Loss: 7.1610, Accuracy: 0.5339, Test Loss: 1.3653, Test Accuracy: 0.6449\n",
      "Epoch 114, Loss: 7.1504, Accuracy: 0.5362, Test Loss: 1.4015, Test Accuracy: 0.6542\n",
      "Epoch 115, Loss: 7.1568, Accuracy: 0.5421, Test Loss: 1.3440, Test Accuracy: 0.5935\n",
      "Epoch 116, Loss: 7.1627, Accuracy: 0.5362, Test Loss: 1.3743, Test Accuracy: 0.6332\n",
      "Epoch 117, Loss: 7.1556, Accuracy: 0.5514, Test Loss: 1.3755, Test Accuracy: 0.6565\n",
      "Epoch 118, Loss: 7.1484, Accuracy: 0.5473, Test Loss: 1.3904, Test Accuracy: 0.6495\n",
      "Epoch 119, Loss: 7.1479, Accuracy: 0.5450, Test Loss: 1.3617, Test Accuracy: 0.6425\n",
      "Epoch 120, Loss: 7.1381, Accuracy: 0.5386, Test Loss: 1.3830, Test Accuracy: 0.6402\n",
      "Epoch 121, Loss: 7.1425, Accuracy: 0.5496, Test Loss: 1.3961, Test Accuracy: 0.6565\n",
      "Epoch 122, Loss: 7.1551, Accuracy: 0.5403, Test Loss: 1.3531, Test Accuracy: 0.6379\n",
      "Epoch 123, Loss: 7.1401, Accuracy: 0.5485, Test Loss: 1.3217, Test Accuracy: 0.6355\n",
      "Epoch 124, Loss: 7.1328, Accuracy: 0.5666, Test Loss: 1.3416, Test Accuracy: 0.6706\n",
      "Epoch 125, Loss: 7.1392, Accuracy: 0.5520, Test Loss: 1.3129, Test Accuracy: 0.6355\n",
      "Epoch 126, Loss: 7.1305, Accuracy: 0.5532, Test Loss: 1.3769, Test Accuracy: 0.6565\n",
      "Epoch 127, Loss: 7.1198, Accuracy: 0.5572, Test Loss: 1.3482, Test Accuracy: 0.6449\n",
      "Epoch 128, Loss: 7.1300, Accuracy: 0.5572, Test Loss: 1.3294, Test Accuracy: 0.6285\n",
      "Epoch 129, Loss: 7.1144, Accuracy: 0.5678, Test Loss: 1.3204, Test Accuracy: 0.6659\n",
      "Epoch 130, Loss: 7.1279, Accuracy: 0.5637, Test Loss: 1.3052, Test Accuracy: 0.6636\n",
      "Epoch 131, Loss: 7.1143, Accuracy: 0.5561, Test Loss: 1.3382, Test Accuracy: 0.6519\n",
      "Epoch 132, Loss: 7.1034, Accuracy: 0.5794, Test Loss: 1.3052, Test Accuracy: 0.6612\n",
      "Epoch 133, Loss: 7.1175, Accuracy: 0.5631, Test Loss: 1.3287, Test Accuracy: 0.6612\n",
      "Epoch 134, Loss: 7.1067, Accuracy: 0.5631, Test Loss: 1.3141, Test Accuracy: 0.6472\n",
      "Epoch 135, Loss: 7.0897, Accuracy: 0.5835, Test Loss: 1.3427, Test Accuracy: 0.6495\n",
      "Epoch 136, Loss: 7.0996, Accuracy: 0.5643, Test Loss: 1.3446, Test Accuracy: 0.6612\n",
      "Epoch 137, Loss: 7.0956, Accuracy: 0.5532, Test Loss: 1.3309, Test Accuracy: 0.6519\n",
      "Epoch 138, Loss: 7.0938, Accuracy: 0.5672, Test Loss: 1.3248, Test Accuracy: 0.6519\n",
      "Epoch 139, Loss: 7.0901, Accuracy: 0.5683, Test Loss: 1.3699, Test Accuracy: 0.6472\n",
      "Epoch 140, Loss: 7.0921, Accuracy: 0.5759, Test Loss: 1.2900, Test Accuracy: 0.6706\n",
      "Epoch 141, Loss: 7.0823, Accuracy: 0.5894, Test Loss: 1.3181, Test Accuracy: 0.6565\n",
      "Epoch 142, Loss: 7.1016, Accuracy: 0.5631, Test Loss: 1.2833, Test Accuracy: 0.6612\n",
      "Epoch 143, Loss: 7.0905, Accuracy: 0.5759, Test Loss: 1.3138, Test Accuracy: 0.6565\n",
      "Epoch 144, Loss: 7.0863, Accuracy: 0.5771, Test Loss: 1.3620, Test Accuracy: 0.6332\n",
      "Epoch 145, Loss: 7.0677, Accuracy: 0.5935, Test Loss: 1.3296, Test Accuracy: 0.6893\n",
      "Epoch 146, Loss: 7.0840, Accuracy: 0.5771, Test Loss: 1.2781, Test Accuracy: 0.6682\n",
      "Epoch 147, Loss: 7.0930, Accuracy: 0.5707, Test Loss: 1.2972, Test Accuracy: 0.6565\n",
      "Epoch 148, Loss: 7.0780, Accuracy: 0.5900, Test Loss: 1.2859, Test Accuracy: 0.6706\n",
      "Epoch 149, Loss: 7.0736, Accuracy: 0.5754, Test Loss: 1.3038, Test Accuracy: 0.6612\n",
      "Epoch 150, Loss: 7.0793, Accuracy: 0.5794, Test Loss: 1.2991, Test Accuracy: 0.6659\n",
      "Epoch 151, Loss: 7.0729, Accuracy: 0.5771, Test Loss: 1.3368, Test Accuracy: 0.6565\n",
      "Epoch 152, Loss: 7.0732, Accuracy: 0.5882, Test Loss: 1.2730, Test Accuracy: 0.6729\n",
      "Epoch 153, Loss: 7.0820, Accuracy: 0.5806, Test Loss: 1.2535, Test Accuracy: 0.6682\n",
      "Epoch 154, Loss: 7.0554, Accuracy: 0.5958, Test Loss: 1.3760, Test Accuracy: 0.6542\n",
      "Epoch 155, Loss: 7.0797, Accuracy: 0.5672, Test Loss: 1.3079, Test Accuracy: 0.6729\n",
      "Epoch 156, Loss: 7.0613, Accuracy: 0.5900, Test Loss: 1.2912, Test Accuracy: 0.6589\n",
      "Epoch 157, Loss: 7.0501, Accuracy: 0.5940, Test Loss: 1.2378, Test Accuracy: 0.6869\n",
      "Epoch 158, Loss: 7.0504, Accuracy: 0.5824, Test Loss: 1.2782, Test Accuracy: 0.6519\n",
      "Epoch 159, Loss: 7.0522, Accuracy: 0.5882, Test Loss: 1.2566, Test Accuracy: 0.6636\n",
      "Epoch 160, Loss: 7.0606, Accuracy: 0.5765, Test Loss: 1.2679, Test Accuracy: 0.6822\n",
      "Epoch 161, Loss: 7.0451, Accuracy: 0.5777, Test Loss: 1.2586, Test Accuracy: 0.6822\n",
      "Epoch 162, Loss: 7.0529, Accuracy: 0.5683, Test Loss: 1.2913, Test Accuracy: 0.6776\n",
      "Epoch 163, Loss: 7.0523, Accuracy: 0.5900, Test Loss: 1.2963, Test Accuracy: 0.6659\n",
      "Epoch 164, Loss: 7.0426, Accuracy: 0.5993, Test Loss: 1.2521, Test Accuracy: 0.6612\n",
      "Epoch 165, Loss: 7.0426, Accuracy: 0.5975, Test Loss: 1.2956, Test Accuracy: 0.6752\n",
      "Epoch 166, Loss: 7.0316, Accuracy: 0.5917, Test Loss: 1.3049, Test Accuracy: 0.6449\n",
      "Epoch 167, Loss: 7.0410, Accuracy: 0.5900, Test Loss: 1.2802, Test Accuracy: 0.6776\n",
      "Epoch 168, Loss: 7.0305, Accuracy: 0.5975, Test Loss: 1.2840, Test Accuracy: 0.6472\n",
      "Epoch 169, Loss: 7.0368, Accuracy: 0.5759, Test Loss: 1.2701, Test Accuracy: 0.6706\n",
      "Epoch 170, Loss: 7.0245, Accuracy: 0.6063, Test Loss: 1.2440, Test Accuracy: 0.6799\n",
      "Epoch 171, Loss: 7.0323, Accuracy: 0.5853, Test Loss: 1.2689, Test Accuracy: 0.6869\n",
      "Epoch 172, Loss: 7.0241, Accuracy: 0.6046, Test Loss: 1.2519, Test Accuracy: 0.6799\n",
      "Epoch 173, Loss: 7.0313, Accuracy: 0.5975, Test Loss: 1.2549, Test Accuracy: 0.6752\n",
      "Epoch 174, Loss: 7.0364, Accuracy: 0.5975, Test Loss: 1.2481, Test Accuracy: 0.6636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:12:33,624] Trial 4 finished with value: 0.6892523364485982 and parameters: {'batch_size': 32, 'num_gcn_layers': 3, 'gcn_hidden_dim_0': 122, 'gcn_hidden_dim_1': 192, 'gcn_hidden_dim_2': 188, 'num_fc_layers': 1, 'fc_hidden_dim_0': 245, 'learning_rate': 1.6450352024751824e-05, 'weight_decay': 0.0008991685651132879, 'pooling_method': 'mean', 'gcn_batch_norm_flag_0': False, 'gcn_batch_norm_flag_1': True, 'gcn_batch_norm_flag_2': True, 'gcn_momentum_1': 0.7518382711145274, 'gcn_momentum_2': 0.6924365665368856, 'gcn_eps_1': 0.008463909266888987, 'gcn_eps_2': 0.003688383168056731, 'gcn_dropout_flag_0': False, 'gcn_dropout_flag_1': True, 'gcn_dropout_flag_2': True, 'gcn_dropout_rate_1': 0.4418277133901761, 'gcn_dropout_rate_2': 0.20549922980536645, 'gcn_activation_0': 'relu', 'gcn_activation_1': 'gelu', 'gcn_activation_2': 'relu', 'fc_batch_norm_flag_0': True, 'fc_momentum_0': 0.748049481465864, 'fc_eps_0': 0.004086117021243364, 'fc_dropout_flag_0': True, 'fc_dropout_rate_0': 0.3129558525155083, 'fc_activation_0': 'gelu', 'gcn_skip_connections_0': True, 'gcn_skip_connections_1': False, 'gcn_skip_connections_2': False, 'l1_lambda': 0.0008137831828275565, 'optimizer': 'SGD', 'momentum': 0.3846236238389149, 'lr_scheduler': 'ReduceLROnPlateau', 'factor': 0.20085248333354544, 'lr_patience': 40, 'lr_threshold': 0.008195213685529648, 'lr_eps': 6.70681429485255e-05, 'loss_function': 'CrossEntropy'}. Best is trial 2 with value: 0.8644859813084113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175, Loss: 7.0271, Accuracy: 0.5946, Test Loss: 1.2446, Test Accuracy: 0.6869\n",
      "Early stopping triggered\n",
      "Epoch 1, Loss: 3.1376, Accuracy: 0.6256, Test Loss: 0.1459, Test Accuracy: 0.7477\n",
      "Epoch 2, Loss: 1.7246, Accuracy: 0.7220, Test Loss: 0.1633, Test Accuracy: 0.7430\n",
      "Epoch 3, Loss: 1.1437, Accuracy: 0.7138, Test Loss: 0.1565, Test Accuracy: 0.7477\n",
      "Epoch 4, Loss: 0.8203, Accuracy: 0.7377, Test Loss: 0.1388, Test Accuracy: 0.7547\n",
      "Epoch 5, Loss: 0.6207, Accuracy: 0.7313, Test Loss: 0.1215, Test Accuracy: 0.7664\n",
      "Epoch 6, Loss: 0.4804, Accuracy: 0.7442, Test Loss: 0.1267, Test Accuracy: 0.7640\n",
      "Epoch 7, Loss: 0.3949, Accuracy: 0.7395, Test Loss: 0.1260, Test Accuracy: 0.7640\n",
      "Epoch 8, Loss: 0.3335, Accuracy: 0.7453, Test Loss: 0.1153, Test Accuracy: 0.7687\n",
      "Epoch 9, Loss: 0.3033, Accuracy: 0.7442, Test Loss: 0.1140, Test Accuracy: 0.7687\n",
      "Epoch 10, Loss: 0.2769, Accuracy: 0.7506, Test Loss: 0.1191, Test Accuracy: 0.7640\n",
      "Epoch 11, Loss: 0.2574, Accuracy: 0.7477, Test Loss: 0.1164, Test Accuracy: 0.7687\n",
      "Epoch 12, Loss: 0.2417, Accuracy: 0.7494, Test Loss: 0.1116, Test Accuracy: 0.7687\n",
      "Epoch 13, Loss: 0.2353, Accuracy: 0.7442, Test Loss: 0.1120, Test Accuracy: 0.7664\n",
      "Epoch 14, Loss: 0.2244, Accuracy: 0.7459, Test Loss: 0.1098, Test Accuracy: 0.7687\n",
      "Epoch 15, Loss: 0.2144, Accuracy: 0.7512, Test Loss: 0.1152, Test Accuracy: 0.7687\n",
      "Epoch 16, Loss: 0.2114, Accuracy: 0.7523, Test Loss: 0.1139, Test Accuracy: 0.7687\n",
      "Epoch 17, Loss: 0.2063, Accuracy: 0.7488, Test Loss: 0.1112, Test Accuracy: 0.7687\n",
      "Epoch 18, Loss: 0.2031, Accuracy: 0.7471, Test Loss: 0.1119, Test Accuracy: 0.7687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:13:00,603] Trial 5 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Loss: 0.1966, Accuracy: 0.7529, Test Loss: 0.1102, Test Accuracy: 0.7687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:13:01,671] Trial 6 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 3.0330, Accuracy: 0.3984, Test Loss: 1.3820, Test Accuracy: 0.4486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:13:02,175] Trial 7 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 4.3897, Accuracy: 0.4883, Test Loss: 0.3647, Test Accuracy: 0.3645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:13:03,342] Trial 8 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 3.4768, Accuracy: 0.0409, Test Loss: 1.8698, Test Accuracy: 0.0117\n",
      "Epoch 1, Loss: 2.6381, Accuracy: 0.4784, Test Loss: 0.5981, Test Accuracy: 0.5257\n",
      "Epoch 2, Loss: 1.9300, Accuracy: 0.5321, Test Loss: 0.4339, Test Accuracy: 0.5257\n",
      "Epoch 3, Loss: 1.3448, Accuracy: 0.5940, Test Loss: 0.5227, Test Accuracy: 0.6869\n",
      "Epoch 4, Loss: 0.8935, Accuracy: 0.6992, Test Loss: 0.3998, Test Accuracy: 0.6893\n",
      "Epoch 5, Loss: 0.6815, Accuracy: 0.7155, Test Loss: 0.4216, Test Accuracy: 0.6893\n",
      "Epoch 6, Loss: 0.5739, Accuracy: 0.7313, Test Loss: 0.3333, Test Accuracy: 0.7407\n",
      "Epoch 7, Loss: 0.4886, Accuracy: 0.7371, Test Loss: 0.3422, Test Accuracy: 0.7173\n",
      "Epoch 8, Loss: 0.4305, Accuracy: 0.7354, Test Loss: 0.2497, Test Accuracy: 0.7383\n",
      "Epoch 9, Loss: 0.3907, Accuracy: 0.7377, Test Loss: 0.1958, Test Accuracy: 0.7407\n",
      "Epoch 10, Loss: 0.3627, Accuracy: 0.7371, Test Loss: 0.1545, Test Accuracy: 0.7407\n",
      "Epoch 11, Loss: 0.3427, Accuracy: 0.7424, Test Loss: 0.1613, Test Accuracy: 0.7570\n",
      "Epoch 12, Loss: 0.3193, Accuracy: 0.7482, Test Loss: 0.1455, Test Accuracy: 0.7640\n",
      "Epoch 13, Loss: 0.3024, Accuracy: 0.7518, Test Loss: 0.1333, Test Accuracy: 0.7640\n",
      "Epoch 14, Loss: 0.2980, Accuracy: 0.7541, Test Loss: 0.1316, Test Accuracy: 0.7570\n",
      "Epoch 15, Loss: 0.2975, Accuracy: 0.7459, Test Loss: 0.1398, Test Accuracy: 0.7500\n",
      "Epoch 16, Loss: 0.2952, Accuracy: 0.7471, Test Loss: 0.1320, Test Accuracy: 0.7570\n",
      "Epoch 17, Loss: 0.2873, Accuracy: 0.7529, Test Loss: 0.1288, Test Accuracy: 0.7523\n",
      "Epoch 18, Loss: 0.2888, Accuracy: 0.7488, Test Loss: 0.1274, Test Accuracy: 0.7664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:13:16,053] Trial 9 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Loss: 0.2925, Accuracy: 0.7482, Test Loss: 0.1267, Test Accuracy: 0.7523\n",
      "Epoch 1, Loss: 1.5062, Accuracy: 0.6933, Test Loss: 0.6204, Test Accuracy: 0.7430\n",
      "Epoch 2, Loss: 1.0241, Accuracy: 0.7745, Test Loss: 0.5655, Test Accuracy: 0.7967\n",
      "Epoch 3, Loss: 0.8867, Accuracy: 0.7862, Test Loss: 0.5176, Test Accuracy: 0.8061\n",
      "Epoch 4, Loss: 0.8156, Accuracy: 0.7897, Test Loss: 0.5162, Test Accuracy: 0.8107\n",
      "Epoch 5, Loss: 0.7665, Accuracy: 0.7926, Test Loss: 0.5060, Test Accuracy: 0.8084\n",
      "Epoch 6, Loss: 0.7289, Accuracy: 0.8020, Test Loss: 0.5101, Test Accuracy: 0.8084\n",
      "Epoch 7, Loss: 0.6950, Accuracy: 0.8072, Test Loss: 0.4977, Test Accuracy: 0.7944\n",
      "Epoch 8, Loss: 0.6757, Accuracy: 0.8067, Test Loss: 0.4714, Test Accuracy: 0.8131\n",
      "Epoch 9, Loss: 0.6474, Accuracy: 0.8090, Test Loss: 0.4916, Test Accuracy: 0.8084\n",
      "Epoch 10, Loss: 0.6562, Accuracy: 0.8008, Test Loss: 0.5191, Test Accuracy: 0.8014\n",
      "Epoch 11, Loss: 0.6575, Accuracy: 0.8020, Test Loss: 0.4789, Test Accuracy: 0.8131\n",
      "Epoch 12, Loss: 0.6138, Accuracy: 0.8090, Test Loss: 0.4783, Test Accuracy: 0.8248\n",
      "Epoch 13, Loss: 0.6139, Accuracy: 0.8037, Test Loss: 0.4653, Test Accuracy: 0.8131\n",
      "Epoch 14, Loss: 0.5944, Accuracy: 0.8137, Test Loss: 0.4658, Test Accuracy: 0.8224\n",
      "Epoch 15, Loss: 0.6053, Accuracy: 0.8072, Test Loss: 0.4742, Test Accuracy: 0.8107\n",
      "Epoch 16, Loss: 0.6007, Accuracy: 0.8084, Test Loss: 0.4526, Test Accuracy: 0.8248\n",
      "Epoch 17, Loss: 0.5827, Accuracy: 0.8096, Test Loss: 0.4679, Test Accuracy: 0.8248\n",
      "Epoch 18, Loss: 0.5841, Accuracy: 0.8067, Test Loss: 0.5138, Test Accuracy: 0.8037\n",
      "Epoch 19, Loss: 0.5970, Accuracy: 0.8055, Test Loss: 0.4496, Test Accuracy: 0.8131\n",
      "Epoch 20, Loss: 0.5717, Accuracy: 0.8154, Test Loss: 0.4505, Test Accuracy: 0.8201\n",
      "Epoch 21, Loss: 0.5651, Accuracy: 0.8125, Test Loss: 0.4735, Test Accuracy: 0.8154\n",
      "Epoch 22, Loss: 0.5740, Accuracy: 0.8125, Test Loss: 0.4664, Test Accuracy: 0.8154\n",
      "Epoch 23, Loss: 0.5732, Accuracy: 0.8096, Test Loss: 0.4602, Test Accuracy: 0.8178\n",
      "Epoch 24, Loss: 0.5709, Accuracy: 0.8125, Test Loss: 0.4439, Test Accuracy: 0.8224\n",
      "Epoch 25, Loss: 0.5509, Accuracy: 0.8166, Test Loss: 0.4466, Test Accuracy: 0.8224\n",
      "Epoch 26, Loss: 0.5506, Accuracy: 0.8125, Test Loss: 0.4547, Test Accuracy: 0.8201\n",
      "Epoch 27, Loss: 0.5506, Accuracy: 0.8143, Test Loss: 0.4621, Test Accuracy: 0.8201\n",
      "Epoch 28, Loss: 0.5535, Accuracy: 0.8154, Test Loss: 0.4759, Test Accuracy: 0.8131\n",
      "Epoch 29, Loss: 0.5582, Accuracy: 0.8119, Test Loss: 0.4539, Test Accuracy: 0.8201\n",
      "Epoch 30, Loss: 0.5480, Accuracy: 0.8143, Test Loss: 0.4401, Test Accuracy: 0.8248\n",
      "Epoch 31, Loss: 0.5448, Accuracy: 0.8131, Test Loss: 0.4445, Test Accuracy: 0.8178\n",
      "Epoch 32, Loss: 0.5365, Accuracy: 0.8166, Test Loss: 0.4436, Test Accuracy: 0.8271\n",
      "Epoch 33, Loss: 0.5552, Accuracy: 0.8084, Test Loss: 0.4812, Test Accuracy: 0.8107\n",
      "Epoch 34, Loss: 0.5514, Accuracy: 0.8090, Test Loss: 0.4422, Test Accuracy: 0.8248\n",
      "Epoch 35, Loss: 0.5443, Accuracy: 0.8154, Test Loss: 0.4446, Test Accuracy: 0.8201\n",
      "Epoch 36, Loss: 0.5408, Accuracy: 0.8131, Test Loss: 0.4717, Test Accuracy: 0.8178\n",
      "Epoch 37, Loss: 0.5363, Accuracy: 0.8178, Test Loss: 0.4396, Test Accuracy: 0.8224\n",
      "Epoch 38, Loss: 0.5322, Accuracy: 0.8154, Test Loss: 0.4567, Test Accuracy: 0.8178\n",
      "Epoch 39, Loss: 0.5354, Accuracy: 0.8183, Test Loss: 0.4571, Test Accuracy: 0.8178\n",
      "Epoch 40, Loss: 0.5487, Accuracy: 0.8119, Test Loss: 0.4359, Test Accuracy: 0.8224\n",
      "Epoch 41, Loss: 0.5344, Accuracy: 0.8154, Test Loss: 0.4376, Test Accuracy: 0.8271\n",
      "Epoch 42, Loss: 0.5255, Accuracy: 0.8166, Test Loss: 0.4498, Test Accuracy: 0.8248\n",
      "Epoch 43, Loss: 0.5257, Accuracy: 0.8166, Test Loss: 0.4400, Test Accuracy: 0.8271\n",
      "Epoch 44, Loss: 0.5344, Accuracy: 0.8084, Test Loss: 0.4484, Test Accuracy: 0.8248\n",
      "Epoch 45, Loss: 0.5242, Accuracy: 0.8143, Test Loss: 0.4783, Test Accuracy: 0.8107\n",
      "Epoch 46, Loss: 0.5361, Accuracy: 0.8137, Test Loss: 0.4439, Test Accuracy: 0.8248\n",
      "Epoch 47, Loss: 0.5307, Accuracy: 0.8166, Test Loss: 0.4465, Test Accuracy: 0.8178\n",
      "Epoch 48, Loss: 0.5279, Accuracy: 0.8119, Test Loss: 0.4454, Test Accuracy: 0.8224\n",
      "Epoch 49, Loss: 0.5225, Accuracy: 0.8154, Test Loss: 0.4513, Test Accuracy: 0.8178\n",
      "Epoch 50, Loss: 0.5299, Accuracy: 0.8131, Test Loss: 0.4397, Test Accuracy: 0.8178\n",
      "Epoch 51, Loss: 0.5179, Accuracy: 0.8201, Test Loss: 0.4455, Test Accuracy: 0.8248\n",
      "Epoch 52, Loss: 0.5243, Accuracy: 0.8143, Test Loss: 0.4448, Test Accuracy: 0.8271\n",
      "Epoch 53, Loss: 0.5285, Accuracy: 0.8119, Test Loss: 0.4376, Test Accuracy: 0.8248\n",
      "Epoch 54, Loss: 0.5245, Accuracy: 0.8160, Test Loss: 0.4413, Test Accuracy: 0.8224\n",
      "Epoch 55, Loss: 0.5215, Accuracy: 0.8131, Test Loss: 0.4369, Test Accuracy: 0.8271\n",
      "Epoch 56, Loss: 0.5183, Accuracy: 0.8160, Test Loss: 0.4401, Test Accuracy: 0.8178\n",
      "Epoch 57, Loss: 0.5332, Accuracy: 0.8090, Test Loss: 0.4380, Test Accuracy: 0.8271\n",
      "Epoch 58, Loss: 0.5204, Accuracy: 0.8172, Test Loss: 0.4377, Test Accuracy: 0.8294\n",
      "Epoch 59, Loss: 0.5189, Accuracy: 0.8189, Test Loss: 0.4436, Test Accuracy: 0.8224\n",
      "Epoch 60, Loss: 0.5216, Accuracy: 0.8178, Test Loss: 0.4364, Test Accuracy: 0.8224\n",
      "Epoch 61, Loss: 0.5204, Accuracy: 0.8148, Test Loss: 0.4301, Test Accuracy: 0.8248\n",
      "Epoch 62, Loss: 0.5163, Accuracy: 0.8137, Test Loss: 0.4557, Test Accuracy: 0.8154\n",
      "Epoch 63, Loss: 0.5268, Accuracy: 0.8131, Test Loss: 0.4314, Test Accuracy: 0.8248\n",
      "Epoch 64, Loss: 0.5303, Accuracy: 0.8131, Test Loss: 0.4411, Test Accuracy: 0.8271\n",
      "Epoch 65, Loss: 0.5231, Accuracy: 0.8154, Test Loss: 0.4496, Test Accuracy: 0.8178\n",
      "Epoch 66, Loss: 0.5123, Accuracy: 0.8166, Test Loss: 0.4333, Test Accuracy: 0.8271\n",
      "Epoch 67, Loss: 0.5331, Accuracy: 0.8078, Test Loss: 0.4352, Test Accuracy: 0.8271\n",
      "Epoch 68, Loss: 0.5250, Accuracy: 0.8166, Test Loss: 0.4496, Test Accuracy: 0.8224\n",
      "Epoch 69, Loss: 0.5158, Accuracy: 0.8166, Test Loss: 0.4407, Test Accuracy: 0.8294\n",
      "Epoch 70, Loss: 0.5113, Accuracy: 0.8166, Test Loss: 0.4449, Test Accuracy: 0.8248\n",
      "Epoch 71, Loss: 0.5255, Accuracy: 0.8119, Test Loss: 0.4453, Test Accuracy: 0.8201\n",
      "Epoch 72, Loss: 0.5184, Accuracy: 0.8119, Test Loss: 0.4593, Test Accuracy: 0.8154\n",
      "Epoch 73, Loss: 0.5207, Accuracy: 0.8160, Test Loss: 0.4274, Test Accuracy: 0.8271\n",
      "Epoch 74, Loss: 0.5230, Accuracy: 0.8113, Test Loss: 0.4376, Test Accuracy: 0.8271\n",
      "Epoch 75, Loss: 0.5159, Accuracy: 0.8154, Test Loss: 0.4336, Test Accuracy: 0.8248\n",
      "Epoch 76, Loss: 0.5219, Accuracy: 0.8125, Test Loss: 0.4732, Test Accuracy: 0.8154\n",
      "Epoch 77, Loss: 0.5214, Accuracy: 0.8154, Test Loss: 0.4385, Test Accuracy: 0.8248\n",
      "Epoch 78, Loss: 0.5143, Accuracy: 0.8148, Test Loss: 0.4473, Test Accuracy: 0.8178\n",
      "Epoch 79, Loss: 0.5094, Accuracy: 0.8178, Test Loss: 0.4365, Test Accuracy: 0.8248\n",
      "Epoch 80, Loss: 0.5134, Accuracy: 0.8137, Test Loss: 0.4413, Test Accuracy: 0.8178\n",
      "Epoch 81, Loss: 0.5254, Accuracy: 0.8143, Test Loss: 0.4358, Test Accuracy: 0.8224\n",
      "Epoch 82, Loss: 0.5272, Accuracy: 0.8102, Test Loss: 0.4321, Test Accuracy: 0.8224\n",
      "Epoch 83, Loss: 0.5186, Accuracy: 0.8119, Test Loss: 0.4339, Test Accuracy: 0.8224\n",
      "Epoch 84, Loss: 0.5143, Accuracy: 0.8189, Test Loss: 0.4399, Test Accuracy: 0.8294\n",
      "Epoch 85, Loss: 0.5143, Accuracy: 0.8172, Test Loss: 0.4287, Test Accuracy: 0.8271\n",
      "Epoch 86, Loss: 0.5148, Accuracy: 0.8131, Test Loss: 0.4359, Test Accuracy: 0.8224\n",
      "Epoch 87, Loss: 0.5153, Accuracy: 0.8160, Test Loss: 0.4355, Test Accuracy: 0.8271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:15:14,409] Trial 10 finished with value: 0.8294392523364486 and parameters: {'batch_size': 32, 'num_gcn_layers': 1, 'gcn_hidden_dim_0': 52, 'num_fc_layers': 3, 'fc_hidden_dim_0': 99, 'fc_hidden_dim_1': 119, 'fc_hidden_dim_2': 50, 'learning_rate': 0.005080700826609854, 'weight_decay': 0.0002458205046390681, 'pooling_method': 'mean', 'gcn_batch_norm_flag_0': True, 'gcn_momentum_0': 0.41580738112482507, 'gcn_eps_0': 0.009517350018400187, 'gcn_dropout_flag_0': False, 'gcn_activation_0': 'leaky_relu', 'fc_batch_norm_flag_0': True, 'fc_batch_norm_flag_1': False, 'fc_batch_norm_flag_2': False, 'fc_momentum_0': 0.08835339007899273, 'fc_eps_0': 0.009432027565672435, 'fc_dropout_flag_0': True, 'fc_dropout_flag_1': False, 'fc_dropout_flag_2': False, 'fc_dropout_rate_0': 0.1017160671645902, 'fc_activation_0': 'elu', 'fc_activation_1': 'leaky_relu', 'fc_activation_2': 'leaky_relu', 'gcn_skip_connections_0': True, 'l1_lambda': 0.00053078654954103, 'optimizer': 'Adam', 'beta1': 0.8682482326621818, 'beta2': 0.9938363708726428, 'lr_scheduler': 'PolynomialLR', 'power': 0.14155967968671568, 'total_iters': 276, 'loss_function': 'CrossEntropy'}. Best is trial 2 with value: 0.8644859813084113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88, Loss: 0.5125, Accuracy: 0.8154, Test Loss: 0.4364, Test Accuracy: 0.8271\n",
      "Early stopping triggered\n",
      "Epoch 1, Loss: 1.2989, Accuracy: 0.7009, Test Loss: 0.8346, Test Accuracy: 0.7196\n",
      "Epoch 2, Loss: 0.9565, Accuracy: 0.7582, Test Loss: 0.5948, Test Accuracy: 0.7991\n",
      "Epoch 3, Loss: 0.8170, Accuracy: 0.7897, Test Loss: 0.5868, Test Accuracy: 0.7336\n",
      "Epoch 4, Loss: 0.7512, Accuracy: 0.7850, Test Loss: 0.6047, Test Accuracy: 0.7547\n",
      "Epoch 5, Loss: 0.7463, Accuracy: 0.7815, Test Loss: 0.8480, Test Accuracy: 0.6285\n",
      "Epoch 6, Loss: 0.6766, Accuracy: 0.7979, Test Loss: 0.5264, Test Accuracy: 0.7897\n",
      "Epoch 7, Loss: 0.6562, Accuracy: 0.8002, Test Loss: 0.4921, Test Accuracy: 0.8131\n",
      "Epoch 8, Loss: 0.6588, Accuracy: 0.7996, Test Loss: 0.5122, Test Accuracy: 0.8107\n",
      "Epoch 9, Loss: 0.6270, Accuracy: 0.7996, Test Loss: 0.4809, Test Accuracy: 0.8131\n",
      "Epoch 10, Loss: 0.6182, Accuracy: 0.8002, Test Loss: 0.4985, Test Accuracy: 0.8107\n",
      "Epoch 11, Loss: 0.6064, Accuracy: 0.8020, Test Loss: 0.4917, Test Accuracy: 0.8154\n",
      "Epoch 12, Loss: 0.5989, Accuracy: 0.7961, Test Loss: 0.5014, Test Accuracy: 0.8131\n",
      "Epoch 13, Loss: 0.5800, Accuracy: 0.8113, Test Loss: 0.4634, Test Accuracy: 0.8201\n",
      "Epoch 14, Loss: 0.5991, Accuracy: 0.8014, Test Loss: 0.4775, Test Accuracy: 0.8131\n",
      "Epoch 15, Loss: 0.5705, Accuracy: 0.8125, Test Loss: 0.4652, Test Accuracy: 0.8131\n",
      "Epoch 16, Loss: 0.5703, Accuracy: 0.8096, Test Loss: 0.4827, Test Accuracy: 0.7967\n",
      "Epoch 17, Loss: 0.5728, Accuracy: 0.8113, Test Loss: 0.4764, Test Accuracy: 0.8154\n",
      "Epoch 18, Loss: 0.5782, Accuracy: 0.8020, Test Loss: 0.4741, Test Accuracy: 0.8131\n",
      "Epoch 19, Loss: 0.5695, Accuracy: 0.8067, Test Loss: 0.5296, Test Accuracy: 0.7967\n",
      "Epoch 20, Loss: 0.5711, Accuracy: 0.8061, Test Loss: 0.4688, Test Accuracy: 0.8154\n",
      "Epoch 21, Loss: 0.5573, Accuracy: 0.8166, Test Loss: 0.4908, Test Accuracy: 0.8061\n",
      "Epoch 22, Loss: 0.5464, Accuracy: 0.8143, Test Loss: 0.4691, Test Accuracy: 0.8178\n",
      "Epoch 23, Loss: 0.5532, Accuracy: 0.8143, Test Loss: 0.4672, Test Accuracy: 0.8178\n",
      "Epoch 24, Loss: 0.5609, Accuracy: 0.8067, Test Loss: 0.4867, Test Accuracy: 0.8131\n",
      "Epoch 25, Loss: 0.5543, Accuracy: 0.8096, Test Loss: 0.4651, Test Accuracy: 0.8178\n",
      "Epoch 26, Loss: 0.5483, Accuracy: 0.8143, Test Loss: 0.5029, Test Accuracy: 0.8014\n",
      "Epoch 27, Loss: 0.5632, Accuracy: 0.8067, Test Loss: 0.5139, Test Accuracy: 0.7967\n",
      "Epoch 28, Loss: 0.5672, Accuracy: 0.8078, Test Loss: 0.4439, Test Accuracy: 0.8178\n",
      "Epoch 29, Loss: 0.5535, Accuracy: 0.8084, Test Loss: 0.4785, Test Accuracy: 0.8107\n",
      "Epoch 30, Loss: 0.5488, Accuracy: 0.8102, Test Loss: 0.4777, Test Accuracy: 0.8154\n",
      "Epoch 31, Loss: 0.5565, Accuracy: 0.8113, Test Loss: 0.4501, Test Accuracy: 0.8201\n",
      "Epoch 32, Loss: 0.5466, Accuracy: 0.8107, Test Loss: 0.4473, Test Accuracy: 0.8271\n",
      "Epoch 33, Loss: 0.5507, Accuracy: 0.8096, Test Loss: 0.4458, Test Accuracy: 0.8224\n",
      "Epoch 34, Loss: 0.5517, Accuracy: 0.8037, Test Loss: 0.4794, Test Accuracy: 0.8154\n",
      "Epoch 35, Loss: 0.5493, Accuracy: 0.8137, Test Loss: 0.4451, Test Accuracy: 0.8201\n",
      "Epoch 36, Loss: 0.5665, Accuracy: 0.8107, Test Loss: 0.4589, Test Accuracy: 0.8154\n",
      "Epoch 37, Loss: 0.5496, Accuracy: 0.8107, Test Loss: 0.4522, Test Accuracy: 0.8248\n",
      "Epoch 38, Loss: 0.5375, Accuracy: 0.8113, Test Loss: 0.4595, Test Accuracy: 0.8201\n",
      "Epoch 39, Loss: 0.5411, Accuracy: 0.8102, Test Loss: 0.4504, Test Accuracy: 0.8178\n",
      "Epoch 40, Loss: 0.5349, Accuracy: 0.8113, Test Loss: 0.4828, Test Accuracy: 0.8154\n",
      "Epoch 41, Loss: 0.5395, Accuracy: 0.8154, Test Loss: 0.5341, Test Accuracy: 0.8061\n",
      "Epoch 42, Loss: 0.5538, Accuracy: 0.8107, Test Loss: 0.4799, Test Accuracy: 0.8154\n",
      "Epoch 43, Loss: 0.5478, Accuracy: 0.8137, Test Loss: 0.4754, Test Accuracy: 0.8224\n",
      "Epoch 44, Loss: 0.5465, Accuracy: 0.8125, Test Loss: 0.5908, Test Accuracy: 0.7430\n",
      "Epoch 45, Loss: 0.5398, Accuracy: 0.8125, Test Loss: 0.4461, Test Accuracy: 0.8248\n",
      "Epoch 46, Loss: 0.5463, Accuracy: 0.8067, Test Loss: 0.4581, Test Accuracy: 0.8248\n",
      "Epoch 47, Loss: 0.5343, Accuracy: 0.8137, Test Loss: 0.4542, Test Accuracy: 0.8178\n",
      "Epoch 48, Loss: 0.5308, Accuracy: 0.8125, Test Loss: 0.4464, Test Accuracy: 0.8224\n",
      "Epoch 49, Loss: 0.5406, Accuracy: 0.8137, Test Loss: 0.4517, Test Accuracy: 0.8178\n",
      "Epoch 50, Loss: 0.5341, Accuracy: 0.8154, Test Loss: 0.4755, Test Accuracy: 0.8084\n",
      "Epoch 51, Loss: 0.5427, Accuracy: 0.8084, Test Loss: 0.4481, Test Accuracy: 0.8131\n",
      "Epoch 52, Loss: 0.5427, Accuracy: 0.8102, Test Loss: 0.4626, Test Accuracy: 0.8224\n",
      "Epoch 53, Loss: 0.5454, Accuracy: 0.8090, Test Loss: 0.4532, Test Accuracy: 0.8178\n",
      "Epoch 54, Loss: 0.5436, Accuracy: 0.8119, Test Loss: 0.4547, Test Accuracy: 0.8178\n",
      "Epoch 55, Loss: 0.5412, Accuracy: 0.8084, Test Loss: 0.5599, Test Accuracy: 0.7897\n",
      "Epoch 56, Loss: 0.5543, Accuracy: 0.8043, Test Loss: 0.4611, Test Accuracy: 0.8154\n",
      "Epoch 57, Loss: 0.5298, Accuracy: 0.8143, Test Loss: 0.4533, Test Accuracy: 0.8271\n",
      "Epoch 58, Loss: 0.5373, Accuracy: 0.8160, Test Loss: 0.5944, Test Accuracy: 0.7664\n",
      "Epoch 59, Loss: 0.5482, Accuracy: 0.8102, Test Loss: 0.5039, Test Accuracy: 0.8107\n",
      "Epoch 60, Loss: 0.5363, Accuracy: 0.8125, Test Loss: 0.4425, Test Accuracy: 0.8294\n",
      "Epoch 61, Loss: 0.5418, Accuracy: 0.8113, Test Loss: 0.4621, Test Accuracy: 0.8154\n",
      "Epoch 62, Loss: 0.5274, Accuracy: 0.8113, Test Loss: 0.4614, Test Accuracy: 0.8154\n",
      "Epoch 63, Loss: 0.5344, Accuracy: 0.8119, Test Loss: 0.4621, Test Accuracy: 0.8224\n",
      "Epoch 64, Loss: 0.5270, Accuracy: 0.8119, Test Loss: 0.4567, Test Accuracy: 0.8248\n",
      "Epoch 65, Loss: 0.5307, Accuracy: 0.8119, Test Loss: 0.4600, Test Accuracy: 0.8131\n",
      "Epoch 66, Loss: 0.5188, Accuracy: 0.8166, Test Loss: 0.4445, Test Accuracy: 0.8201\n",
      "Epoch 67, Loss: 0.5408, Accuracy: 0.8090, Test Loss: 0.4740, Test Accuracy: 0.8154\n",
      "Epoch 68, Loss: 0.5667, Accuracy: 0.8020, Test Loss: 0.5079, Test Accuracy: 0.7944\n",
      "Epoch 69, Loss: 0.5768, Accuracy: 0.7926, Test Loss: 0.4775, Test Accuracy: 0.8037\n",
      "Epoch 70, Loss: 0.5455, Accuracy: 0.8119, Test Loss: 0.4629, Test Accuracy: 0.8201\n",
      "Epoch 71, Loss: 0.5467, Accuracy: 0.8107, Test Loss: 0.4480, Test Accuracy: 0.8224\n",
      "Epoch 72, Loss: 0.5384, Accuracy: 0.8107, Test Loss: 0.4420, Test Accuracy: 0.8224\n",
      "Epoch 73, Loss: 0.5239, Accuracy: 0.8172, Test Loss: 0.4397, Test Accuracy: 0.8248\n",
      "Epoch 74, Loss: 0.5418, Accuracy: 0.8131, Test Loss: 0.4700, Test Accuracy: 0.8154\n",
      "Epoch 75, Loss: 0.5231, Accuracy: 0.8143, Test Loss: 0.4493, Test Accuracy: 0.8178\n",
      "Epoch 76, Loss: 0.5686, Accuracy: 0.8014, Test Loss: 0.4542, Test Accuracy: 0.8178\n",
      "Epoch 77, Loss: 0.5439, Accuracy: 0.8119, Test Loss: 0.4428, Test Accuracy: 0.8201\n",
      "Epoch 78, Loss: 0.5310, Accuracy: 0.8143, Test Loss: 0.4661, Test Accuracy: 0.8154\n",
      "Epoch 79, Loss: 0.5305, Accuracy: 0.8166, Test Loss: 0.4532, Test Accuracy: 0.8178\n",
      "Epoch 80, Loss: 0.5307, Accuracy: 0.8125, Test Loss: 0.4421, Test Accuracy: 0.8201\n",
      "Epoch 81, Loss: 0.5356, Accuracy: 0.8107, Test Loss: 0.4514, Test Accuracy: 0.8178\n",
      "Epoch 82, Loss: 0.5317, Accuracy: 0.8154, Test Loss: 0.4460, Test Accuracy: 0.8201\n",
      "Epoch 83, Loss: 0.5263, Accuracy: 0.8148, Test Loss: 0.4559, Test Accuracy: 0.8248\n",
      "Epoch 84, Loss: 0.5232, Accuracy: 0.8125, Test Loss: 0.4436, Test Accuracy: 0.8201\n",
      "Epoch 85, Loss: 0.5186, Accuracy: 0.8172, Test Loss: 0.4482, Test Accuracy: 0.8178\n",
      "Epoch 86, Loss: 0.5244, Accuracy: 0.8154, Test Loss: 0.4576, Test Accuracy: 0.8178\n",
      "Epoch 87, Loss: 0.5365, Accuracy: 0.8107, Test Loss: 0.4648, Test Accuracy: 0.8061\n",
      "Epoch 88, Loss: 0.5343, Accuracy: 0.8125, Test Loss: 0.4613, Test Accuracy: 0.8201\n",
      "Epoch 89, Loss: 0.5217, Accuracy: 0.8131, Test Loss: 0.4528, Test Accuracy: 0.8224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:17:10,090] Trial 11 finished with value: 0.8294392523364486 and parameters: {'batch_size': 32, 'num_gcn_layers': 1, 'gcn_hidden_dim_0': 32, 'num_fc_layers': 3, 'fc_hidden_dim_0': 94, 'fc_hidden_dim_1': 118, 'fc_hidden_dim_2': 51, 'learning_rate': 0.009818544133289853, 'weight_decay': 0.0002730304509509354, 'pooling_method': 'mean', 'gcn_batch_norm_flag_0': True, 'gcn_momentum_0': 0.4125932810017344, 'gcn_eps_0': 0.009250262657374055, 'gcn_dropout_flag_0': False, 'gcn_activation_0': 'leaky_relu', 'fc_batch_norm_flag_0': True, 'fc_batch_norm_flag_1': False, 'fc_batch_norm_flag_2': False, 'fc_momentum_0': 0.020339231571934804, 'fc_eps_0': 0.009995206800259532, 'fc_dropout_flag_0': True, 'fc_dropout_flag_1': False, 'fc_dropout_flag_2': False, 'fc_dropout_rate_0': 0.12353720886458663, 'fc_activation_0': 'elu', 'fc_activation_1': 'leaky_relu', 'fc_activation_2': 'leaky_relu', 'gcn_skip_connections_0': True, 'l1_lambda': 0.00047278424722835326, 'optimizer': 'Adam', 'beta1': 0.8527910804304493, 'beta2': 0.9988127614069698, 'lr_scheduler': 'PolynomialLR', 'power': 0.10278876522774633, 'total_iters': 282, 'loss_function': 'CrossEntropy'}. Best is trial 2 with value: 0.8644859813084113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90, Loss: 0.5159, Accuracy: 0.8207, Test Loss: 0.4524, Test Accuracy: 0.8178\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:17:11,820] Trial 12 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.8644, Accuracy: 0.6893, Test Loss: 0.8698, Test Accuracy: 0.6939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:17:15,082] Trial 13 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 4.6795, Accuracy: 0.3727, Test Loss: 1.3336, Test Accuracy: 0.6612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:17:18,353] Trial 14 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 4.0318, Accuracy: 0.6998, Test Loss: 1.1308, Test Accuracy: 0.6682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:17:19,427] Trial 15 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.2521, Accuracy: 0.6268, Test Loss: 0.9800, Test Accuracy: 0.6893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:17:22,787] Trial 16 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.0760, Accuracy: 0.7319, Test Loss: 0.7172, Test Accuracy: 0.6963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:17:24,807] Trial 17 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 4.8406, Accuracy: 0.0794, Test Loss: 1.7881, Test Accuracy: 0.0350\n",
      "Epoch 1, Loss: 2.7002, Accuracy: 0.6828, Test Loss: 0.7099, Test Accuracy: 0.7500\n",
      "Epoch 2, Loss: 1.6967, Accuracy: 0.7103, Test Loss: 0.6833, Test Accuracy: 0.7383\n",
      "Epoch 3, Loss: 1.6760, Accuracy: 0.6974, Test Loss: 0.7253, Test Accuracy: 0.7407\n",
      "Epoch 4, Loss: 1.5382, Accuracy: 0.7196, Test Loss: 1.5446, Test Accuracy: 0.4439\n",
      "Epoch 5, Loss: 1.5341, Accuracy: 0.7190, Test Loss: 0.7317, Test Accuracy: 0.7243\n",
      "Epoch 6, Loss: 1.8902, Accuracy: 0.7155, Test Loss: 3.4482, Test Accuracy: 0.3551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:17:43,706] Trial 18 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 2.6303, Accuracy: 0.6840, Test Loss: 8.7767, Test Accuracy: 0.4089\n",
      "Epoch 1, Loss: 2.4671, Accuracy: 0.5502, Test Loss: 0.8021, Test Accuracy: 0.7383\n",
      "Epoch 2, Loss: 1.7977, Accuracy: 0.7377, Test Loss: 0.6093, Test Accuracy: 0.7593\n",
      "Epoch 3, Loss: 1.6969, Accuracy: 0.7815, Test Loss: 0.5888, Test Accuracy: 0.7290\n",
      "Epoch 4, Loss: 1.7174, Accuracy: 0.7786, Test Loss: 0.6492, Test Accuracy: 0.7734\n",
      "Epoch 5, Loss: 1.6958, Accuracy: 0.8002, Test Loss: 0.5874, Test Accuracy: 0.7827\n",
      "Epoch 6, Loss: 1.6790, Accuracy: 0.7926, Test Loss: 0.5376, Test Accuracy: 0.7687\n",
      "Epoch 7, Loss: 1.6492, Accuracy: 0.7810, Test Loss: 0.5439, Test Accuracy: 0.8084\n",
      "Epoch 8, Loss: 1.6007, Accuracy: 0.8026, Test Loss: 0.5246, Test Accuracy: 0.7967\n",
      "Epoch 9, Loss: 1.5426, Accuracy: 0.8014, Test Loss: 0.5387, Test Accuracy: 0.8061\n",
      "Epoch 10, Loss: 1.5255, Accuracy: 0.8067, Test Loss: 0.5055, Test Accuracy: 0.8061\n",
      "Epoch 11, Loss: 1.4688, Accuracy: 0.8049, Test Loss: 0.5035, Test Accuracy: 0.8061\n",
      "Epoch 12, Loss: 1.4215, Accuracy: 0.8055, Test Loss: 0.5042, Test Accuracy: 0.8084\n",
      "Epoch 13, Loss: 1.3634, Accuracy: 0.8096, Test Loss: 0.4974, Test Accuracy: 0.8084\n",
      "Epoch 14, Loss: 1.3131, Accuracy: 0.8090, Test Loss: 0.4870, Test Accuracy: 0.8084\n",
      "Epoch 15, Loss: 1.2659, Accuracy: 0.8131, Test Loss: 0.4873, Test Accuracy: 0.8107\n",
      "Epoch 16, Loss: 1.2269, Accuracy: 0.8148, Test Loss: 0.4973, Test Accuracy: 0.8131\n",
      "Epoch 17, Loss: 1.1967, Accuracy: 0.8183, Test Loss: 0.4749, Test Accuracy: 0.8201\n",
      "Epoch 18, Loss: 1.1597, Accuracy: 0.8148, Test Loss: 0.4778, Test Accuracy: 0.8224\n",
      "Epoch 19, Loss: 1.1260, Accuracy: 0.8189, Test Loss: 0.4687, Test Accuracy: 0.8131\n",
      "Epoch 20, Loss: 1.1007, Accuracy: 0.8119, Test Loss: 0.4742, Test Accuracy: 0.8178\n",
      "Epoch 21, Loss: 1.0860, Accuracy: 0.8137, Test Loss: 0.4759, Test Accuracy: 0.8178\n",
      "Epoch 22, Loss: 1.0644, Accuracy: 0.8154, Test Loss: 0.4739, Test Accuracy: 0.8178\n",
      "Epoch 23, Loss: 1.0275, Accuracy: 0.8160, Test Loss: 0.4994, Test Accuracy: 0.8154\n",
      "Epoch 24, Loss: 1.0200, Accuracy: 0.8143, Test Loss: 0.4596, Test Accuracy: 0.8201\n",
      "Epoch 25, Loss: 0.9851, Accuracy: 0.8119, Test Loss: 0.4507, Test Accuracy: 0.8201\n",
      "Epoch 26, Loss: 0.9621, Accuracy: 0.8189, Test Loss: 0.4636, Test Accuracy: 0.8178\n",
      "Epoch 27, Loss: 0.9416, Accuracy: 0.8189, Test Loss: 0.4764, Test Accuracy: 0.8178\n",
      "Epoch 28, Loss: 0.9225, Accuracy: 0.8166, Test Loss: 0.4682, Test Accuracy: 0.8131\n",
      "Epoch 29, Loss: 0.9063, Accuracy: 0.8189, Test Loss: 0.4643, Test Accuracy: 0.8201\n",
      "Epoch 30, Loss: 0.8864, Accuracy: 0.8178, Test Loss: 0.4663, Test Accuracy: 0.8248\n",
      "Epoch 31, Loss: 0.8716, Accuracy: 0.8172, Test Loss: 0.4627, Test Accuracy: 0.8178\n",
      "Epoch 32, Loss: 0.8590, Accuracy: 0.8172, Test Loss: 0.4611, Test Accuracy: 0.8248\n",
      "Epoch 33, Loss: 0.8405, Accuracy: 0.8189, Test Loss: 0.4642, Test Accuracy: 0.8224\n",
      "Epoch 34, Loss: 0.8177, Accuracy: 0.8218, Test Loss: 0.4651, Test Accuracy: 0.8154\n",
      "Epoch 35, Loss: 0.8005, Accuracy: 0.8236, Test Loss: 0.4686, Test Accuracy: 0.8084\n",
      "Epoch 36, Loss: 0.7834, Accuracy: 0.8207, Test Loss: 0.4768, Test Accuracy: 0.8084\n",
      "Epoch 37, Loss: 0.7690, Accuracy: 0.8236, Test Loss: 0.4654, Test Accuracy: 0.8131\n",
      "Epoch 38, Loss: 0.7563, Accuracy: 0.8242, Test Loss: 0.4523, Test Accuracy: 0.8248\n",
      "Epoch 39, Loss: 0.7437, Accuracy: 0.8207, Test Loss: 0.4655, Test Accuracy: 0.8248\n",
      "Epoch 40, Loss: 0.7329, Accuracy: 0.8254, Test Loss: 0.4498, Test Accuracy: 0.8294\n",
      "Epoch 41, Loss: 0.7239, Accuracy: 0.8230, Test Loss: 0.4520, Test Accuracy: 0.8131\n",
      "Epoch 42, Loss: 0.7148, Accuracy: 0.8207, Test Loss: 0.4433, Test Accuracy: 0.8224\n",
      "Epoch 43, Loss: 0.6990, Accuracy: 0.8248, Test Loss: 0.4615, Test Accuracy: 0.8178\n",
      "Epoch 44, Loss: 0.6900, Accuracy: 0.8218, Test Loss: 0.4719, Test Accuracy: 0.8061\n",
      "Epoch 45, Loss: 0.6756, Accuracy: 0.8224, Test Loss: 0.4661, Test Accuracy: 0.8131\n",
      "Epoch 46, Loss: 0.6733, Accuracy: 0.8254, Test Loss: 0.4702, Test Accuracy: 0.8201\n",
      "Epoch 47, Loss: 0.6755, Accuracy: 0.8189, Test Loss: 0.4594, Test Accuracy: 0.8201\n",
      "Epoch 48, Loss: 0.6625, Accuracy: 0.8207, Test Loss: 0.4570, Test Accuracy: 0.8248\n",
      "Epoch 49, Loss: 0.6434, Accuracy: 0.8271, Test Loss: 0.4668, Test Accuracy: 0.8154\n",
      "Epoch 50, Loss: 0.6388, Accuracy: 0.8259, Test Loss: 0.4618, Test Accuracy: 0.8248\n",
      "Epoch 51, Loss: 0.6369, Accuracy: 0.8218, Test Loss: 0.4519, Test Accuracy: 0.8224\n",
      "Epoch 52, Loss: 0.6277, Accuracy: 0.8265, Test Loss: 0.4626, Test Accuracy: 0.8131\n",
      "Epoch 53, Loss: 0.6210, Accuracy: 0.8248, Test Loss: 0.4626, Test Accuracy: 0.8178\n",
      "Epoch 54, Loss: 0.6092, Accuracy: 0.8254, Test Loss: 0.4692, Test Accuracy: 0.8037\n",
      "Epoch 55, Loss: 0.6033, Accuracy: 0.8242, Test Loss: 0.4523, Test Accuracy: 0.8248\n",
      "Epoch 56, Loss: 0.6043, Accuracy: 0.8248, Test Loss: 0.4495, Test Accuracy: 0.8201\n",
      "Epoch 57, Loss: 0.5979, Accuracy: 0.8248, Test Loss: 0.4555, Test Accuracy: 0.8294\n",
      "Epoch 58, Loss: 0.5890, Accuracy: 0.8324, Test Loss: 0.4775, Test Accuracy: 0.7991\n",
      "Epoch 59, Loss: 0.5875, Accuracy: 0.8218, Test Loss: 0.4729, Test Accuracy: 0.8271\n",
      "Epoch 60, Loss: 0.5797, Accuracy: 0.8236, Test Loss: 0.4612, Test Accuracy: 0.8131\n",
      "Epoch 61, Loss: 0.5751, Accuracy: 0.8294, Test Loss: 0.4572, Test Accuracy: 0.8154\n",
      "Epoch 62, Loss: 0.5725, Accuracy: 0.8236, Test Loss: 0.4620, Test Accuracy: 0.8271\n",
      "Epoch 63, Loss: 0.5605, Accuracy: 0.8289, Test Loss: 0.4734, Test Accuracy: 0.8061\n",
      "Epoch 64, Loss: 0.5645, Accuracy: 0.8242, Test Loss: 0.4712, Test Accuracy: 0.8201\n",
      "Epoch 65, Loss: 0.5604, Accuracy: 0.8236, Test Loss: 0.4578, Test Accuracy: 0.8084\n",
      "Epoch 66, Loss: 0.5595, Accuracy: 0.8318, Test Loss: 0.4600, Test Accuracy: 0.8131\n",
      "Epoch 67, Loss: 0.5612, Accuracy: 0.8218, Test Loss: 0.4793, Test Accuracy: 0.7897\n",
      "Epoch 68, Loss: 0.5587, Accuracy: 0.8265, Test Loss: 0.4609, Test Accuracy: 0.8201\n",
      "Epoch 69, Loss: 0.5531, Accuracy: 0.8289, Test Loss: 0.4703, Test Accuracy: 0.8131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:18:17,948] Trial 19 finished with value: 0.8294392523364486 and parameters: {'batch_size': 256, 'num_gcn_layers': 1, 'gcn_hidden_dim_0': 107, 'num_fc_layers': 2, 'fc_hidden_dim_0': 177, 'fc_hidden_dim_1': 223, 'learning_rate': 0.00913903429808127, 'weight_decay': 0.00039342099653808703, 'pooling_method': 'add', 'gcn_batch_norm_flag_0': True, 'gcn_momentum_0': 0.9422732911648466, 'gcn_eps_0': 0.005953801699116162, 'gcn_dropout_flag_0': False, 'gcn_activation_0': 'elu', 'fc_batch_norm_flag_0': False, 'fc_batch_norm_flag_1': False, 'fc_dropout_flag_0': False, 'fc_dropout_flag_1': False, 'fc_activation_0': 'leaky_relu', 'fc_activation_1': 'relu', 'gcn_skip_connections_0': True, 'l1_lambda': 0.00036794083655299526, 'optimizer': 'Adam', 'beta1': 0.9873755210369288, 'beta2': 0.9661475509343214, 'lr_scheduler': 'PolynomialLR', 'power': 0.49541974115695486, 'total_iters': 193, 'loss_function': 'CrossEntropy'}. Best is trial 2 with value: 0.8644859813084113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70, Loss: 0.5428, Accuracy: 0.8289, Test Loss: 0.4773, Test Accuracy: 0.8107\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:18:20,118] Trial 20 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 4.1580, Accuracy: 0.0754, Test Loss: 1.7932, Test Accuracy: 0.0958\n",
      "Epoch 1, Loss: 1.2886, Accuracy: 0.7074, Test Loss: 0.6443, Test Accuracy: 0.7523\n",
      "Epoch 2, Loss: 0.8758, Accuracy: 0.7839, Test Loss: 0.5875, Test Accuracy: 0.7290\n",
      "Epoch 3, Loss: 0.7727, Accuracy: 0.7926, Test Loss: 0.5091, Test Accuracy: 0.8107\n",
      "Epoch 4, Loss: 0.7291, Accuracy: 0.7956, Test Loss: 0.5477, Test Accuracy: 0.8084\n",
      "Epoch 5, Loss: 0.7018, Accuracy: 0.7956, Test Loss: 0.5013, Test Accuracy: 0.8107\n",
      "Epoch 6, Loss: 0.6808, Accuracy: 0.7961, Test Loss: 0.5018, Test Accuracy: 0.7944\n",
      "Epoch 7, Loss: 0.6551, Accuracy: 0.8049, Test Loss: 0.4936, Test Accuracy: 0.8107\n",
      "Epoch 8, Loss: 0.6344, Accuracy: 0.7991, Test Loss: 0.4919, Test Accuracy: 0.8107\n",
      "Epoch 9, Loss: 0.6172, Accuracy: 0.8032, Test Loss: 0.4779, Test Accuracy: 0.8154\n",
      "Epoch 10, Loss: 0.6133, Accuracy: 0.8055, Test Loss: 0.4768, Test Accuracy: 0.8131\n",
      "Epoch 11, Loss: 0.6288, Accuracy: 0.7938, Test Loss: 0.4876, Test Accuracy: 0.8107\n",
      "Epoch 12, Loss: 0.5964, Accuracy: 0.8113, Test Loss: 0.5027, Test Accuracy: 0.8107\n",
      "Epoch 13, Loss: 0.5908, Accuracy: 0.8067, Test Loss: 0.4913, Test Accuracy: 0.8107\n",
      "Epoch 14, Loss: 0.5710, Accuracy: 0.8131, Test Loss: 0.4774, Test Accuracy: 0.8107\n",
      "Epoch 15, Loss: 0.5694, Accuracy: 0.8090, Test Loss: 0.4917, Test Accuracy: 0.8154\n",
      "Epoch 16, Loss: 0.5629, Accuracy: 0.8043, Test Loss: 0.4818, Test Accuracy: 0.8014\n",
      "Epoch 17, Loss: 0.5794, Accuracy: 0.8072, Test Loss: 0.4578, Test Accuracy: 0.8178\n",
      "Epoch 18, Loss: 0.5517, Accuracy: 0.8137, Test Loss: 0.4739, Test Accuracy: 0.8131\n",
      "Epoch 19, Loss: 0.5857, Accuracy: 0.8020, Test Loss: 0.4961, Test Accuracy: 0.8037\n",
      "Epoch 20, Loss: 0.5714, Accuracy: 0.8049, Test Loss: 0.4820, Test Accuracy: 0.8061\n",
      "Epoch 21, Loss: 0.5664, Accuracy: 0.8084, Test Loss: 0.4784, Test Accuracy: 0.8131\n",
      "Epoch 22, Loss: 0.5571, Accuracy: 0.8113, Test Loss: 0.4670, Test Accuracy: 0.8131\n",
      "Epoch 23, Loss: 0.5679, Accuracy: 0.8037, Test Loss: 0.4639, Test Accuracy: 0.8178\n",
      "Epoch 24, Loss: 0.5707, Accuracy: 0.8055, Test Loss: 0.4652, Test Accuracy: 0.8178\n",
      "Epoch 25, Loss: 0.5635, Accuracy: 0.8084, Test Loss: 0.4841, Test Accuracy: 0.8154\n",
      "Epoch 26, Loss: 0.5541, Accuracy: 0.8125, Test Loss: 0.4499, Test Accuracy: 0.8178\n",
      "Epoch 27, Loss: 0.5468, Accuracy: 0.8137, Test Loss: 0.4720, Test Accuracy: 0.8248\n",
      "Epoch 28, Loss: 0.5645, Accuracy: 0.8102, Test Loss: 0.4629, Test Accuracy: 0.8154\n",
      "Epoch 29, Loss: 0.5427, Accuracy: 0.8119, Test Loss: 0.5046, Test Accuracy: 0.7944\n",
      "Epoch 30, Loss: 0.5459, Accuracy: 0.8107, Test Loss: 0.4702, Test Accuracy: 0.8154\n",
      "Epoch 31, Loss: 0.5424, Accuracy: 0.8107, Test Loss: 0.4614, Test Accuracy: 0.8224\n",
      "Epoch 32, Loss: 0.5472, Accuracy: 0.8143, Test Loss: 0.4447, Test Accuracy: 0.8201\n",
      "Epoch 33, Loss: 0.5417, Accuracy: 0.8096, Test Loss: 0.4541, Test Accuracy: 0.8248\n",
      "Epoch 34, Loss: 0.5415, Accuracy: 0.8148, Test Loss: 0.4557, Test Accuracy: 0.8224\n",
      "Epoch 35, Loss: 0.5448, Accuracy: 0.8090, Test Loss: 0.4518, Test Accuracy: 0.8178\n",
      "Epoch 36, Loss: 0.5349, Accuracy: 0.8102, Test Loss: 0.4778, Test Accuracy: 0.8224\n",
      "Epoch 37, Loss: 0.5366, Accuracy: 0.8119, Test Loss: 0.4464, Test Accuracy: 0.8178\n",
      "Epoch 38, Loss: 0.5382, Accuracy: 0.8113, Test Loss: 0.4399, Test Accuracy: 0.8294\n",
      "Epoch 39, Loss: 0.5502, Accuracy: 0.8049, Test Loss: 0.4427, Test Accuracy: 0.8271\n",
      "Epoch 40, Loss: 0.5430, Accuracy: 0.8072, Test Loss: 0.4664, Test Accuracy: 0.8131\n",
      "Epoch 41, Loss: 0.5388, Accuracy: 0.8107, Test Loss: 0.4524, Test Accuracy: 0.8201\n",
      "Epoch 42, Loss: 0.5373, Accuracy: 0.8125, Test Loss: 0.4481, Test Accuracy: 0.8248\n",
      "Epoch 43, Loss: 0.5378, Accuracy: 0.8148, Test Loss: 0.4719, Test Accuracy: 0.8271\n",
      "Epoch 44, Loss: 0.5319, Accuracy: 0.8166, Test Loss: 0.4479, Test Accuracy: 0.8224\n",
      "Epoch 45, Loss: 0.5318, Accuracy: 0.8125, Test Loss: 0.4484, Test Accuracy: 0.8178\n",
      "Epoch 46, Loss: 0.5359, Accuracy: 0.8102, Test Loss: 0.4410, Test Accuracy: 0.8248\n",
      "Epoch 47, Loss: 0.5272, Accuracy: 0.8154, Test Loss: 0.4596, Test Accuracy: 0.8201\n",
      "Epoch 48, Loss: 0.5247, Accuracy: 0.8148, Test Loss: 0.4349, Test Accuracy: 0.8224\n",
      "Epoch 49, Loss: 0.5260, Accuracy: 0.8148, Test Loss: 0.4670, Test Accuracy: 0.8271\n",
      "Epoch 50, Loss: 0.5337, Accuracy: 0.8125, Test Loss: 0.4430, Test Accuracy: 0.8178\n",
      "Epoch 51, Loss: 0.5221, Accuracy: 0.8154, Test Loss: 0.4508, Test Accuracy: 0.8107\n",
      "Epoch 52, Loss: 0.5278, Accuracy: 0.8131, Test Loss: 0.4794, Test Accuracy: 0.7967\n",
      "Epoch 53, Loss: 0.5313, Accuracy: 0.8131, Test Loss: 0.4617, Test Accuracy: 0.8178\n",
      "Epoch 54, Loss: 0.5305, Accuracy: 0.8119, Test Loss: 0.4349, Test Accuracy: 0.8201\n",
      "Epoch 55, Loss: 0.5226, Accuracy: 0.8172, Test Loss: 0.4410, Test Accuracy: 0.8178\n",
      "Epoch 56, Loss: 0.5336, Accuracy: 0.8137, Test Loss: 0.4607, Test Accuracy: 0.8248\n",
      "Epoch 57, Loss: 0.5250, Accuracy: 0.8143, Test Loss: 0.4466, Test Accuracy: 0.8224\n",
      "Epoch 58, Loss: 0.5511, Accuracy: 0.7991, Test Loss: 0.4558, Test Accuracy: 0.8201\n",
      "Epoch 59, Loss: 0.5433, Accuracy: 0.8084, Test Loss: 0.4413, Test Accuracy: 0.8224\n",
      "Epoch 60, Loss: 0.5291, Accuracy: 0.8131, Test Loss: 0.4523, Test Accuracy: 0.8294\n",
      "Epoch 61, Loss: 0.5304, Accuracy: 0.8166, Test Loss: 0.4384, Test Accuracy: 0.8294\n",
      "Epoch 62, Loss: 0.5230, Accuracy: 0.8119, Test Loss: 0.4408, Test Accuracy: 0.8248\n",
      "Epoch 63, Loss: 0.5162, Accuracy: 0.8160, Test Loss: 0.4919, Test Accuracy: 0.8154\n",
      "Epoch 64, Loss: 0.5313, Accuracy: 0.8119, Test Loss: 0.4368, Test Accuracy: 0.8294\n",
      "Epoch 65, Loss: 0.5188, Accuracy: 0.8160, Test Loss: 0.4467, Test Accuracy: 0.8248\n",
      "Epoch 66, Loss: 0.5250, Accuracy: 0.8131, Test Loss: 0.4368, Test Accuracy: 0.8224\n",
      "Epoch 67, Loss: 0.5318, Accuracy: 0.8160, Test Loss: 0.4585, Test Accuracy: 0.8201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:19:48,782] Trial 21 finished with value: 0.8294392523364486 and parameters: {'batch_size': 32, 'num_gcn_layers': 1, 'gcn_hidden_dim_0': 32, 'num_fc_layers': 3, 'fc_hidden_dim_0': 91, 'fc_hidden_dim_1': 125, 'fc_hidden_dim_2': 41, 'learning_rate': 0.009125383051213245, 'weight_decay': 0.0002820370899390242, 'pooling_method': 'mean', 'gcn_batch_norm_flag_0': True, 'gcn_momentum_0': 0.3754890910756398, 'gcn_eps_0': 0.009054303715735892, 'gcn_dropout_flag_0': False, 'gcn_activation_0': 'leaky_relu', 'fc_batch_norm_flag_0': True, 'fc_batch_norm_flag_1': False, 'fc_batch_norm_flag_2': False, 'fc_momentum_0': 0.039836514138691714, 'fc_eps_0': 0.009922687549932755, 'fc_dropout_flag_0': True, 'fc_dropout_flag_1': False, 'fc_dropout_flag_2': False, 'fc_dropout_rate_0': 0.1001023362544777, 'fc_activation_0': 'elu', 'fc_activation_1': 'leaky_relu', 'fc_activation_2': 'leaky_relu', 'gcn_skip_connections_0': True, 'l1_lambda': 0.0004415785498239407, 'optimizer': 'Adam', 'beta1': 0.8552875771957883, 'beta2': 0.9989647357719865, 'lr_scheduler': 'PolynomialLR', 'power': 0.10103904607283629, 'total_iters': 296, 'loss_function': 'CrossEntropy'}. Best is trial 2 with value: 0.8644859813084113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68, Loss: 0.5366, Accuracy: 0.8160, Test Loss: 0.4436, Test Accuracy: 0.8248\n",
      "Early stopping triggered\n",
      "Epoch 1, Loss: 2.1304, Accuracy: 0.7074, Test Loss: 0.6341, Test Accuracy: 0.7710\n",
      "Epoch 2, Loss: 1.3712, Accuracy: 0.7827, Test Loss: 0.5629, Test Accuracy: 0.7874\n",
      "Epoch 3, Loss: 1.1465, Accuracy: 0.7921, Test Loss: 0.5486, Test Accuracy: 0.8037\n",
      "Epoch 4, Loss: 1.0205, Accuracy: 0.7967, Test Loss: 0.5334, Test Accuracy: 0.8084\n",
      "Epoch 5, Loss: 0.9493, Accuracy: 0.7961, Test Loss: 0.5040, Test Accuracy: 0.8084\n",
      "Epoch 6, Loss: 0.8922, Accuracy: 0.8014, Test Loss: 0.5315, Test Accuracy: 0.8014\n",
      "Epoch 7, Loss: 0.8635, Accuracy: 0.8037, Test Loss: 0.4907, Test Accuracy: 0.8084\n",
      "Epoch 8, Loss: 0.8258, Accuracy: 0.8002, Test Loss: 0.4790, Test Accuracy: 0.8131\n",
      "Epoch 9, Loss: 0.7826, Accuracy: 0.8102, Test Loss: 0.4774, Test Accuracy: 0.8154\n",
      "Epoch 10, Loss: 0.7705, Accuracy: 0.8014, Test Loss: 0.4696, Test Accuracy: 0.8201\n",
      "Epoch 11, Loss: 0.7449, Accuracy: 0.8072, Test Loss: 0.4787, Test Accuracy: 0.8131\n",
      "Epoch 12, Loss: 0.7197, Accuracy: 0.8113, Test Loss: 0.4817, Test Accuracy: 0.8154\n",
      "Epoch 13, Loss: 0.7134, Accuracy: 0.8078, Test Loss: 0.4634, Test Accuracy: 0.8131\n",
      "Epoch 14, Loss: 0.6912, Accuracy: 0.8125, Test Loss: 0.4601, Test Accuracy: 0.8201\n",
      "Epoch 15, Loss: 0.6792, Accuracy: 0.8084, Test Loss: 0.4723, Test Accuracy: 0.8224\n",
      "Epoch 16, Loss: 0.6647, Accuracy: 0.8131, Test Loss: 0.4563, Test Accuracy: 0.8224\n",
      "Epoch 17, Loss: 0.6589, Accuracy: 0.8119, Test Loss: 0.4682, Test Accuracy: 0.8154\n",
      "Epoch 18, Loss: 0.6436, Accuracy: 0.8154, Test Loss: 0.4574, Test Accuracy: 0.8201\n",
      "Epoch 19, Loss: 0.6412, Accuracy: 0.8137, Test Loss: 0.4649, Test Accuracy: 0.8178\n",
      "Epoch 20, Loss: 0.6387, Accuracy: 0.8131, Test Loss: 0.4510, Test Accuracy: 0.8201\n",
      "Epoch 21, Loss: 0.6260, Accuracy: 0.8119, Test Loss: 0.4567, Test Accuracy: 0.8201\n",
      "Epoch 22, Loss: 0.6238, Accuracy: 0.8107, Test Loss: 0.4537, Test Accuracy: 0.8224\n",
      "Epoch 23, Loss: 0.6292, Accuracy: 0.8125, Test Loss: 0.4504, Test Accuracy: 0.8224\n",
      "Epoch 24, Loss: 0.6190, Accuracy: 0.8090, Test Loss: 0.4526, Test Accuracy: 0.8294\n",
      "Epoch 25, Loss: 0.6186, Accuracy: 0.8072, Test Loss: 0.4548, Test Accuracy: 0.8271\n",
      "Epoch 26, Loss: 0.6165, Accuracy: 0.8119, Test Loss: 0.4471, Test Accuracy: 0.8224\n",
      "Epoch 27, Loss: 0.6023, Accuracy: 0.8137, Test Loss: 0.4388, Test Accuracy: 0.8248\n",
      "Epoch 28, Loss: 0.6138, Accuracy: 0.8102, Test Loss: 0.4412, Test Accuracy: 0.8248\n",
      "Epoch 29, Loss: 0.6085, Accuracy: 0.8119, Test Loss: 0.4422, Test Accuracy: 0.8248\n",
      "Epoch 30, Loss: 0.6008, Accuracy: 0.8172, Test Loss: 0.4428, Test Accuracy: 0.8294\n",
      "Epoch 31, Loss: 0.6016, Accuracy: 0.8119, Test Loss: 0.4467, Test Accuracy: 0.8248\n",
      "Epoch 32, Loss: 0.5937, Accuracy: 0.8160, Test Loss: 0.4520, Test Accuracy: 0.8201\n",
      "Epoch 33, Loss: 0.5964, Accuracy: 0.8183, Test Loss: 0.4389, Test Accuracy: 0.8248\n",
      "Epoch 34, Loss: 0.5854, Accuracy: 0.8154, Test Loss: 0.4465, Test Accuracy: 0.8201\n",
      "Epoch 35, Loss: 0.5843, Accuracy: 0.8143, Test Loss: 0.4386, Test Accuracy: 0.8248\n",
      "Epoch 36, Loss: 0.5822, Accuracy: 0.8160, Test Loss: 0.4412, Test Accuracy: 0.8271\n",
      "Epoch 37, Loss: 0.5896, Accuracy: 0.8143, Test Loss: 0.4414, Test Accuracy: 0.8224\n",
      "Epoch 38, Loss: 0.5823, Accuracy: 0.8178, Test Loss: 0.4354, Test Accuracy: 0.8271\n",
      "Epoch 39, Loss: 0.5807, Accuracy: 0.8172, Test Loss: 0.4465, Test Accuracy: 0.8201\n",
      "Epoch 40, Loss: 0.5805, Accuracy: 0.8160, Test Loss: 0.4546, Test Accuracy: 0.8248\n",
      "Epoch 41, Loss: 0.5860, Accuracy: 0.8160, Test Loss: 0.4401, Test Accuracy: 0.8224\n",
      "Epoch 42, Loss: 0.5786, Accuracy: 0.8178, Test Loss: 0.4608, Test Accuracy: 0.8178\n",
      "Epoch 43, Loss: 0.5737, Accuracy: 0.8189, Test Loss: 0.4431, Test Accuracy: 0.8248\n",
      "Epoch 44, Loss: 0.5724, Accuracy: 0.8183, Test Loss: 0.4399, Test Accuracy: 0.8248\n",
      "Epoch 45, Loss: 0.5820, Accuracy: 0.8143, Test Loss: 0.4408, Test Accuracy: 0.8271\n",
      "Epoch 46, Loss: 0.5747, Accuracy: 0.8172, Test Loss: 0.4379, Test Accuracy: 0.8271\n",
      "Epoch 47, Loss: 0.5634, Accuracy: 0.8183, Test Loss: 0.4371, Test Accuracy: 0.8294\n",
      "Epoch 48, Loss: 0.5669, Accuracy: 0.8183, Test Loss: 0.4485, Test Accuracy: 0.8201\n",
      "Epoch 49, Loss: 0.5703, Accuracy: 0.8166, Test Loss: 0.4381, Test Accuracy: 0.8271\n",
      "Epoch 50, Loss: 0.5684, Accuracy: 0.8160, Test Loss: 0.4343, Test Accuracy: 0.8271\n",
      "Epoch 51, Loss: 0.5623, Accuracy: 0.8172, Test Loss: 0.4366, Test Accuracy: 0.8294\n",
      "Epoch 52, Loss: 0.5711, Accuracy: 0.8143, Test Loss: 0.4478, Test Accuracy: 0.8248\n",
      "Epoch 53, Loss: 0.5695, Accuracy: 0.8143, Test Loss: 0.4347, Test Accuracy: 0.8271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:21:07,179] Trial 22 finished with value: 0.8294392523364486 and parameters: {'batch_size': 32, 'num_gcn_layers': 1, 'gcn_hidden_dim_0': 57, 'num_fc_layers': 3, 'fc_hidden_dim_0': 128, 'fc_hidden_dim_1': 106, 'fc_hidden_dim_2': 84, 'learning_rate': 0.0022517746540931475, 'weight_decay': 0.0001549085549020478, 'pooling_method': 'mean', 'gcn_batch_norm_flag_0': True, 'gcn_momentum_0': 0.408571038331842, 'gcn_eps_0': 0.00679186863330195, 'gcn_dropout_flag_0': False, 'gcn_activation_0': 'leaky_relu', 'fc_batch_norm_flag_0': True, 'fc_batch_norm_flag_1': False, 'fc_batch_norm_flag_2': False, 'fc_momentum_0': 0.13566314402643243, 'fc_eps_0': 0.009892396556766778, 'fc_dropout_flag_0': True, 'fc_dropout_flag_1': False, 'fc_dropout_flag_2': False, 'fc_dropout_rate_0': 0.1848881992261092, 'fc_activation_0': 'elu', 'fc_activation_1': 'leaky_relu', 'fc_activation_2': 'leaky_relu', 'gcn_skip_connections_0': True, 'l1_lambda': 0.0007653272724240769, 'optimizer': 'Adam', 'beta1': 0.8786770994237758, 'beta2': 0.9873957487875954, 'lr_scheduler': 'PolynomialLR', 'power': 0.35511886892032174, 'total_iters': 236, 'loss_function': 'CrossEntropy'}. Best is trial 2 with value: 0.8644859813084113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54, Loss: 0.5656, Accuracy: 0.8172, Test Loss: 0.4463, Test Accuracy: 0.8178\n",
      "Early stopping triggered\n",
      "Epoch 1, Loss: 1.7885, Accuracy: 0.6939, Test Loss: 0.6471, Test Accuracy: 0.7523\n",
      "Epoch 2, Loss: 1.2340, Accuracy: 0.7225, Test Loss: 0.6574, Test Accuracy: 0.7664\n",
      "Epoch 3, Loss: 1.0381, Accuracy: 0.7558, Test Loss: 0.5544, Test Accuracy: 0.7827\n",
      "Epoch 4, Loss: 0.8988, Accuracy: 0.7821, Test Loss: 0.5649, Test Accuracy: 0.7827\n",
      "Epoch 5, Loss: 0.8542, Accuracy: 0.7850, Test Loss: 0.5104, Test Accuracy: 0.8084\n",
      "Epoch 6, Loss: 0.8434, Accuracy: 0.7798, Test Loss: 0.5231, Test Accuracy: 0.8037\n",
      "Epoch 7, Loss: 0.7713, Accuracy: 0.7944, Test Loss: 0.4986, Test Accuracy: 0.8084\n",
      "Epoch 8, Loss: 0.7337, Accuracy: 0.7926, Test Loss: 0.5079, Test Accuracy: 0.8061\n",
      "Epoch 9, Loss: 0.7425, Accuracy: 0.7880, Test Loss: 0.5055, Test Accuracy: 0.8061\n",
      "Epoch 10, Loss: 0.7333, Accuracy: 0.7944, Test Loss: 0.4991, Test Accuracy: 0.8084\n",
      "Epoch 11, Loss: 0.7143, Accuracy: 0.7909, Test Loss: 0.5335, Test Accuracy: 0.7897\n",
      "Epoch 12, Loss: 0.7064, Accuracy: 0.7903, Test Loss: 0.5105, Test Accuracy: 0.7921\n",
      "Epoch 13, Loss: 0.6744, Accuracy: 0.7996, Test Loss: 0.5089, Test Accuracy: 0.8084\n",
      "Epoch 14, Loss: 0.6673, Accuracy: 0.8008, Test Loss: 0.4980, Test Accuracy: 0.8107\n",
      "Epoch 15, Loss: 0.6585, Accuracy: 0.7991, Test Loss: 0.4902, Test Accuracy: 0.8061\n",
      "Epoch 16, Loss: 0.6374, Accuracy: 0.8037, Test Loss: 0.5085, Test Accuracy: 0.8131\n",
      "Epoch 17, Loss: 0.6729, Accuracy: 0.7862, Test Loss: 0.5159, Test Accuracy: 0.8061\n",
      "Epoch 18, Loss: 0.6611, Accuracy: 0.7961, Test Loss: 0.5077, Test Accuracy: 0.8084\n",
      "Epoch 19, Loss: 0.6410, Accuracy: 0.8014, Test Loss: 0.4879, Test Accuracy: 0.8084\n",
      "Epoch 20, Loss: 0.6362, Accuracy: 0.7996, Test Loss: 0.4964, Test Accuracy: 0.8107\n",
      "Epoch 21, Loss: 0.6260, Accuracy: 0.7973, Test Loss: 0.4948, Test Accuracy: 0.8084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:21:46,364] Trial 23 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, Loss: 0.6358, Accuracy: 0.7921, Test Loss: 0.4991, Test Accuracy: 0.7967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:21:47,174] Trial 24 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 4.3683, Accuracy: 0.3645, Test Loss: 1.6368, Test Accuracy: 0.2430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:21:49,077] Trial 25 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.7676, Accuracy: 0.6904, Test Loss: 0.7188, Test Accuracy: 0.7126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:21:51,190] Trial 26 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.1551, Accuracy: 0.6238, Test Loss: 0.1597, Test Accuracy: 0.7150\n",
      "Epoch 1, Loss: 0.8135, Accuracy: 0.6910, Test Loss: 0.5744, Test Accuracy: 0.7921\n",
      "Epoch 2, Loss: 0.5845, Accuracy: 0.7739, Test Loss: 0.5291, Test Accuracy: 0.7944\n",
      "Epoch 3, Loss: 0.5467, Accuracy: 0.7845, Test Loss: 0.5676, Test Accuracy: 0.7290\n",
      "Epoch 4, Loss: 0.5337, Accuracy: 0.7821, Test Loss: 0.4924, Test Accuracy: 0.8084\n",
      "Epoch 5, Loss: 0.5458, Accuracy: 0.7891, Test Loss: 0.5133, Test Accuracy: 0.8131\n",
      "Epoch 6, Loss: 0.5096, Accuracy: 0.7967, Test Loss: 0.4877, Test Accuracy: 0.8084\n",
      "Epoch 7, Loss: 0.5335, Accuracy: 0.7862, Test Loss: 0.4877, Test Accuracy: 0.8084\n",
      "Epoch 8, Loss: 0.5112, Accuracy: 0.7932, Test Loss: 0.4724, Test Accuracy: 0.8154\n",
      "Epoch 9, Loss: 0.5072, Accuracy: 0.7996, Test Loss: 0.4744, Test Accuracy: 0.8107\n",
      "Epoch 10, Loss: 0.5037, Accuracy: 0.8020, Test Loss: 0.5672, Test Accuracy: 0.7944\n",
      "Epoch 11, Loss: 0.5143, Accuracy: 0.7903, Test Loss: 0.5324, Test Accuracy: 0.7897\n",
      "Epoch 12, Loss: 0.5105, Accuracy: 0.8002, Test Loss: 0.4627, Test Accuracy: 0.8224\n",
      "Epoch 13, Loss: 0.4894, Accuracy: 0.8008, Test Loss: 0.4764, Test Accuracy: 0.8154\n",
      "Epoch 14, Loss: 0.5241, Accuracy: 0.7926, Test Loss: 0.5721, Test Accuracy: 0.7897\n",
      "Epoch 15, Loss: 0.4699, Accuracy: 0.8107, Test Loss: 0.5319, Test Accuracy: 0.7407\n",
      "Epoch 16, Loss: 0.4856, Accuracy: 0.7932, Test Loss: 0.4549, Test Accuracy: 0.8248\n",
      "Epoch 17, Loss: 0.4756, Accuracy: 0.8072, Test Loss: 0.4852, Test Accuracy: 0.8107\n",
      "Epoch 18, Loss: 0.4953, Accuracy: 0.8014, Test Loss: 0.4575, Test Accuracy: 0.8107\n",
      "Epoch 19, Loss: 0.4652, Accuracy: 0.8096, Test Loss: 0.4507, Test Accuracy: 0.8201\n",
      "Epoch 20, Loss: 0.4652, Accuracy: 0.8084, Test Loss: 0.4600, Test Accuracy: 0.8154\n",
      "Epoch 21, Loss: 0.4511, Accuracy: 0.8154, Test Loss: 0.4488, Test Accuracy: 0.8294\n",
      "Epoch 22, Loss: 0.4637, Accuracy: 0.8131, Test Loss: 0.4390, Test Accuracy: 0.8224\n",
      "Epoch 23, Loss: 0.4566, Accuracy: 0.8189, Test Loss: 0.4380, Test Accuracy: 0.8271\n",
      "Epoch 24, Loss: 0.4540, Accuracy: 0.8107, Test Loss: 0.4273, Test Accuracy: 0.8248\n",
      "Epoch 25, Loss: 0.4468, Accuracy: 0.8154, Test Loss: 0.4433, Test Accuracy: 0.8178\n",
      "Epoch 26, Loss: 0.4528, Accuracy: 0.8148, Test Loss: 0.4371, Test Accuracy: 0.8178\n",
      "Epoch 27, Loss: 0.4395, Accuracy: 0.8183, Test Loss: 0.4391, Test Accuracy: 0.8178\n",
      "Epoch 28, Loss: 0.4455, Accuracy: 0.8131, Test Loss: 0.4476, Test Accuracy: 0.8201\n",
      "Epoch 29, Loss: 0.4409, Accuracy: 0.8160, Test Loss: 0.4317, Test Accuracy: 0.8248\n",
      "Epoch 30, Loss: 0.4370, Accuracy: 0.8148, Test Loss: 0.4536, Test Accuracy: 0.8154\n",
      "Epoch 31, Loss: 0.4390, Accuracy: 0.8178, Test Loss: 0.4411, Test Accuracy: 0.8178\n",
      "Epoch 32, Loss: 0.4442, Accuracy: 0.8160, Test Loss: 0.4233, Test Accuracy: 0.8248\n",
      "Epoch 33, Loss: 0.4328, Accuracy: 0.8166, Test Loss: 0.4256, Test Accuracy: 0.8294\n",
      "Epoch 34, Loss: 0.4245, Accuracy: 0.8189, Test Loss: 0.4270, Test Accuracy: 0.8248\n",
      "Epoch 35, Loss: 0.4256, Accuracy: 0.8154, Test Loss: 0.4297, Test Accuracy: 0.8294\n",
      "Epoch 36, Loss: 0.4181, Accuracy: 0.8218, Test Loss: 0.4330, Test Accuracy: 0.8294\n",
      "Epoch 37, Loss: 0.4228, Accuracy: 0.8172, Test Loss: 0.4217, Test Accuracy: 0.8294\n",
      "Epoch 38, Loss: 0.4228, Accuracy: 0.8160, Test Loss: 0.4268, Test Accuracy: 0.8248\n",
      "Epoch 39, Loss: 0.4167, Accuracy: 0.8213, Test Loss: 0.4245, Test Accuracy: 0.8294\n",
      "Epoch 40, Loss: 0.4181, Accuracy: 0.8224, Test Loss: 0.4289, Test Accuracy: 0.8271\n",
      "Epoch 41, Loss: 0.4247, Accuracy: 0.8189, Test Loss: 0.4427, Test Accuracy: 0.8201\n",
      "Epoch 42, Loss: 0.4187, Accuracy: 0.8207, Test Loss: 0.4325, Test Accuracy: 0.8271\n",
      "Epoch 43, Loss: 0.4145, Accuracy: 0.8189, Test Loss: 0.4303, Test Accuracy: 0.8224\n",
      "Epoch 44, Loss: 0.4181, Accuracy: 0.8201, Test Loss: 0.4399, Test Accuracy: 0.8248\n",
      "Epoch 45, Loss: 0.4170, Accuracy: 0.8154, Test Loss: 0.4282, Test Accuracy: 0.8248\n",
      "Epoch 46, Loss: 0.4120, Accuracy: 0.8224, Test Loss: 0.4266, Test Accuracy: 0.8248\n",
      "Epoch 47, Loss: 0.4116, Accuracy: 0.8201, Test Loss: 0.4258, Test Accuracy: 0.8271\n",
      "Epoch 48, Loss: 0.4131, Accuracy: 0.8230, Test Loss: 0.4301, Test Accuracy: 0.8271\n",
      "Epoch 49, Loss: 0.4049, Accuracy: 0.8195, Test Loss: 0.4299, Test Accuracy: 0.8248\n",
      "Epoch 50, Loss: 0.4057, Accuracy: 0.8224, Test Loss: 0.4230, Test Accuracy: 0.8294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:22:59,138] Trial 27 finished with value: 0.8294392523364486 and parameters: {'batch_size': 32, 'num_gcn_layers': 1, 'gcn_hidden_dim_0': 101, 'num_fc_layers': 2, 'fc_hidden_dim_0': 106, 'fc_hidden_dim_1': 185, 'learning_rate': 0.00560249433384476, 'weight_decay': 0.00034135116044090497, 'pooling_method': 'mean', 'gcn_batch_norm_flag_0': True, 'gcn_momentum_0': 0.436501710341499, 'gcn_eps_0': 0.005082202163378799, 'gcn_dropout_flag_0': False, 'gcn_activation_0': 'tanh', 'fc_batch_norm_flag_0': True, 'fc_batch_norm_flag_1': False, 'fc_momentum_0': 0.16790923697001509, 'fc_eps_0': 0.008781664792155305, 'fc_dropout_flag_0': True, 'fc_dropout_flag_1': False, 'fc_dropout_rate_0': 0.2577515627695375, 'fc_activation_0': 'elu', 'fc_activation_1': 'leaky_relu', 'gcn_skip_connections_0': True, 'l1_lambda': 8.385871222969278e-07, 'optimizer': 'Adam', 'beta1': 0.9095511015459715, 'beta2': 0.9685758762589052, 'lr_scheduler': 'ReduceLROnPlateau', 'factor': 0.8294260813767578, 'lr_patience': 3, 'lr_threshold': 0.00040704620342148917, 'lr_eps': 2.264505424620068e-06, 'loss_function': 'CrossEntropy'}. Best is trial 2 with value: 0.8644859813084113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51, Loss: 0.3997, Accuracy: 0.8218, Test Loss: 0.4247, Test Accuracy: 0.8294\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:23:01,098] Trial 28 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.4559, Accuracy: 0.2301, Test Loss: 1.6433, Test Accuracy: 0.4696\n",
      "Epoch 1, Loss: 3.0545, Accuracy: 0.7237, Test Loss: 0.5626, Test Accuracy: 0.7921\n",
      "Epoch 2, Loss: 2.3939, Accuracy: 0.7675, Test Loss: 0.5537, Test Accuracy: 0.8061\n",
      "Epoch 3, Loss: 1.8784, Accuracy: 0.7897, Test Loss: 0.5543, Test Accuracy: 0.7897\n",
      "Epoch 4, Loss: 1.5063, Accuracy: 0.7804, Test Loss: 0.5629, Test Accuracy: 0.7897\n",
      "Epoch 5, Loss: 1.2776, Accuracy: 0.7921, Test Loss: 0.5422, Test Accuracy: 0.8014\n",
      "Epoch 6, Loss: 1.1228, Accuracy: 0.7926, Test Loss: 0.5467, Test Accuracy: 0.8154\n",
      "Epoch 7, Loss: 1.0283, Accuracy: 0.7926, Test Loss: 0.5272, Test Accuracy: 0.8107\n",
      "Epoch 8, Loss: 0.9697, Accuracy: 0.7985, Test Loss: 0.5204, Test Accuracy: 0.8107\n",
      "Epoch 9, Loss: 0.9114, Accuracy: 0.7956, Test Loss: 0.5655, Test Accuracy: 0.7967\n",
      "Epoch 10, Loss: 0.8565, Accuracy: 0.8067, Test Loss: 0.5487, Test Accuracy: 0.8084\n",
      "Epoch 11, Loss: 0.8314, Accuracy: 0.8002, Test Loss: 0.5289, Test Accuracy: 0.8131\n",
      "Epoch 12, Loss: 0.8063, Accuracy: 0.7973, Test Loss: 0.5208, Test Accuracy: 0.8014\n",
      "Epoch 13, Loss: 0.7734, Accuracy: 0.8043, Test Loss: 0.4969, Test Accuracy: 0.8178\n",
      "Epoch 14, Loss: 0.7512, Accuracy: 0.8061, Test Loss: 0.5433, Test Accuracy: 0.7850\n",
      "Epoch 15, Loss: 0.7205, Accuracy: 0.8078, Test Loss: 0.4952, Test Accuracy: 0.8154\n",
      "Epoch 16, Loss: 0.7078, Accuracy: 0.8084, Test Loss: 0.5012, Test Accuracy: 0.7640\n",
      "Epoch 17, Loss: 0.7016, Accuracy: 0.8113, Test Loss: 0.4841, Test Accuracy: 0.8224\n",
      "Epoch 18, Loss: 0.6752, Accuracy: 0.8107, Test Loss: 0.4680, Test Accuracy: 0.8248\n",
      "Epoch 19, Loss: 0.6611, Accuracy: 0.8259, Test Loss: 0.4578, Test Accuracy: 0.8224\n",
      "Epoch 20, Loss: 0.6694, Accuracy: 0.8143, Test Loss: 0.4652, Test Accuracy: 0.8201\n",
      "Epoch 21, Loss: 0.6655, Accuracy: 0.8189, Test Loss: 0.4803, Test Accuracy: 0.8107\n",
      "Epoch 22, Loss: 0.6460, Accuracy: 0.8189, Test Loss: 0.4374, Test Accuracy: 0.8364\n",
      "Epoch 23, Loss: 0.6447, Accuracy: 0.8201, Test Loss: 0.4598, Test Accuracy: 0.8178\n",
      "Epoch 24, Loss: 0.6461, Accuracy: 0.8148, Test Loss: 0.4307, Test Accuracy: 0.8271\n",
      "Epoch 25, Loss: 0.6294, Accuracy: 0.8242, Test Loss: 0.4252, Test Accuracy: 0.8435\n",
      "Epoch 26, Loss: 0.6219, Accuracy: 0.8259, Test Loss: 0.4551, Test Accuracy: 0.8318\n",
      "Epoch 27, Loss: 0.6253, Accuracy: 0.8248, Test Loss: 0.4335, Test Accuracy: 0.8341\n",
      "Epoch 28, Loss: 0.6079, Accuracy: 0.8265, Test Loss: 0.4218, Test Accuracy: 0.8341\n",
      "Epoch 29, Loss: 0.6135, Accuracy: 0.8236, Test Loss: 0.4156, Test Accuracy: 0.8458\n",
      "Epoch 30, Loss: 0.6109, Accuracy: 0.8230, Test Loss: 0.4104, Test Accuracy: 0.8458\n",
      "Epoch 31, Loss: 0.6041, Accuracy: 0.8312, Test Loss: 0.4043, Test Accuracy: 0.8318\n",
      "Epoch 32, Loss: 0.6142, Accuracy: 0.8248, Test Loss: 0.4030, Test Accuracy: 0.8435\n",
      "Epoch 33, Loss: 0.6090, Accuracy: 0.8289, Test Loss: 0.4197, Test Accuracy: 0.8458\n",
      "Epoch 34, Loss: 0.6001, Accuracy: 0.8353, Test Loss: 0.4126, Test Accuracy: 0.8341\n",
      "Epoch 35, Loss: 0.5945, Accuracy: 0.8335, Test Loss: 0.3844, Test Accuracy: 0.8458\n",
      "Epoch 36, Loss: 0.5824, Accuracy: 0.8271, Test Loss: 0.3847, Test Accuracy: 0.8505\n",
      "Epoch 37, Loss: 0.5894, Accuracy: 0.8329, Test Loss: 0.3840, Test Accuracy: 0.8551\n",
      "Epoch 38, Loss: 0.5936, Accuracy: 0.8294, Test Loss: 0.3942, Test Accuracy: 0.8435\n",
      "Epoch 39, Loss: 0.5865, Accuracy: 0.8353, Test Loss: 0.3849, Test Accuracy: 0.8551\n",
      "Epoch 40, Loss: 0.5711, Accuracy: 0.8370, Test Loss: 0.3923, Test Accuracy: 0.8388\n",
      "Epoch 41, Loss: 0.5805, Accuracy: 0.8376, Test Loss: 0.3813, Test Accuracy: 0.8505\n",
      "Epoch 42, Loss: 0.5803, Accuracy: 0.8347, Test Loss: 0.3825, Test Accuracy: 0.8528\n",
      "Epoch 43, Loss: 0.5868, Accuracy: 0.8382, Test Loss: 0.3859, Test Accuracy: 0.8435\n",
      "Epoch 44, Loss: 0.5739, Accuracy: 0.8318, Test Loss: 0.3820, Test Accuracy: 0.8551\n",
      "Epoch 45, Loss: 0.5614, Accuracy: 0.8376, Test Loss: 0.4013, Test Accuracy: 0.8341\n",
      "Epoch 46, Loss: 0.5638, Accuracy: 0.8364, Test Loss: 0.3780, Test Accuracy: 0.8575\n",
      "Epoch 47, Loss: 0.5604, Accuracy: 0.8370, Test Loss: 0.4162, Test Accuracy: 0.8224\n",
      "Epoch 48, Loss: 0.5678, Accuracy: 0.8294, Test Loss: 0.3855, Test Accuracy: 0.8388\n",
      "Epoch 49, Loss: 0.5790, Accuracy: 0.8318, Test Loss: 0.4061, Test Accuracy: 0.8435\n",
      "Epoch 50, Loss: 0.5709, Accuracy: 0.8376, Test Loss: 0.3958, Test Accuracy: 0.8341\n",
      "Epoch 51, Loss: 0.5753, Accuracy: 0.8335, Test Loss: 0.3974, Test Accuracy: 0.8364\n",
      "Epoch 52, Loss: 0.5515, Accuracy: 0.8394, Test Loss: 0.3781, Test Accuracy: 0.8341\n",
      "Epoch 53, Loss: 0.5301, Accuracy: 0.8435, Test Loss: 0.3638, Test Accuracy: 0.8575\n",
      "Epoch 54, Loss: 0.5486, Accuracy: 0.8417, Test Loss: 0.3741, Test Accuracy: 0.8551\n",
      "Epoch 55, Loss: 0.5472, Accuracy: 0.8388, Test Loss: 0.3681, Test Accuracy: 0.8505\n",
      "Epoch 56, Loss: 0.5492, Accuracy: 0.8423, Test Loss: 0.3703, Test Accuracy: 0.8551\n",
      "Epoch 57, Loss: 0.5421, Accuracy: 0.8435, Test Loss: 0.3722, Test Accuracy: 0.8528\n",
      "Epoch 58, Loss: 0.5379, Accuracy: 0.8400, Test Loss: 0.3613, Test Accuracy: 0.8551\n",
      "Epoch 59, Loss: 0.5532, Accuracy: 0.8370, Test Loss: 0.3728, Test Accuracy: 0.8551\n",
      "Epoch 60, Loss: 0.5472, Accuracy: 0.8388, Test Loss: 0.3657, Test Accuracy: 0.8551\n",
      "Epoch 61, Loss: 0.5357, Accuracy: 0.8429, Test Loss: 0.3514, Test Accuracy: 0.8598\n",
      "Epoch 62, Loss: 0.5350, Accuracy: 0.8429, Test Loss: 0.3861, Test Accuracy: 0.8528\n",
      "Epoch 63, Loss: 0.5170, Accuracy: 0.8470, Test Loss: 0.3810, Test Accuracy: 0.8505\n",
      "Epoch 64, Loss: 0.5204, Accuracy: 0.8440, Test Loss: 0.4106, Test Accuracy: 0.8528\n",
      "Epoch 65, Loss: 0.5158, Accuracy: 0.8475, Test Loss: 0.3652, Test Accuracy: 0.8551\n",
      "Epoch 66, Loss: 0.5233, Accuracy: 0.8452, Test Loss: 0.3859, Test Accuracy: 0.8388\n",
      "Epoch 67, Loss: 0.5312, Accuracy: 0.8400, Test Loss: 0.3715, Test Accuracy: 0.8481\n",
      "Epoch 68, Loss: 0.5366, Accuracy: 0.8464, Test Loss: 0.3576, Test Accuracy: 0.8598\n",
      "Epoch 69, Loss: 0.5260, Accuracy: 0.8493, Test Loss: 0.3693, Test Accuracy: 0.8505\n",
      "Epoch 70, Loss: 0.5453, Accuracy: 0.8429, Test Loss: 0.3565, Test Accuracy: 0.8621\n",
      "Epoch 71, Loss: 0.5283, Accuracy: 0.8458, Test Loss: 0.3678, Test Accuracy: 0.8481\n",
      "Epoch 72, Loss: 0.5255, Accuracy: 0.8446, Test Loss: 0.3748, Test Accuracy: 0.8575\n",
      "Epoch 73, Loss: 0.5315, Accuracy: 0.8394, Test Loss: 0.3722, Test Accuracy: 0.8621\n",
      "Epoch 74, Loss: 0.5396, Accuracy: 0.8411, Test Loss: 0.3531, Test Accuracy: 0.8598\n",
      "Epoch 75, Loss: 0.5367, Accuracy: 0.8423, Test Loss: 0.3861, Test Accuracy: 0.8505\n",
      "Epoch 76, Loss: 0.5305, Accuracy: 0.8452, Test Loss: 0.3564, Test Accuracy: 0.8528\n",
      "Epoch 77, Loss: 0.5173, Accuracy: 0.8499, Test Loss: 0.3734, Test Accuracy: 0.8458\n",
      "Epoch 78, Loss: 0.5253, Accuracy: 0.8487, Test Loss: 0.3722, Test Accuracy: 0.8505\n",
      "Epoch 79, Loss: 0.5190, Accuracy: 0.8446, Test Loss: 0.3867, Test Accuracy: 0.8551\n",
      "Epoch 80, Loss: 0.5081, Accuracy: 0.8522, Test Loss: 0.3572, Test Accuracy: 0.8621\n",
      "Epoch 81, Loss: 0.5071, Accuracy: 0.8429, Test Loss: 0.3636, Test Accuracy: 0.8528\n",
      "Epoch 82, Loss: 0.5161, Accuracy: 0.8341, Test Loss: 0.3488, Test Accuracy: 0.8668\n",
      "Epoch 83, Loss: 0.5241, Accuracy: 0.8394, Test Loss: 0.3719, Test Accuracy: 0.8575\n",
      "Epoch 84, Loss: 0.5197, Accuracy: 0.8481, Test Loss: 0.3755, Test Accuracy: 0.8435\n",
      "Epoch 85, Loss: 0.4986, Accuracy: 0.8470, Test Loss: 0.3908, Test Accuracy: 0.8481\n",
      "Epoch 86, Loss: 0.5176, Accuracy: 0.8511, Test Loss: 0.3644, Test Accuracy: 0.8575\n",
      "Epoch 87, Loss: 0.5120, Accuracy: 0.8464, Test Loss: 0.3722, Test Accuracy: 0.8505\n",
      "Epoch 88, Loss: 0.5177, Accuracy: 0.8435, Test Loss: 0.3496, Test Accuracy: 0.8575\n",
      "Epoch 89, Loss: 0.4967, Accuracy: 0.8487, Test Loss: 0.3933, Test Accuracy: 0.8411\n",
      "Epoch 90, Loss: 0.5164, Accuracy: 0.8405, Test Loss: 0.3742, Test Accuracy: 0.8528\n",
      "Epoch 91, Loss: 0.5168, Accuracy: 0.8446, Test Loss: 0.3593, Test Accuracy: 0.8551\n",
      "Epoch 92, Loss: 0.4954, Accuracy: 0.8511, Test Loss: 0.3451, Test Accuracy: 0.8621\n",
      "Epoch 93, Loss: 0.4980, Accuracy: 0.8534, Test Loss: 0.3717, Test Accuracy: 0.8528\n",
      "Epoch 94, Loss: 0.5076, Accuracy: 0.8435, Test Loss: 0.3784, Test Accuracy: 0.8528\n",
      "Epoch 95, Loss: 0.4990, Accuracy: 0.8516, Test Loss: 0.3697, Test Accuracy: 0.8458\n",
      "Epoch 96, Loss: 0.5014, Accuracy: 0.8440, Test Loss: 0.3449, Test Accuracy: 0.8598\n",
      "Epoch 97, Loss: 0.4957, Accuracy: 0.8458, Test Loss: 0.3564, Test Accuracy: 0.8621\n",
      "Epoch 98, Loss: 0.5084, Accuracy: 0.8487, Test Loss: 0.3626, Test Accuracy: 0.8505\n",
      "Epoch 99, Loss: 0.5234, Accuracy: 0.8475, Test Loss: 0.3880, Test Accuracy: 0.8551\n",
      "Epoch 100, Loss: 0.5233, Accuracy: 0.8493, Test Loss: 0.4007, Test Accuracy: 0.8481\n",
      "Epoch 101, Loss: 0.5217, Accuracy: 0.8470, Test Loss: 0.4201, Test Accuracy: 0.8481\n",
      "Epoch 102, Loss: 0.5208, Accuracy: 0.8464, Test Loss: 0.3740, Test Accuracy: 0.8621\n",
      "Epoch 103, Loss: 0.5019, Accuracy: 0.8481, Test Loss: 0.3775, Test Accuracy: 0.8528\n",
      "Epoch 104, Loss: 0.4880, Accuracy: 0.8540, Test Loss: 0.3779, Test Accuracy: 0.8505\n",
      "Epoch 105, Loss: 0.4911, Accuracy: 0.8470, Test Loss: 0.4030, Test Accuracy: 0.8458\n",
      "Epoch 106, Loss: 0.5070, Accuracy: 0.8470, Test Loss: 0.3914, Test Accuracy: 0.8458\n",
      "Epoch 107, Loss: 0.5050, Accuracy: 0.8528, Test Loss: 0.3573, Test Accuracy: 0.8575\n",
      "Epoch 108, Loss: 0.5138, Accuracy: 0.8394, Test Loss: 0.3530, Test Accuracy: 0.8668\n",
      "Epoch 109, Loss: 0.5166, Accuracy: 0.8394, Test Loss: 0.3369, Test Accuracy: 0.8668\n",
      "Epoch 110, Loss: 0.5053, Accuracy: 0.8511, Test Loss: 0.3671, Test Accuracy: 0.8551\n",
      "Epoch 111, Loss: 0.4840, Accuracy: 0.8505, Test Loss: 0.3554, Test Accuracy: 0.8645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:26:30,084] Trial 29 finished with value: 0.866822429906542 and parameters: {'batch_size': 64, 'num_gcn_layers': 4, 'gcn_hidden_dim_0': 72, 'gcn_hidden_dim_1': 32, 'gcn_hidden_dim_2': 116, 'gcn_hidden_dim_3': 201, 'num_fc_layers': 2, 'fc_hidden_dim_0': 160, 'fc_hidden_dim_1': 227, 'learning_rate': 6.939056984176202e-05, 'weight_decay': 0.0009968222394385567, 'pooling_method': 'max', 'gcn_batch_norm_flag_0': True, 'gcn_batch_norm_flag_1': True, 'gcn_batch_norm_flag_2': False, 'gcn_batch_norm_flag_3': True, 'gcn_momentum_0': 0.7477108886300342, 'gcn_momentum_1': 0.959642902790424, 'gcn_momentum_3': 0.6103398952299889, 'gcn_eps_0': 0.00747132571971257, 'gcn_eps_1': 0.003589026763773517, 'gcn_eps_3': 0.006130841227898249, 'gcn_dropout_flag_0': True, 'gcn_dropout_flag_1': False, 'gcn_dropout_flag_2': False, 'gcn_dropout_flag_3': False, 'gcn_dropout_rate_0': 0.10663443830310523, 'gcn_activation_0': 'softplus', 'gcn_activation_1': 'gelu', 'gcn_activation_2': 'gelu', 'gcn_activation_3': 'elu', 'fc_batch_norm_flag_0': False, 'fc_batch_norm_flag_1': True, 'fc_momentum_1': 0.9677626367003457, 'fc_eps_1': 0.00018935298839716473, 'fc_dropout_flag_0': False, 'fc_dropout_flag_1': True, 'fc_dropout_rate_1': 0.29393604741146545, 'fc_activation_0': 'relu', 'fc_activation_1': 'tanh', 'gcn_skip_connections_0': True, 'gcn_skip_connections_1': True, 'gcn_skip_connections_2': False, 'gcn_skip_connections_3': True, 'l1_lambda': 0.00034798056445930624, 'optimizer': 'Adam', 'beta1': 0.8626685695610015, 'beta2': 0.9785915584698384, 'lr_scheduler': 'OneCycleLR', 'max_lr_1': 0.09527254191438926, 'pct_start': 0.4998956863574824, 'loss_function': 'CrossEntropy'}. Best is trial 29 with value: 0.866822429906542.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112, Loss: 0.4844, Accuracy: 0.8481, Test Loss: 0.3455, Test Accuracy: 0.8621\n",
      "Early stopping triggered\n",
      "Epoch 1, Loss: 3.0504, Accuracy: 0.6361, Test Loss: 0.6784, Test Accuracy: 0.7687\n",
      "Epoch 2, Loss: 2.3472, Accuracy: 0.6928, Test Loss: 0.8527, Test Accuracy: 0.6729\n",
      "Epoch 3, Loss: 1.9430, Accuracy: 0.7150, Test Loss: 0.6733, Test Accuracy: 0.7220\n",
      "Epoch 4, Loss: 1.8480, Accuracy: 0.7109, Test Loss: 0.7147, Test Accuracy: 0.7056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:26:40,390] Trial 30 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 1.8001, Accuracy: 0.7196, Test Loss: 0.7684, Test Accuracy: 0.7734\n",
      "Epoch 1, Loss: 4.9597, Accuracy: 0.6583, Test Loss: 0.6690, Test Accuracy: 0.7570\n",
      "Epoch 2, Loss: 3.4953, Accuracy: 0.7325, Test Loss: 0.6675, Test Accuracy: 0.7500\n",
      "Epoch 3, Loss: 2.3837, Accuracy: 0.7611, Test Loss: 0.5231, Test Accuracy: 0.8084\n",
      "Epoch 4, Loss: 1.7031, Accuracy: 0.7909, Test Loss: 0.5520, Test Accuracy: 0.7921\n",
      "Epoch 5, Loss: 1.3844, Accuracy: 0.7815, Test Loss: 0.5921, Test Accuracy: 0.7921\n",
      "Epoch 6, Loss: 1.2112, Accuracy: 0.7979, Test Loss: 0.5522, Test Accuracy: 0.8037\n",
      "Epoch 7, Loss: 1.0766, Accuracy: 0.8096, Test Loss: 0.5449, Test Accuracy: 0.7921\n",
      "Epoch 8, Loss: 0.9702, Accuracy: 0.8090, Test Loss: 0.5820, Test Accuracy: 0.7640\n",
      "Epoch 9, Loss: 0.9430, Accuracy: 0.8055, Test Loss: 0.4848, Test Accuracy: 0.8154\n",
      "Epoch 10, Loss: 0.8798, Accuracy: 0.8148, Test Loss: 0.4816, Test Accuracy: 0.8224\n",
      "Epoch 11, Loss: 0.8192, Accuracy: 0.8137, Test Loss: 0.4831, Test Accuracy: 0.8154\n",
      "Epoch 12, Loss: 0.8101, Accuracy: 0.8067, Test Loss: 0.4911, Test Accuracy: 0.8014\n",
      "Epoch 13, Loss: 0.7939, Accuracy: 0.8072, Test Loss: 0.4543, Test Accuracy: 0.8364\n",
      "Epoch 14, Loss: 0.7744, Accuracy: 0.8166, Test Loss: 0.4969, Test Accuracy: 0.8084\n",
      "Epoch 15, Loss: 0.7485, Accuracy: 0.8218, Test Loss: 0.4552, Test Accuracy: 0.8341\n",
      "Epoch 16, Loss: 0.7359, Accuracy: 0.8143, Test Loss: 0.4499, Test Accuracy: 0.8107\n",
      "Epoch 17, Loss: 0.7173, Accuracy: 0.8166, Test Loss: 0.4660, Test Accuracy: 0.8154\n",
      "Epoch 18, Loss: 0.7159, Accuracy: 0.8160, Test Loss: 0.4446, Test Accuracy: 0.8318\n",
      "Epoch 19, Loss: 0.7195, Accuracy: 0.8143, Test Loss: 0.4625, Test Accuracy: 0.8178\n",
      "Epoch 20, Loss: 0.6991, Accuracy: 0.8166, Test Loss: 0.4593, Test Accuracy: 0.8201\n",
      "Epoch 21, Loss: 0.7054, Accuracy: 0.8213, Test Loss: 0.4495, Test Accuracy: 0.8201\n",
      "Epoch 22, Loss: 0.6896, Accuracy: 0.8248, Test Loss: 0.4417, Test Accuracy: 0.8341\n",
      "Epoch 23, Loss: 0.6853, Accuracy: 0.8172, Test Loss: 0.4253, Test Accuracy: 0.8411\n",
      "Epoch 24, Loss: 0.6777, Accuracy: 0.8259, Test Loss: 0.4510, Test Accuracy: 0.8084\n",
      "Epoch 25, Loss: 0.6741, Accuracy: 0.8254, Test Loss: 0.4313, Test Accuracy: 0.8318\n",
      "Epoch 26, Loss: 0.6662, Accuracy: 0.8218, Test Loss: 0.4315, Test Accuracy: 0.8411\n",
      "Epoch 27, Loss: 0.6556, Accuracy: 0.8218, Test Loss: 0.4387, Test Accuracy: 0.8201\n",
      "Epoch 28, Loss: 0.6589, Accuracy: 0.8195, Test Loss: 0.4270, Test Accuracy: 0.8341\n",
      "Epoch 29, Loss: 0.6397, Accuracy: 0.8300, Test Loss: 0.4301, Test Accuracy: 0.8318\n",
      "Epoch 30, Loss: 0.6369, Accuracy: 0.8248, Test Loss: 0.4298, Test Accuracy: 0.8388\n",
      "Epoch 31, Loss: 0.6337, Accuracy: 0.8312, Test Loss: 0.4667, Test Accuracy: 0.8107\n",
      "Epoch 32, Loss: 0.6641, Accuracy: 0.8178, Test Loss: 0.4516, Test Accuracy: 0.8201\n",
      "Epoch 33, Loss: 0.6540, Accuracy: 0.8160, Test Loss: 0.4220, Test Accuracy: 0.8364\n",
      "Epoch 34, Loss: 0.6644, Accuracy: 0.8213, Test Loss: 0.4413, Test Accuracy: 0.8318\n",
      "Epoch 35, Loss: 0.6428, Accuracy: 0.8183, Test Loss: 0.4153, Test Accuracy: 0.8364\n",
      "Epoch 36, Loss: 0.6455, Accuracy: 0.8178, Test Loss: 0.4391, Test Accuracy: 0.8201\n",
      "Epoch 37, Loss: 0.6360, Accuracy: 0.8230, Test Loss: 0.4037, Test Accuracy: 0.8411\n",
      "Epoch 38, Loss: 0.6219, Accuracy: 0.8265, Test Loss: 0.4055, Test Accuracy: 0.8341\n",
      "Epoch 39, Loss: 0.6080, Accuracy: 0.8242, Test Loss: 0.3938, Test Accuracy: 0.8528\n",
      "Epoch 40, Loss: 0.6181, Accuracy: 0.8329, Test Loss: 0.4101, Test Accuracy: 0.8364\n",
      "Epoch 41, Loss: 0.6177, Accuracy: 0.8248, Test Loss: 0.4005, Test Accuracy: 0.8388\n",
      "Epoch 42, Loss: 0.6067, Accuracy: 0.8271, Test Loss: 0.3780, Test Accuracy: 0.8645\n",
      "Epoch 43, Loss: 0.5966, Accuracy: 0.8347, Test Loss: 0.4252, Test Accuracy: 0.8388\n",
      "Epoch 44, Loss: 0.5948, Accuracy: 0.8324, Test Loss: 0.4005, Test Accuracy: 0.8341\n",
      "Epoch 45, Loss: 0.5855, Accuracy: 0.8370, Test Loss: 0.4629, Test Accuracy: 0.8201\n",
      "Epoch 46, Loss: 0.5888, Accuracy: 0.8359, Test Loss: 0.3743, Test Accuracy: 0.8551\n",
      "Epoch 47, Loss: 0.6048, Accuracy: 0.8248, Test Loss: 0.4002, Test Accuracy: 0.8271\n",
      "Epoch 48, Loss: 0.6041, Accuracy: 0.8300, Test Loss: 0.4167, Test Accuracy: 0.8481\n",
      "Epoch 49, Loss: 0.5903, Accuracy: 0.8341, Test Loss: 0.3727, Test Accuracy: 0.8528\n",
      "Epoch 50, Loss: 0.5881, Accuracy: 0.8277, Test Loss: 0.4026, Test Accuracy: 0.8294\n",
      "Epoch 51, Loss: 0.5875, Accuracy: 0.8294, Test Loss: 0.3911, Test Accuracy: 0.8341\n",
      "Epoch 52, Loss: 0.5746, Accuracy: 0.8388, Test Loss: 0.3973, Test Accuracy: 0.8575\n",
      "Epoch 53, Loss: 0.5720, Accuracy: 0.8394, Test Loss: 0.4061, Test Accuracy: 0.8388\n",
      "Epoch 54, Loss: 0.5874, Accuracy: 0.8382, Test Loss: 0.4036, Test Accuracy: 0.8341\n",
      "Epoch 55, Loss: 0.5866, Accuracy: 0.8318, Test Loss: 0.4050, Test Accuracy: 0.8481\n",
      "Epoch 56, Loss: 0.5876, Accuracy: 0.8312, Test Loss: 0.3954, Test Accuracy: 0.8505\n",
      "Epoch 57, Loss: 0.5883, Accuracy: 0.8306, Test Loss: 0.3793, Test Accuracy: 0.8551\n",
      "Epoch 58, Loss: 0.5820, Accuracy: 0.8376, Test Loss: 0.3867, Test Accuracy: 0.8435\n",
      "Epoch 59, Loss: 0.5677, Accuracy: 0.8353, Test Loss: 0.4014, Test Accuracy: 0.8575\n",
      "Epoch 60, Loss: 0.5713, Accuracy: 0.8376, Test Loss: 0.3754, Test Accuracy: 0.8645\n",
      "Epoch 61, Loss: 0.5673, Accuracy: 0.8411, Test Loss: 0.3855, Test Accuracy: 0.8458\n",
      "Epoch 62, Loss: 0.5614, Accuracy: 0.8394, Test Loss: 0.3788, Test Accuracy: 0.8551\n",
      "Epoch 63, Loss: 0.5601, Accuracy: 0.8329, Test Loss: 0.4042, Test Accuracy: 0.8575\n",
      "Epoch 64, Loss: 0.5749, Accuracy: 0.8376, Test Loss: 0.4423, Test Accuracy: 0.8411\n",
      "Epoch 65, Loss: 0.5817, Accuracy: 0.8341, Test Loss: 0.3878, Test Accuracy: 0.8411\n",
      "Epoch 66, Loss: 0.5690, Accuracy: 0.8289, Test Loss: 0.3855, Test Accuracy: 0.8645\n",
      "Epoch 67, Loss: 0.5730, Accuracy: 0.8341, Test Loss: 0.3726, Test Accuracy: 0.8458\n",
      "Epoch 68, Loss: 0.5664, Accuracy: 0.8353, Test Loss: 0.4242, Test Accuracy: 0.8505\n",
      "Epoch 69, Loss: 0.5580, Accuracy: 0.8359, Test Loss: 0.3770, Test Accuracy: 0.8435\n",
      "Epoch 70, Loss: 0.5452, Accuracy: 0.8423, Test Loss: 0.4214, Test Accuracy: 0.8388\n",
      "Epoch 71, Loss: 0.5403, Accuracy: 0.8464, Test Loss: 0.3676, Test Accuracy: 0.8598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:29:19,218] Trial 31 finished with value: 0.8644859813084113 and parameters: {'batch_size': 64, 'num_gcn_layers': 5, 'gcn_hidden_dim_0': 44, 'gcn_hidden_dim_1': 69, 'gcn_hidden_dim_2': 160, 'gcn_hidden_dim_3': 148, 'gcn_hidden_dim_4': 251, 'num_fc_layers': 2, 'fc_hidden_dim_0': 191, 'fc_hidden_dim_1': 237, 'learning_rate': 0.00010997151634530269, 'weight_decay': 0.0009764326149684461, 'pooling_method': 'max', 'gcn_batch_norm_flag_0': True, 'gcn_batch_norm_flag_1': True, 'gcn_batch_norm_flag_2': False, 'gcn_batch_norm_flag_3': True, 'gcn_batch_norm_flag_4': False, 'gcn_momentum_0': 0.988351809090147, 'gcn_momentum_1': 0.8206102251198542, 'gcn_momentum_3': 0.7506159596976265, 'gcn_eps_0': 0.008578687562229353, 'gcn_eps_1': 0.0007588724577369519, 'gcn_eps_3': 0.007970653239875732, 'gcn_dropout_flag_0': True, 'gcn_dropout_flag_1': False, 'gcn_dropout_flag_2': False, 'gcn_dropout_flag_3': False, 'gcn_dropout_flag_4': False, 'gcn_dropout_rate_0': 0.21583670358475004, 'gcn_activation_0': 'softplus', 'gcn_activation_1': 'gelu', 'gcn_activation_2': 'gelu', 'gcn_activation_3': 'elu', 'gcn_activation_4': 'relu', 'fc_batch_norm_flag_0': False, 'fc_batch_norm_flag_1': True, 'fc_momentum_1': 0.6716920228673997, 'fc_eps_1': 0.002525166661512032, 'fc_dropout_flag_0': False, 'fc_dropout_flag_1': True, 'fc_dropout_rate_1': 0.21405861303897034, 'fc_activation_0': 'relu', 'fc_activation_1': 'tanh', 'gcn_skip_connections_0': True, 'gcn_skip_connections_1': True, 'gcn_skip_connections_2': False, 'gcn_skip_connections_3': True, 'gcn_skip_connections_4': True, 'l1_lambda': 0.00038065482893278983, 'optimizer': 'Adam', 'beta1': 0.8622856522218183, 'beta2': 0.9825904110147375, 'lr_scheduler': 'OneCycleLR', 'max_lr_1': 0.09816513192770115, 'pct_start': 0.4928131345246984, 'loss_function': 'CrossEntropy'}. Best is trial 29 with value: 0.866822429906542.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72, Loss: 0.5448, Accuracy: 0.8429, Test Loss: 0.4271, Test Accuracy: 0.8364\n",
      "Early stopping triggered\n",
      "Epoch 1, Loss: 4.7211, Accuracy: 0.6723, Test Loss: 0.6646, Test Accuracy: 0.7640\n",
      "Epoch 2, Loss: 3.3630, Accuracy: 0.7342, Test Loss: 0.6860, Test Accuracy: 0.7617\n",
      "Epoch 3, Loss: 2.2959, Accuracy: 0.7366, Test Loss: 0.6220, Test Accuracy: 0.7687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:29:28,181] Trial 32 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 1.7048, Accuracy: 0.7383, Test Loss: 0.6165, Test Accuracy: 0.7640\n",
      "Epoch 1, Loss: 2.2010, Accuracy: 0.6694, Test Loss: 0.5974, Test Accuracy: 0.7734\n",
      "Epoch 2, Loss: 1.7940, Accuracy: 0.7734, Test Loss: 0.5280, Test Accuracy: 0.8061\n",
      "Epoch 3, Loss: 1.5139, Accuracy: 0.7815, Test Loss: 0.5795, Test Accuracy: 0.7570\n",
      "Epoch 4, Loss: 1.2930, Accuracy: 0.7897, Test Loss: 0.5618, Test Accuracy: 0.8084\n",
      "Epoch 5, Loss: 1.1026, Accuracy: 0.7897, Test Loss: 0.5714, Test Accuracy: 0.7687\n",
      "Epoch 6, Loss: 0.9922, Accuracy: 0.7903, Test Loss: 0.5042, Test Accuracy: 0.8107\n",
      "Epoch 7, Loss: 0.8963, Accuracy: 0.7950, Test Loss: 0.4716, Test Accuracy: 0.8154\n",
      "Epoch 8, Loss: 0.8430, Accuracy: 0.8032, Test Loss: 0.4890, Test Accuracy: 0.8014\n",
      "Epoch 9, Loss: 0.7979, Accuracy: 0.8002, Test Loss: 0.4568, Test Accuracy: 0.8154\n",
      "Epoch 10, Loss: 0.7442, Accuracy: 0.8172, Test Loss: 0.4489, Test Accuracy: 0.8178\n",
      "Epoch 11, Loss: 0.7043, Accuracy: 0.8143, Test Loss: 0.4635, Test Accuracy: 0.7850\n",
      "Epoch 12, Loss: 0.6742, Accuracy: 0.8265, Test Loss: 0.4192, Test Accuracy: 0.8248\n",
      "Epoch 13, Loss: 0.6676, Accuracy: 0.8195, Test Loss: 0.4356, Test Accuracy: 0.8248\n",
      "Epoch 14, Loss: 0.6719, Accuracy: 0.8189, Test Loss: 0.4591, Test Accuracy: 0.8224\n",
      "Epoch 15, Loss: 0.6585, Accuracy: 0.8242, Test Loss: 0.4147, Test Accuracy: 0.8388\n",
      "Epoch 16, Loss: 0.6310, Accuracy: 0.8312, Test Loss: 0.4395, Test Accuracy: 0.8271\n",
      "Epoch 17, Loss: 0.6296, Accuracy: 0.8230, Test Loss: 0.4208, Test Accuracy: 0.8341\n",
      "Epoch 18, Loss: 0.6204, Accuracy: 0.8236, Test Loss: 0.4350, Test Accuracy: 0.8435\n",
      "Epoch 19, Loss: 0.6261, Accuracy: 0.8236, Test Loss: 0.4261, Test Accuracy: 0.8341\n",
      "Epoch 20, Loss: 0.6291, Accuracy: 0.8230, Test Loss: 0.4344, Test Accuracy: 0.8248\n",
      "Epoch 21, Loss: 0.5878, Accuracy: 0.8370, Test Loss: 0.3883, Test Accuracy: 0.8388\n",
      "Epoch 22, Loss: 0.5771, Accuracy: 0.8359, Test Loss: 0.4036, Test Accuracy: 0.8271\n",
      "Epoch 23, Loss: 0.5992, Accuracy: 0.8218, Test Loss: 0.3972, Test Accuracy: 0.8318\n",
      "Epoch 24, Loss: 0.6043, Accuracy: 0.8178, Test Loss: 0.4795, Test Accuracy: 0.8201\n",
      "Epoch 25, Loss: 0.5747, Accuracy: 0.8382, Test Loss: 0.3913, Test Accuracy: 0.8364\n",
      "Epoch 26, Loss: 0.5722, Accuracy: 0.8341, Test Loss: 0.3994, Test Accuracy: 0.8435\n",
      "Epoch 27, Loss: 0.5733, Accuracy: 0.8265, Test Loss: 0.3883, Test Accuracy: 0.8318\n",
      "Epoch 28, Loss: 0.5445, Accuracy: 0.8376, Test Loss: 0.4042, Test Accuracy: 0.8481\n",
      "Epoch 29, Loss: 0.5331, Accuracy: 0.8364, Test Loss: 0.3813, Test Accuracy: 0.8481\n",
      "Epoch 30, Loss: 0.5544, Accuracy: 0.8265, Test Loss: 0.3832, Test Accuracy: 0.8458\n",
      "Epoch 31, Loss: 0.5391, Accuracy: 0.8411, Test Loss: 0.3880, Test Accuracy: 0.8505\n",
      "Epoch 32, Loss: 0.5364, Accuracy: 0.8318, Test Loss: 0.3719, Test Accuracy: 0.8528\n",
      "Epoch 33, Loss: 0.5288, Accuracy: 0.8400, Test Loss: 0.3866, Test Accuracy: 0.8575\n",
      "Epoch 34, Loss: 0.5303, Accuracy: 0.8300, Test Loss: 0.3666, Test Accuracy: 0.8598\n",
      "Epoch 35, Loss: 0.5405, Accuracy: 0.8347, Test Loss: 0.3761, Test Accuracy: 0.8505\n",
      "Epoch 36, Loss: 0.5360, Accuracy: 0.8341, Test Loss: 0.3916, Test Accuracy: 0.8411\n",
      "Epoch 37, Loss: 0.5398, Accuracy: 0.8312, Test Loss: 0.3971, Test Accuracy: 0.8505\n",
      "Epoch 38, Loss: 0.5383, Accuracy: 0.8312, Test Loss: 0.4860, Test Accuracy: 0.8248\n",
      "Epoch 39, Loss: 0.5510, Accuracy: 0.8324, Test Loss: 0.3971, Test Accuracy: 0.8294\n",
      "Epoch 40, Loss: 0.5579, Accuracy: 0.8283, Test Loss: 0.3776, Test Accuracy: 0.8458\n",
      "Epoch 41, Loss: 0.5407, Accuracy: 0.8300, Test Loss: 0.4076, Test Accuracy: 0.8318\n",
      "Epoch 42, Loss: 0.5437, Accuracy: 0.8353, Test Loss: 0.3987, Test Accuracy: 0.8388\n",
      "Epoch 43, Loss: 0.5253, Accuracy: 0.8359, Test Loss: 0.3793, Test Accuracy: 0.8528\n",
      "Epoch 44, Loss: 0.5230, Accuracy: 0.8405, Test Loss: 0.3847, Test Accuracy: 0.8364\n",
      "Epoch 45, Loss: 0.5160, Accuracy: 0.8376, Test Loss: 0.3830, Test Accuracy: 0.8551\n",
      "Epoch 46, Loss: 0.5032, Accuracy: 0.8446, Test Loss: 0.3826, Test Accuracy: 0.8575\n",
      "Epoch 47, Loss: 0.4980, Accuracy: 0.8394, Test Loss: 0.3635, Test Accuracy: 0.8505\n",
      "Epoch 48, Loss: 0.5043, Accuracy: 0.8411, Test Loss: 0.4097, Test Accuracy: 0.8364\n",
      "Epoch 49, Loss: 0.5092, Accuracy: 0.8364, Test Loss: 0.3758, Test Accuracy: 0.8551\n",
      "Epoch 50, Loss: 0.5052, Accuracy: 0.8464, Test Loss: 0.3653, Test Accuracy: 0.8575\n",
      "Epoch 51, Loss: 0.4964, Accuracy: 0.8376, Test Loss: 0.3614, Test Accuracy: 0.8551\n",
      "Epoch 52, Loss: 0.5163, Accuracy: 0.8335, Test Loss: 0.3696, Test Accuracy: 0.8505\n",
      "Epoch 53, Loss: 0.4969, Accuracy: 0.8446, Test Loss: 0.3780, Test Accuracy: 0.8528\n",
      "Epoch 54, Loss: 0.4988, Accuracy: 0.8470, Test Loss: 0.3650, Test Accuracy: 0.8505\n",
      "Epoch 55, Loss: 0.4978, Accuracy: 0.8364, Test Loss: 0.3608, Test Accuracy: 0.8551\n",
      "Epoch 56, Loss: 0.4854, Accuracy: 0.8452, Test Loss: 0.3613, Test Accuracy: 0.8575\n",
      "Epoch 57, Loss: 0.4818, Accuracy: 0.8388, Test Loss: 0.3801, Test Accuracy: 0.8598\n",
      "Epoch 58, Loss: 0.4908, Accuracy: 0.8417, Test Loss: 0.4226, Test Accuracy: 0.8364\n",
      "Epoch 59, Loss: 0.4924, Accuracy: 0.8417, Test Loss: 0.3662, Test Accuracy: 0.8481\n",
      "Epoch 60, Loss: 0.4984, Accuracy: 0.8411, Test Loss: 0.3634, Test Accuracy: 0.8528\n",
      "Epoch 61, Loss: 0.4913, Accuracy: 0.8435, Test Loss: 0.3750, Test Accuracy: 0.8481\n",
      "Epoch 62, Loss: 0.4883, Accuracy: 0.8411, Test Loss: 0.3766, Test Accuracy: 0.8551\n",
      "Epoch 63, Loss: 0.4937, Accuracy: 0.8429, Test Loss: 0.3662, Test Accuracy: 0.8621\n",
      "Epoch 64, Loss: 0.5096, Accuracy: 0.8306, Test Loss: 0.3882, Test Accuracy: 0.8435\n",
      "Epoch 65, Loss: 0.5002, Accuracy: 0.8376, Test Loss: 0.4047, Test Accuracy: 0.8435\n",
      "Epoch 66, Loss: 0.4750, Accuracy: 0.8464, Test Loss: 0.3761, Test Accuracy: 0.8505\n",
      "Epoch 67, Loss: 0.4828, Accuracy: 0.8405, Test Loss: 0.3619, Test Accuracy: 0.8598\n",
      "Epoch 68, Loss: 0.4819, Accuracy: 0.8370, Test Loss: 0.3637, Test Accuracy: 0.8248\n",
      "Epoch 69, Loss: 0.4969, Accuracy: 0.8388, Test Loss: 0.3912, Test Accuracy: 0.8435\n",
      "Epoch 70, Loss: 0.4836, Accuracy: 0.8400, Test Loss: 0.3529, Test Accuracy: 0.8598\n",
      "Epoch 71, Loss: 0.4850, Accuracy: 0.8470, Test Loss: 0.3556, Test Accuracy: 0.8645\n",
      "Epoch 72, Loss: 0.4718, Accuracy: 0.8516, Test Loss: 0.3611, Test Accuracy: 0.8551\n",
      "Epoch 73, Loss: 0.4923, Accuracy: 0.8446, Test Loss: 0.3782, Test Accuracy: 0.8458\n",
      "Epoch 74, Loss: 0.4721, Accuracy: 0.8528, Test Loss: 0.3477, Test Accuracy: 0.8575\n",
      "Epoch 75, Loss: 0.4838, Accuracy: 0.8353, Test Loss: 0.3447, Test Accuracy: 0.8621\n",
      "Epoch 76, Loss: 0.4718, Accuracy: 0.8516, Test Loss: 0.3564, Test Accuracy: 0.8598\n",
      "Epoch 77, Loss: 0.4619, Accuracy: 0.8487, Test Loss: 0.3539, Test Accuracy: 0.8645\n",
      "Epoch 78, Loss: 0.4589, Accuracy: 0.8452, Test Loss: 0.3650, Test Accuracy: 0.8551\n",
      "Epoch 79, Loss: 0.4845, Accuracy: 0.8388, Test Loss: 0.3760, Test Accuracy: 0.8388\n",
      "Epoch 80, Loss: 0.4929, Accuracy: 0.8382, Test Loss: 0.3721, Test Accuracy: 0.8458\n",
      "Epoch 81, Loss: 0.5082, Accuracy: 0.8364, Test Loss: 0.3684, Test Accuracy: 0.8551\n",
      "Epoch 82, Loss: 0.4775, Accuracy: 0.8452, Test Loss: 0.3737, Test Accuracy: 0.8505\n",
      "Epoch 83, Loss: 0.4860, Accuracy: 0.8435, Test Loss: 0.3534, Test Accuracy: 0.8598\n",
      "Epoch 84, Loss: 0.4743, Accuracy: 0.8475, Test Loss: 0.3663, Test Accuracy: 0.8621\n",
      "Epoch 85, Loss: 0.4761, Accuracy: 0.8464, Test Loss: 0.3971, Test Accuracy: 0.8411\n",
      "Epoch 86, Loss: 0.4776, Accuracy: 0.8435, Test Loss: 0.3592, Test Accuracy: 0.8551\n",
      "Epoch 87, Loss: 0.4744, Accuracy: 0.8470, Test Loss: 0.3385, Test Accuracy: 0.8645\n",
      "Epoch 88, Loss: 0.4725, Accuracy: 0.8429, Test Loss: 0.3580, Test Accuracy: 0.8598\n",
      "Epoch 89, Loss: 0.4650, Accuracy: 0.8487, Test Loss: 0.3473, Test Accuracy: 0.8692\n",
      "Epoch 90, Loss: 0.4606, Accuracy: 0.8487, Test Loss: 0.3359, Test Accuracy: 0.8668\n",
      "Epoch 91, Loss: 0.4730, Accuracy: 0.8470, Test Loss: 0.3926, Test Accuracy: 0.8481\n",
      "Epoch 92, Loss: 0.4813, Accuracy: 0.8405, Test Loss: 0.3681, Test Accuracy: 0.8575\n",
      "Epoch 93, Loss: 0.4726, Accuracy: 0.8505, Test Loss: 0.3624, Test Accuracy: 0.8551\n",
      "Epoch 94, Loss: 0.4586, Accuracy: 0.8470, Test Loss: 0.3509, Test Accuracy: 0.8598\n",
      "Epoch 95, Loss: 0.4533, Accuracy: 0.8487, Test Loss: 0.3874, Test Accuracy: 0.8458\n",
      "Epoch 96, Loss: 0.4668, Accuracy: 0.8452, Test Loss: 0.3465, Test Accuracy: 0.8621\n",
      "Epoch 97, Loss: 0.4740, Accuracy: 0.8458, Test Loss: 0.3642, Test Accuracy: 0.8668\n",
      "Epoch 98, Loss: 0.4778, Accuracy: 0.8400, Test Loss: 0.3884, Test Accuracy: 0.8528\n",
      "Epoch 99, Loss: 0.4813, Accuracy: 0.8464, Test Loss: 0.3742, Test Accuracy: 0.8575\n",
      "Epoch 100, Loss: 0.4871, Accuracy: 0.8341, Test Loss: 0.3793, Test Accuracy: 0.8528\n",
      "Epoch 101, Loss: 0.4931, Accuracy: 0.8446, Test Loss: 0.3571, Test Accuracy: 0.8505\n",
      "Epoch 102, Loss: 0.4802, Accuracy: 0.8499, Test Loss: 0.3435, Test Accuracy: 0.8598\n",
      "Epoch 103, Loss: 0.4662, Accuracy: 0.8417, Test Loss: 0.3603, Test Accuracy: 0.8598\n",
      "Epoch 104, Loss: 0.4988, Accuracy: 0.8382, Test Loss: 0.3912, Test Accuracy: 0.8178\n",
      "Epoch 105, Loss: 0.5061, Accuracy: 0.8400, Test Loss: 0.3691, Test Accuracy: 0.8621\n",
      "Epoch 106, Loss: 0.4774, Accuracy: 0.8452, Test Loss: 0.3573, Test Accuracy: 0.8528\n",
      "Epoch 107, Loss: 0.4637, Accuracy: 0.8470, Test Loss: 0.3524, Test Accuracy: 0.8645\n",
      "Epoch 108, Loss: 0.4569, Accuracy: 0.8411, Test Loss: 0.3964, Test Accuracy: 0.8528\n",
      "Epoch 109, Loss: 0.4809, Accuracy: 0.8417, Test Loss: 0.3938, Test Accuracy: 0.8505\n",
      "Epoch 110, Loss: 0.4780, Accuracy: 0.8411, Test Loss: 0.3423, Test Accuracy: 0.8668\n",
      "Epoch 111, Loss: 0.4766, Accuracy: 0.8470, Test Loss: 0.3511, Test Accuracy: 0.8528\n",
      "Epoch 112, Loss: 0.4847, Accuracy: 0.8405, Test Loss: 0.3552, Test Accuracy: 0.8551\n",
      "Epoch 113, Loss: 0.4750, Accuracy: 0.8440, Test Loss: 0.3516, Test Accuracy: 0.8621\n",
      "Epoch 114, Loss: 0.4620, Accuracy: 0.8481, Test Loss: 0.3470, Test Accuracy: 0.8692\n",
      "Epoch 115, Loss: 0.4741, Accuracy: 0.8487, Test Loss: 0.3911, Test Accuracy: 0.8505\n",
      "Epoch 116, Loss: 0.4635, Accuracy: 0.8470, Test Loss: 0.3443, Test Accuracy: 0.8715\n",
      "Epoch 117, Loss: 0.4524, Accuracy: 0.8446, Test Loss: 0.3595, Test Accuracy: 0.8598\n",
      "Epoch 118, Loss: 0.4685, Accuracy: 0.8423, Test Loss: 0.3328, Test Accuracy: 0.8645\n",
      "Epoch 119, Loss: 0.4681, Accuracy: 0.8470, Test Loss: 0.3641, Test Accuracy: 0.8528\n",
      "Epoch 120, Loss: 0.4721, Accuracy: 0.8411, Test Loss: 0.3446, Test Accuracy: 0.8645\n",
      "Epoch 121, Loss: 0.4542, Accuracy: 0.8505, Test Loss: 0.3615, Test Accuracy: 0.8528\n",
      "Epoch 122, Loss: 0.4728, Accuracy: 0.8329, Test Loss: 0.3792, Test Accuracy: 0.8551\n",
      "Epoch 123, Loss: 0.4841, Accuracy: 0.8435, Test Loss: 0.3835, Test Accuracy: 0.8551\n",
      "Epoch 124, Loss: 0.4654, Accuracy: 0.8505, Test Loss: 0.3531, Test Accuracy: 0.8645\n",
      "Epoch 125, Loss: 0.4625, Accuracy: 0.8452, Test Loss: 0.3541, Test Accuracy: 0.8621\n",
      "Epoch 126, Loss: 0.4601, Accuracy: 0.8528, Test Loss: 0.3463, Test Accuracy: 0.8598\n",
      "Epoch 127, Loss: 0.4803, Accuracy: 0.8417, Test Loss: 0.3689, Test Accuracy: 0.8528\n",
      "Epoch 128, Loss: 0.4657, Accuracy: 0.8475, Test Loss: 0.3582, Test Accuracy: 0.8481\n",
      "Epoch 129, Loss: 0.4621, Accuracy: 0.8452, Test Loss: 0.3583, Test Accuracy: 0.8645\n",
      "Epoch 130, Loss: 0.4562, Accuracy: 0.8429, Test Loss: 0.3657, Test Accuracy: 0.8551\n",
      "Epoch 131, Loss: 0.4564, Accuracy: 0.8429, Test Loss: 0.4171, Test Accuracy: 0.8435\n",
      "Epoch 132, Loss: 0.4564, Accuracy: 0.8464, Test Loss: 0.3341, Test Accuracy: 0.8621\n",
      "Epoch 133, Loss: 0.4639, Accuracy: 0.8470, Test Loss: 0.3472, Test Accuracy: 0.8598\n",
      "Epoch 134, Loss: 0.4676, Accuracy: 0.8452, Test Loss: 0.3417, Test Accuracy: 0.8668\n",
      "Epoch 135, Loss: 0.4652, Accuracy: 0.8458, Test Loss: 0.3555, Test Accuracy: 0.8551\n",
      "Epoch 136, Loss: 0.4628, Accuracy: 0.8464, Test Loss: 0.3714, Test Accuracy: 0.8575\n",
      "Epoch 137, Loss: 0.4683, Accuracy: 0.8470, Test Loss: 0.3768, Test Accuracy: 0.8528\n",
      "Epoch 138, Loss: 0.4703, Accuracy: 0.8452, Test Loss: 0.3791, Test Accuracy: 0.8458\n",
      "Epoch 139, Loss: 0.4668, Accuracy: 0.8487, Test Loss: 0.3443, Test Accuracy: 0.8551\n",
      "Epoch 140, Loss: 0.4721, Accuracy: 0.8376, Test Loss: 0.3538, Test Accuracy: 0.8551\n",
      "Epoch 141, Loss: 0.4782, Accuracy: 0.8516, Test Loss: 0.3471, Test Accuracy: 0.8621\n",
      "Epoch 142, Loss: 0.4739, Accuracy: 0.8435, Test Loss: 0.3490, Test Accuracy: 0.8621\n",
      "Epoch 143, Loss: 0.4694, Accuracy: 0.8423, Test Loss: 0.3386, Test Accuracy: 0.8668\n",
      "Epoch 144, Loss: 0.4578, Accuracy: 0.8458, Test Loss: 0.4250, Test Accuracy: 0.8388\n",
      "Epoch 145, Loss: 0.4669, Accuracy: 0.8452, Test Loss: 0.3624, Test Accuracy: 0.8505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:34:00,756] Trial 33 finished with value: 0.8714953271028038 and parameters: {'batch_size': 64, 'num_gcn_layers': 4, 'gcn_hidden_dim_0': 75, 'gcn_hidden_dim_1': 38, 'gcn_hidden_dim_2': 203, 'gcn_hidden_dim_3': 216, 'num_fc_layers': 2, 'fc_hidden_dim_0': 195, 'fc_hidden_dim_1': 211, 'learning_rate': 3.906092533355772e-05, 'weight_decay': 0.0008383274514321103, 'pooling_method': 'max', 'gcn_batch_norm_flag_0': True, 'gcn_batch_norm_flag_1': True, 'gcn_batch_norm_flag_2': False, 'gcn_batch_norm_flag_3': True, 'gcn_momentum_0': 0.8217968152253406, 'gcn_momentum_1': 0.8370398653730386, 'gcn_momentum_3': 0.7815973993240434, 'gcn_eps_0': 0.0056463681340145795, 'gcn_eps_1': 0.001529708689395466, 'gcn_eps_3': 0.007629669710253976, 'gcn_dropout_flag_0': True, 'gcn_dropout_flag_1': False, 'gcn_dropout_flag_2': False, 'gcn_dropout_flag_3': False, 'gcn_dropout_rate_0': 0.1958699153219181, 'gcn_activation_0': 'softplus', 'gcn_activation_1': 'gelu', 'gcn_activation_2': 'gelu', 'gcn_activation_3': 'elu', 'fc_batch_norm_flag_0': False, 'fc_batch_norm_flag_1': True, 'fc_momentum_1': 0.7312571225456058, 'fc_eps_1': 0.002633219222852208, 'fc_dropout_flag_0': False, 'fc_dropout_flag_1': True, 'fc_dropout_rate_1': 0.22646533440385175, 'fc_activation_0': 'relu', 'fc_activation_1': 'tanh', 'gcn_skip_connections_0': True, 'gcn_skip_connections_1': True, 'gcn_skip_connections_2': False, 'gcn_skip_connections_3': True, 'l1_lambda': 0.00014847614815074084, 'optimizer': 'Adam', 'beta1': 0.8847832072232581, 'beta2': 0.9765193026440564, 'lr_scheduler': 'OneCycleLR', 'max_lr_1': 0.07913189464182088, 'pct_start': 0.35947256384374804, 'loss_function': 'CrossEntropy'}. Best is trial 33 with value: 0.8714953271028038.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146, Loss: 0.4581, Accuracy: 0.8487, Test Loss: 0.3395, Test Accuracy: 0.8668\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:34:02,819] Trial 34 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.3358, Accuracy: 0.5917, Test Loss: 0.7789, Test Accuracy: 0.7150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:34:05,071] Trial 35 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 3.9952, Accuracy: 0.5234, Test Loss: 0.8520, Test Accuracy: 0.7290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:34:07,490] Trial 36 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.4960, Accuracy: 0.5771, Test Loss: 0.8548, Test Accuracy: 0.2150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:34:10,124] Trial 37 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 3.3896, Accuracy: 0.5713, Test Loss: 0.7988, Test Accuracy: 0.7196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:34:12,670] Trial 38 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.8520, Accuracy: 0.6641, Test Loss: 0.4296, Test Accuracy: 0.6659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:34:14,213] Trial 39 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 4.9051, Accuracy: 0.5175, Test Loss: 1.0173, Test Accuracy: 0.7126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:34:15,615] Trial 40 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.9809, Accuracy: 0.3347, Test Loss: 0.4690, Test Accuracy: 0.4065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:34:16,919] Trial 41 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 3.0795, Accuracy: 0.1933, Test Loss: 1.6355, Test Accuracy: 0.4556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:34:17,847] Trial 42 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 3.1516, Accuracy: 0.5082, Test Loss: 1.0810, Test Accuracy: 0.6893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:34:19,531] Trial 43 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 3.6295, Accuracy: 0.2336, Test Loss: 1.6446, Test Accuracy: 0.3785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:34:21,083] Trial 44 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 5.7619, Accuracy: 0.1530, Test Loss: 1.8214, Test Accuracy: 0.2383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:34:23,317] Trial 45 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 9.5662, Accuracy: 0.6016, Test Loss: 0.9880, Test Accuracy: 0.6659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:34:24,413] Trial 46 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 5.4036, Accuracy: 0.4410, Test Loss: 1.2222, Test Accuracy: 0.6589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:34:26,496] Trial 47 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.0317, Accuracy: 0.4895, Test Loss: 1.2304, Test Accuracy: 0.6402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:34:27,554] Trial 48 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.5289, Accuracy: 0.4749, Test Loss: 1.2861, Test Accuracy: 0.4486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:34:29,071] Trial 49 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.6269, Accuracy: 0.1583, Test Loss: 1.0239, Test Accuracy: 0.2150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:34:31,193] Trial 50 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.8952, Accuracy: 0.6279, Test Loss: 1.6798, Test Accuracy: 0.4065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:34:33,507] Trial 51 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.2963, Accuracy: 0.6659, Test Loss: 0.6914, Test Accuracy: 0.7290\n",
      "Epoch 1, Loss: 3.6349, Accuracy: 0.7044, Test Loss: 0.6508, Test Accuracy: 0.7523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:34:40,260] Trial 52 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 1.8263, Accuracy: 0.7407, Test Loss: 0.8688, Test Accuracy: 0.6379\n",
      "Epoch 1, Loss: 1.9635, Accuracy: 0.6466, Test Loss: 0.6652, Test Accuracy: 0.7523\n",
      "Epoch 2, Loss: 1.1747, Accuracy: 0.7389, Test Loss: 0.6280, Test Accuracy: 0.7827\n",
      "Epoch 3, Loss: 1.0639, Accuracy: 0.7436, Test Loss: 0.6219, Test Accuracy: 0.7547\n",
      "Epoch 4, Loss: 1.0032, Accuracy: 0.7424, Test Loss: 0.6277, Test Accuracy: 0.7523\n",
      "Epoch 5, Loss: 0.8857, Accuracy: 0.7792, Test Loss: 0.5523, Test Accuracy: 0.7991\n",
      "Epoch 6, Loss: 0.8870, Accuracy: 0.7652, Test Loss: 0.5574, Test Accuracy: 0.7874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:34:51,516] Trial 53 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 0.8358, Accuracy: 0.7845, Test Loss: 0.5295, Test Accuracy: 0.8061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:34:55,202] Trial 54 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 3.1902, Accuracy: 0.5970, Test Loss: 0.8951, Test Accuracy: 0.6963\n",
      "Epoch 1, Loss: 1.7932, Accuracy: 0.6600, Test Loss: 0.6693, Test Accuracy: 0.7500\n",
      "Epoch 2, Loss: 1.3706, Accuracy: 0.7518, Test Loss: 0.5678, Test Accuracy: 0.7734\n",
      "Epoch 3, Loss: 1.1539, Accuracy: 0.7827, Test Loss: 0.5412, Test Accuracy: 0.7944\n",
      "Epoch 4, Loss: 1.0362, Accuracy: 0.7897, Test Loss: 0.5093, Test Accuracy: 0.8061\n",
      "Epoch 5, Loss: 0.9525, Accuracy: 0.7868, Test Loss: 0.4998, Test Accuracy: 0.8061\n",
      "Epoch 6, Loss: 0.8990, Accuracy: 0.7961, Test Loss: 0.4868, Test Accuracy: 0.8107\n",
      "Epoch 7, Loss: 0.8431, Accuracy: 0.7973, Test Loss: 0.4846, Test Accuracy: 0.8131\n",
      "Epoch 8, Loss: 0.8083, Accuracy: 0.8037, Test Loss: 0.4806, Test Accuracy: 0.8154\n",
      "Epoch 9, Loss: 0.7998, Accuracy: 0.7973, Test Loss: 0.4696, Test Accuracy: 0.8178\n",
      "Epoch 10, Loss: 0.7756, Accuracy: 0.8037, Test Loss: 0.4729, Test Accuracy: 0.8224\n",
      "Epoch 11, Loss: 0.7635, Accuracy: 0.8061, Test Loss: 0.4718, Test Accuracy: 0.8178\n",
      "Epoch 12, Loss: 0.7568, Accuracy: 0.7985, Test Loss: 0.4854, Test Accuracy: 0.8107\n",
      "Epoch 13, Loss: 0.7385, Accuracy: 0.8049, Test Loss: 0.4594, Test Accuracy: 0.8201\n",
      "Epoch 14, Loss: 0.7445, Accuracy: 0.8084, Test Loss: 0.4633, Test Accuracy: 0.8154\n",
      "Epoch 15, Loss: 0.7183, Accuracy: 0.8072, Test Loss: 0.4525, Test Accuracy: 0.8201\n",
      "Epoch 16, Loss: 0.6956, Accuracy: 0.8107, Test Loss: 0.4710, Test Accuracy: 0.8131\n",
      "Epoch 17, Loss: 0.6901, Accuracy: 0.8096, Test Loss: 0.4666, Test Accuracy: 0.8178\n",
      "Epoch 18, Loss: 0.6769, Accuracy: 0.8078, Test Loss: 0.4651, Test Accuracy: 0.8107\n",
      "Epoch 19, Loss: 0.6666, Accuracy: 0.8084, Test Loss: 0.4584, Test Accuracy: 0.8154\n",
      "Epoch 20, Loss: 0.6673, Accuracy: 0.8078, Test Loss: 0.4471, Test Accuracy: 0.8248\n",
      "Epoch 21, Loss: 0.6483, Accuracy: 0.8154, Test Loss: 0.4456, Test Accuracy: 0.8248\n",
      "Epoch 22, Loss: 0.6577, Accuracy: 0.8072, Test Loss: 0.4667, Test Accuracy: 0.8178\n",
      "Epoch 23, Loss: 0.6596, Accuracy: 0.8102, Test Loss: 0.4493, Test Accuracy: 0.8201\n",
      "Epoch 24, Loss: 0.6490, Accuracy: 0.8107, Test Loss: 0.4466, Test Accuracy: 0.8224\n",
      "Epoch 25, Loss: 0.6316, Accuracy: 0.8154, Test Loss: 0.4394, Test Accuracy: 0.8224\n",
      "Epoch 26, Loss: 0.6360, Accuracy: 0.8125, Test Loss: 0.4373, Test Accuracy: 0.8271\n",
      "Epoch 27, Loss: 0.6395, Accuracy: 0.8096, Test Loss: 0.4526, Test Accuracy: 0.8248\n",
      "Epoch 28, Loss: 0.6242, Accuracy: 0.8178, Test Loss: 0.4444, Test Accuracy: 0.8201\n",
      "Epoch 29, Loss: 0.6259, Accuracy: 0.8131, Test Loss: 0.4325, Test Accuracy: 0.8294\n",
      "Epoch 30, Loss: 0.6208, Accuracy: 0.8125, Test Loss: 0.4397, Test Accuracy: 0.8294\n",
      "Epoch 31, Loss: 0.6071, Accuracy: 0.8183, Test Loss: 0.4452, Test Accuracy: 0.8201\n",
      "Epoch 32, Loss: 0.6070, Accuracy: 0.8160, Test Loss: 0.4306, Test Accuracy: 0.8248\n",
      "Epoch 33, Loss: 0.6020, Accuracy: 0.8172, Test Loss: 0.4432, Test Accuracy: 0.8201\n",
      "Epoch 34, Loss: 0.6184, Accuracy: 0.8131, Test Loss: 0.4455, Test Accuracy: 0.8271\n",
      "Epoch 35, Loss: 0.6177, Accuracy: 0.8148, Test Loss: 0.4342, Test Accuracy: 0.8294\n",
      "Epoch 36, Loss: 0.6189, Accuracy: 0.8119, Test Loss: 0.4632, Test Accuracy: 0.8201\n",
      "Epoch 37, Loss: 0.5990, Accuracy: 0.8154, Test Loss: 0.4450, Test Accuracy: 0.8201\n",
      "Epoch 38, Loss: 0.5916, Accuracy: 0.8131, Test Loss: 0.4401, Test Accuracy: 0.8294\n",
      "Epoch 39, Loss: 0.6005, Accuracy: 0.8137, Test Loss: 0.4332, Test Accuracy: 0.8271\n",
      "Epoch 40, Loss: 0.6089, Accuracy: 0.8090, Test Loss: 0.4481, Test Accuracy: 0.8248\n",
      "Epoch 41, Loss: 0.5945, Accuracy: 0.8131, Test Loss: 0.4372, Test Accuracy: 0.8271\n",
      "Epoch 42, Loss: 0.5869, Accuracy: 0.8137, Test Loss: 0.4348, Test Accuracy: 0.8248\n",
      "Epoch 43, Loss: 0.5897, Accuracy: 0.8148, Test Loss: 0.4409, Test Accuracy: 0.8271\n",
      "Epoch 44, Loss: 0.5845, Accuracy: 0.8166, Test Loss: 0.4467, Test Accuracy: 0.8294\n",
      "Epoch 45, Loss: 0.5863, Accuracy: 0.8154, Test Loss: 0.4284, Test Accuracy: 0.8294\n",
      "Epoch 46, Loss: 0.5732, Accuracy: 0.8172, Test Loss: 0.4327, Test Accuracy: 0.8248\n",
      "Epoch 47, Loss: 0.5817, Accuracy: 0.8137, Test Loss: 0.4355, Test Accuracy: 0.8224\n",
      "Epoch 48, Loss: 0.5734, Accuracy: 0.8107, Test Loss: 0.4403, Test Accuracy: 0.8271\n",
      "Epoch 49, Loss: 0.5741, Accuracy: 0.8166, Test Loss: 0.4357, Test Accuracy: 0.8201\n",
      "Epoch 50, Loss: 0.5696, Accuracy: 0.8178, Test Loss: 0.4351, Test Accuracy: 0.8271\n",
      "Epoch 51, Loss: 0.5770, Accuracy: 0.8189, Test Loss: 0.4308, Test Accuracy: 0.8294\n",
      "Epoch 52, Loss: 0.5719, Accuracy: 0.8166, Test Loss: 0.4352, Test Accuracy: 0.8248\n",
      "Epoch 53, Loss: 0.5730, Accuracy: 0.8166, Test Loss: 0.4292, Test Accuracy: 0.8271\n",
      "Epoch 54, Loss: 0.5582, Accuracy: 0.8218, Test Loss: 0.4325, Test Accuracy: 0.8271\n",
      "Epoch 55, Loss: 0.5657, Accuracy: 0.8154, Test Loss: 0.4304, Test Accuracy: 0.8271\n",
      "Epoch 56, Loss: 0.5718, Accuracy: 0.8183, Test Loss: 0.4299, Test Accuracy: 0.8248\n",
      "Epoch 57, Loss: 0.5746, Accuracy: 0.8090, Test Loss: 0.4313, Test Accuracy: 0.8271\n",
      "Epoch 58, Loss: 0.5704, Accuracy: 0.8178, Test Loss: 0.4244, Test Accuracy: 0.8271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:35:49,240] Trial 55 finished with value: 0.8294392523364486 and parameters: {'batch_size': 64, 'num_gcn_layers': 1, 'gcn_hidden_dim_0': 61, 'num_fc_layers': 3, 'fc_hidden_dim_0': 79, 'fc_hidden_dim_1': 230, 'fc_hidden_dim_2': 59, 'learning_rate': 0.001595540860591585, 'weight_decay': 4.25098852451161e-05, 'pooling_method': 'mean', 'gcn_batch_norm_flag_0': True, 'gcn_momentum_0': 0.2974868229727471, 'gcn_eps_0': 0.007093530333111306, 'gcn_dropout_flag_0': False, 'gcn_activation_0': 'leaky_relu', 'fc_batch_norm_flag_0': True, 'fc_batch_norm_flag_1': False, 'fc_batch_norm_flag_2': False, 'fc_momentum_0': 0.587916814652033, 'fc_eps_0': 0.007383806853036962, 'fc_dropout_flag_0': True, 'fc_dropout_flag_1': False, 'fc_dropout_flag_2': True, 'fc_dropout_rate_0': 0.41180201395039573, 'fc_dropout_rate_2': 0.3170984242764725, 'fc_activation_0': 'elu', 'fc_activation_1': 'leaky_relu', 'fc_activation_2': 'leaky_relu', 'gcn_skip_connections_0': True, 'l1_lambda': 0.00039448536642281936, 'optimizer': 'Adam', 'beta1': 0.870676692423426, 'beta2': 0.9947315395624762, 'lr_scheduler': 'OneCycleLR', 'max_lr_1': 0.08600057411912398, 'pct_start': 0.4490590283090816, 'loss_function': 'CrossEntropy'}. Best is trial 33 with value: 0.8714953271028038.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59, Loss: 0.5718, Accuracy: 0.8148, Test Loss: 0.4386, Test Accuracy: 0.8248\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:35:50,328] Trial 56 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 5.7915, Accuracy: 0.1846, Test Loss: 1.7263, Test Accuracy: 0.1098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:35:54,275] Trial 57 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 6.1709, Accuracy: 0.6472, Test Loss: 0.7888, Test Accuracy: 0.7290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:35:55,698] Trial 58 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 3.2544, Accuracy: 0.4299, Test Loss: 1.7626, Test Accuracy: 0.4836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:35:56,430] Trial 59 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.6324, Accuracy: 0.0724, Test Loss: 1.8041, Test Accuracy: 0.0467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:35:58,198] Trial 60 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 5.4246, Accuracy: 0.4089, Test Loss: 1.1255, Test Accuracy: 0.6472\n",
      "Epoch 1, Loss: 2.4235, Accuracy: 0.5794, Test Loss: 0.7097, Test Accuracy: 0.7430\n",
      "Epoch 2, Loss: 1.7630, Accuracy: 0.7377, Test Loss: 0.6600, Test Accuracy: 0.7687\n",
      "Epoch 3, Loss: 1.7333, Accuracy: 0.7629, Test Loss: 0.5602, Test Accuracy: 0.8061\n",
      "Epoch 4, Loss: 1.6903, Accuracy: 0.7991, Test Loss: 0.5758, Test Accuracy: 0.7640\n",
      "Epoch 5, Loss: 1.6999, Accuracy: 0.7798, Test Loss: 0.5684, Test Accuracy: 0.8061\n",
      "Epoch 6, Loss: 1.6668, Accuracy: 0.8049, Test Loss: 0.5357, Test Accuracy: 0.8084\n",
      "Epoch 7, Loss: 1.6122, Accuracy: 0.8020, Test Loss: 0.5098, Test Accuracy: 0.8084\n",
      "Epoch 8, Loss: 1.5571, Accuracy: 0.8049, Test Loss: 0.5101, Test Accuracy: 0.8084\n",
      "Epoch 9, Loss: 1.5219, Accuracy: 0.8049, Test Loss: 0.5050, Test Accuracy: 0.8107\n",
      "Epoch 10, Loss: 1.4832, Accuracy: 0.8026, Test Loss: 0.5236, Test Accuracy: 0.8107\n",
      "Epoch 11, Loss: 1.4329, Accuracy: 0.8061, Test Loss: 0.5179, Test Accuracy: 0.8061\n",
      "Epoch 12, Loss: 1.3739, Accuracy: 0.8090, Test Loss: 0.4908, Test Accuracy: 0.8037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:36:04,415] Trial 61 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Loss: 1.3240, Accuracy: 0.8037, Test Loss: 0.5047, Test Accuracy: 0.8084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:36:05,051] Trial 62 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.8833, Accuracy: 0.5888, Test Loss: 0.7151, Test Accuracy: 0.7336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:36:05,687] Trial 63 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.2440, Accuracy: 0.5239, Test Loss: 0.8951, Test Accuracy: 0.6799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:36:06,305] Trial 64 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.6554, Accuracy: 0.4930, Test Loss: 0.9531, Test Accuracy: 0.6121\n",
      "Epoch 1, Loss: 1.2954, Accuracy: 0.7027, Test Loss: 0.5923, Test Accuracy: 0.7500\n",
      "Epoch 2, Loss: 0.9810, Accuracy: 0.7804, Test Loss: 0.5507, Test Accuracy: 0.7804\n",
      "Epoch 3, Loss: 0.9035, Accuracy: 0.8014, Test Loss: 0.5664, Test Accuracy: 0.7897\n",
      "Epoch 4, Loss: 0.8512, Accuracy: 0.8061, Test Loss: 0.4922, Test Accuracy: 0.8107\n",
      "Epoch 5, Loss: 0.7886, Accuracy: 0.8107, Test Loss: 0.4767, Test Accuracy: 0.8107\n",
      "Epoch 6, Loss: 0.7578, Accuracy: 0.8131, Test Loss: 0.4565, Test Accuracy: 0.8107\n",
      "Epoch 7, Loss: 0.7463, Accuracy: 0.8090, Test Loss: 0.5031, Test Accuracy: 0.8037\n",
      "Epoch 8, Loss: 0.6844, Accuracy: 0.8283, Test Loss: 0.4525, Test Accuracy: 0.8131\n",
      "Epoch 9, Loss: 0.6368, Accuracy: 0.8324, Test Loss: 0.4275, Test Accuracy: 0.8224\n",
      "Epoch 10, Loss: 0.6199, Accuracy: 0.8289, Test Loss: 0.4377, Test Accuracy: 0.8224\n",
      "Epoch 11, Loss: 0.5901, Accuracy: 0.8411, Test Loss: 0.4092, Test Accuracy: 0.8388\n",
      "Epoch 12, Loss: 0.5894, Accuracy: 0.8359, Test Loss: 0.4237, Test Accuracy: 0.8388\n",
      "Epoch 13, Loss: 0.5591, Accuracy: 0.8440, Test Loss: 0.4012, Test Accuracy: 0.8458\n",
      "Epoch 14, Loss: 0.5281, Accuracy: 0.8493, Test Loss: 0.4072, Test Accuracy: 0.8341\n",
      "Epoch 15, Loss: 0.5336, Accuracy: 0.8452, Test Loss: 0.4019, Test Accuracy: 0.8341\n",
      "Epoch 16, Loss: 0.5267, Accuracy: 0.8487, Test Loss: 0.4302, Test Accuracy: 0.8294\n",
      "Epoch 17, Loss: 0.5380, Accuracy: 0.8400, Test Loss: 0.4054, Test Accuracy: 0.8341\n",
      "Epoch 18, Loss: 0.5211, Accuracy: 0.8481, Test Loss: 0.3732, Test Accuracy: 0.8458\n",
      "Epoch 19, Loss: 0.4886, Accuracy: 0.8528, Test Loss: 0.3842, Test Accuracy: 0.8458\n",
      "Epoch 20, Loss: 0.5069, Accuracy: 0.8429, Test Loss: 0.4005, Test Accuracy: 0.8435\n",
      "Epoch 21, Loss: 0.4744, Accuracy: 0.8522, Test Loss: 0.4080, Test Accuracy: 0.8435\n",
      "Epoch 22, Loss: 0.4945, Accuracy: 0.8470, Test Loss: 0.4077, Test Accuracy: 0.8388\n",
      "Epoch 23, Loss: 0.4856, Accuracy: 0.8481, Test Loss: 0.3791, Test Accuracy: 0.8364\n",
      "Epoch 24, Loss: 0.4610, Accuracy: 0.8522, Test Loss: 0.3728, Test Accuracy: 0.8505\n",
      "Epoch 25, Loss: 0.4782, Accuracy: 0.8417, Test Loss: 0.3948, Test Accuracy: 0.8411\n",
      "Epoch 26, Loss: 0.4624, Accuracy: 0.8516, Test Loss: 0.4085, Test Accuracy: 0.8318\n",
      "Epoch 27, Loss: 0.4520, Accuracy: 0.8534, Test Loss: 0.3892, Test Accuracy: 0.8435\n",
      "Epoch 28, Loss: 0.4599, Accuracy: 0.8458, Test Loss: 0.3910, Test Accuracy: 0.8458\n",
      "Epoch 29, Loss: 0.4481, Accuracy: 0.8581, Test Loss: 0.3601, Test Accuracy: 0.8481\n",
      "Epoch 30, Loss: 0.4390, Accuracy: 0.8569, Test Loss: 0.3677, Test Accuracy: 0.8528\n",
      "Epoch 31, Loss: 0.4380, Accuracy: 0.8493, Test Loss: 0.3896, Test Accuracy: 0.8481\n",
      "Epoch 32, Loss: 0.4464, Accuracy: 0.8470, Test Loss: 0.3755, Test Accuracy: 0.8481\n",
      "Epoch 33, Loss: 0.4585, Accuracy: 0.8522, Test Loss: 0.3680, Test Accuracy: 0.8481\n",
      "Epoch 34, Loss: 0.4450, Accuracy: 0.8487, Test Loss: 0.3672, Test Accuracy: 0.8458\n",
      "Epoch 35, Loss: 0.4356, Accuracy: 0.8505, Test Loss: 0.3881, Test Accuracy: 0.8388\n",
      "Epoch 36, Loss: 0.4303, Accuracy: 0.8575, Test Loss: 0.3845, Test Accuracy: 0.8411\n",
      "Epoch 37, Loss: 0.4290, Accuracy: 0.8528, Test Loss: 0.3633, Test Accuracy: 0.8598\n",
      "Epoch 38, Loss: 0.4307, Accuracy: 0.8499, Test Loss: 0.3797, Test Accuracy: 0.8575\n",
      "Epoch 39, Loss: 0.4251, Accuracy: 0.8499, Test Loss: 0.3603, Test Accuracy: 0.8551\n",
      "Epoch 40, Loss: 0.4169, Accuracy: 0.8546, Test Loss: 0.4410, Test Accuracy: 0.8224\n",
      "Epoch 41, Loss: 0.4250, Accuracy: 0.8546, Test Loss: 0.4085, Test Accuracy: 0.7850\n",
      "Epoch 42, Loss: 0.4389, Accuracy: 0.8452, Test Loss: 0.3696, Test Accuracy: 0.8528\n",
      "Epoch 43, Loss: 0.4423, Accuracy: 0.8487, Test Loss: 0.3599, Test Accuracy: 0.8505\n",
      "Epoch 44, Loss: 0.4135, Accuracy: 0.8540, Test Loss: 0.3603, Test Accuracy: 0.8505\n",
      "Epoch 45, Loss: 0.4033, Accuracy: 0.8563, Test Loss: 0.3910, Test Accuracy: 0.8505\n",
      "Epoch 46, Loss: 0.4028, Accuracy: 0.8610, Test Loss: 0.3779, Test Accuracy: 0.8458\n",
      "Epoch 47, Loss: 0.3954, Accuracy: 0.8616, Test Loss: 0.3845, Test Accuracy: 0.8505\n",
      "Epoch 48, Loss: 0.4056, Accuracy: 0.8534, Test Loss: 0.4091, Test Accuracy: 0.8388\n",
      "Epoch 49, Loss: 0.4090, Accuracy: 0.8528, Test Loss: 0.3908, Test Accuracy: 0.8458\n",
      "Epoch 50, Loss: 0.4270, Accuracy: 0.8516, Test Loss: 0.3820, Test Accuracy: 0.8505\n",
      "Epoch 51, Loss: 0.4053, Accuracy: 0.8604, Test Loss: 0.3795, Test Accuracy: 0.8341\n",
      "Epoch 52, Loss: 0.3904, Accuracy: 0.8610, Test Loss: 0.3526, Test Accuracy: 0.8505\n",
      "Epoch 53, Loss: 0.3910, Accuracy: 0.8598, Test Loss: 0.3607, Test Accuracy: 0.8505\n",
      "Epoch 54, Loss: 0.3889, Accuracy: 0.8633, Test Loss: 0.3803, Test Accuracy: 0.8481\n",
      "Epoch 55, Loss: 0.3947, Accuracy: 0.8563, Test Loss: 0.4027, Test Accuracy: 0.8411\n",
      "Epoch 56, Loss: 0.3842, Accuracy: 0.8627, Test Loss: 0.3705, Test Accuracy: 0.8505\n",
      "Epoch 57, Loss: 0.3868, Accuracy: 0.8557, Test Loss: 0.3543, Test Accuracy: 0.8575\n",
      "Epoch 58, Loss: 0.3777, Accuracy: 0.8610, Test Loss: 0.3569, Test Accuracy: 0.8528\n",
      "Epoch 59, Loss: 0.3854, Accuracy: 0.8598, Test Loss: 0.3911, Test Accuracy: 0.8528\n",
      "Epoch 60, Loss: 0.3920, Accuracy: 0.8598, Test Loss: 0.3857, Test Accuracy: 0.8458\n",
      "Epoch 61, Loss: 0.3989, Accuracy: 0.8546, Test Loss: 0.3833, Test Accuracy: 0.8411\n",
      "Epoch 62, Loss: 0.3868, Accuracy: 0.8557, Test Loss: 0.3883, Test Accuracy: 0.8435\n",
      "Epoch 63, Loss: 0.3758, Accuracy: 0.8563, Test Loss: 0.3869, Test Accuracy: 0.8458\n",
      "Epoch 64, Loss: 0.3667, Accuracy: 0.8645, Test Loss: 0.4096, Test Accuracy: 0.8481\n",
      "Epoch 65, Loss: 0.3693, Accuracy: 0.8610, Test Loss: 0.4023, Test Accuracy: 0.8435\n",
      "Epoch 66, Loss: 0.3820, Accuracy: 0.8610, Test Loss: 0.4030, Test Accuracy: 0.8388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:38:25,152] Trial 65 finished with value: 0.8598130841121495 and parameters: {'batch_size': 32, 'num_gcn_layers': 2, 'gcn_hidden_dim_0': 114, 'gcn_hidden_dim_1': 164, 'num_fc_layers': 2, 'fc_hidden_dim_0': 192, 'fc_hidden_dim_1': 231, 'learning_rate': 0.008354965091124015, 'weight_decay': 0.00019254171842944485, 'pooling_method': 'max', 'gcn_batch_norm_flag_0': False, 'gcn_batch_norm_flag_1': True, 'gcn_momentum_1': 0.841096925230596, 'gcn_eps_1': 0.00796920792806599, 'gcn_dropout_flag_0': False, 'gcn_dropout_flag_1': False, 'gcn_activation_0': 'leaky_relu', 'gcn_activation_1': 'relu', 'fc_batch_norm_flag_0': False, 'fc_batch_norm_flag_1': False, 'fc_dropout_flag_0': False, 'fc_dropout_flag_1': False, 'fc_activation_0': 'elu', 'fc_activation_1': 'leaky_relu', 'gcn_skip_connections_0': True, 'gcn_skip_connections_1': True, 'l1_lambda': 8.625991266784938e-05, 'optimizer': 'Adam', 'beta1': 0.9619651106833019, 'beta2': 0.9890464036126791, 'lr_scheduler': 'OneCycleLR', 'max_lr_1': 0.0298679913109833, 'pct_start': 0.22168673214177032, 'loss_function': 'CrossEntropy'}. Best is trial 33 with value: 0.8714953271028038.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67, Loss: 0.3778, Accuracy: 0.8633, Test Loss: 0.3993, Test Accuracy: 0.8458\n",
      "Early stopping triggered\n",
      "Epoch 1, Loss: 1.2388, Accuracy: 0.6758, Test Loss: 0.6238, Test Accuracy: 0.7757\n",
      "Epoch 2, Loss: 0.8920, Accuracy: 0.7640, Test Loss: 0.5469, Test Accuracy: 0.8061\n",
      "Epoch 3, Loss: 0.8158, Accuracy: 0.7973, Test Loss: 0.5388, Test Accuracy: 0.8037\n",
      "Epoch 4, Loss: 0.7849, Accuracy: 0.7996, Test Loss: 0.4997, Test Accuracy: 0.8084\n",
      "Epoch 5, Loss: 0.7435, Accuracy: 0.8002, Test Loss: 0.5563, Test Accuracy: 0.7991\n",
      "Epoch 6, Loss: 0.7284, Accuracy: 0.8078, Test Loss: 0.5224, Test Accuracy: 0.8084\n",
      "Epoch 7, Loss: 0.7088, Accuracy: 0.8067, Test Loss: 0.5286, Test Accuracy: 0.7827\n",
      "Epoch 8, Loss: 0.6713, Accuracy: 0.8061, Test Loss: 0.5183, Test Accuracy: 0.7780\n",
      "Epoch 9, Loss: 0.6338, Accuracy: 0.8195, Test Loss: 0.4492, Test Accuracy: 0.8178\n",
      "Epoch 10, Loss: 0.6129, Accuracy: 0.8329, Test Loss: 0.4441, Test Accuracy: 0.8178\n",
      "Epoch 11, Loss: 0.5797, Accuracy: 0.8382, Test Loss: 0.4027, Test Accuracy: 0.8364\n",
      "Epoch 12, Loss: 0.5904, Accuracy: 0.8364, Test Loss: 0.4225, Test Accuracy: 0.8224\n",
      "Epoch 13, Loss: 0.5502, Accuracy: 0.8446, Test Loss: 0.4386, Test Accuracy: 0.8248\n",
      "Epoch 14, Loss: 0.5662, Accuracy: 0.8376, Test Loss: 0.4310, Test Accuracy: 0.8364\n",
      "Epoch 15, Loss: 0.5455, Accuracy: 0.8470, Test Loss: 0.3945, Test Accuracy: 0.8388\n",
      "Epoch 16, Loss: 0.5353, Accuracy: 0.8458, Test Loss: 0.4175, Test Accuracy: 0.8271\n",
      "Epoch 17, Loss: 0.5085, Accuracy: 0.8557, Test Loss: 0.4192, Test Accuracy: 0.8364\n",
      "Epoch 18, Loss: 0.5219, Accuracy: 0.8429, Test Loss: 0.4340, Test Accuracy: 0.8294\n",
      "Epoch 19, Loss: 0.5359, Accuracy: 0.8429, Test Loss: 0.3813, Test Accuracy: 0.8435\n",
      "Epoch 20, Loss: 0.5163, Accuracy: 0.8481, Test Loss: 0.4198, Test Accuracy: 0.8271\n",
      "Epoch 21, Loss: 0.4958, Accuracy: 0.8505, Test Loss: 0.4061, Test Accuracy: 0.8271\n",
      "Epoch 22, Loss: 0.5189, Accuracy: 0.8411, Test Loss: 0.3773, Test Accuracy: 0.8481\n",
      "Epoch 23, Loss: 0.5059, Accuracy: 0.8481, Test Loss: 0.4446, Test Accuracy: 0.8248\n",
      "Epoch 24, Loss: 0.4832, Accuracy: 0.8481, Test Loss: 0.3961, Test Accuracy: 0.8411\n",
      "Epoch 25, Loss: 0.4802, Accuracy: 0.8528, Test Loss: 0.4129, Test Accuracy: 0.8224\n",
      "Epoch 26, Loss: 0.4808, Accuracy: 0.8505, Test Loss: 0.3813, Test Accuracy: 0.8505\n",
      "Epoch 27, Loss: 0.4813, Accuracy: 0.8446, Test Loss: 0.4407, Test Accuracy: 0.8224\n",
      "Epoch 28, Loss: 0.4812, Accuracy: 0.8429, Test Loss: 0.4088, Test Accuracy: 0.8294\n",
      "Epoch 29, Loss: 0.4985, Accuracy: 0.8370, Test Loss: 0.4007, Test Accuracy: 0.8411\n",
      "Epoch 30, Loss: 0.4878, Accuracy: 0.8435, Test Loss: 0.4467, Test Accuracy: 0.8224\n",
      "Epoch 31, Loss: 0.4780, Accuracy: 0.8481, Test Loss: 0.3887, Test Accuracy: 0.8435\n",
      "Epoch 32, Loss: 0.4748, Accuracy: 0.8475, Test Loss: 0.3772, Test Accuracy: 0.8388\n",
      "Epoch 33, Loss: 0.4530, Accuracy: 0.8540, Test Loss: 0.4199, Test Accuracy: 0.8411\n",
      "Epoch 34, Loss: 0.4452, Accuracy: 0.8528, Test Loss: 0.3990, Test Accuracy: 0.8364\n",
      "Epoch 35, Loss: 0.4772, Accuracy: 0.8394, Test Loss: 0.4045, Test Accuracy: 0.8271\n",
      "Epoch 36, Loss: 0.4933, Accuracy: 0.8388, Test Loss: 0.3759, Test Accuracy: 0.8551\n",
      "Epoch 37, Loss: 0.4599, Accuracy: 0.8511, Test Loss: 0.3815, Test Accuracy: 0.8528\n",
      "Epoch 38, Loss: 0.4548, Accuracy: 0.8452, Test Loss: 0.3651, Test Accuracy: 0.8575\n",
      "Epoch 39, Loss: 0.4331, Accuracy: 0.8563, Test Loss: 0.3956, Test Accuracy: 0.8458\n",
      "Epoch 40, Loss: 0.4308, Accuracy: 0.8581, Test Loss: 0.3792, Test Accuracy: 0.8528\n",
      "Epoch 41, Loss: 0.4237, Accuracy: 0.8592, Test Loss: 0.3798, Test Accuracy: 0.8481\n",
      "Epoch 42, Loss: 0.4272, Accuracy: 0.8598, Test Loss: 0.4015, Test Accuracy: 0.8364\n",
      "Epoch 43, Loss: 0.4417, Accuracy: 0.8481, Test Loss: 0.4230, Test Accuracy: 0.8411\n",
      "Epoch 44, Loss: 0.4302, Accuracy: 0.8516, Test Loss: 0.3627, Test Accuracy: 0.8505\n",
      "Epoch 45, Loss: 0.4306, Accuracy: 0.8563, Test Loss: 0.3630, Test Accuracy: 0.8551\n",
      "Epoch 46, Loss: 0.4216, Accuracy: 0.8610, Test Loss: 0.3652, Test Accuracy: 0.8551\n",
      "Epoch 47, Loss: 0.4444, Accuracy: 0.8417, Test Loss: 0.4130, Test Accuracy: 0.8294\n",
      "Epoch 48, Loss: 0.4269, Accuracy: 0.8516, Test Loss: 0.3824, Test Accuracy: 0.8458\n",
      "Epoch 49, Loss: 0.4318, Accuracy: 0.8563, Test Loss: 0.4076, Test Accuracy: 0.8411\n",
      "Epoch 50, Loss: 0.4239, Accuracy: 0.8505, Test Loss: 0.3835, Test Accuracy: 0.8481\n",
      "Epoch 51, Loss: 0.4009, Accuracy: 0.8598, Test Loss: 0.3611, Test Accuracy: 0.8551\n",
      "Epoch 52, Loss: 0.4102, Accuracy: 0.8581, Test Loss: 0.3919, Test Accuracy: 0.8411\n",
      "Epoch 53, Loss: 0.4112, Accuracy: 0.8557, Test Loss: 0.3977, Test Accuracy: 0.8435\n",
      "Epoch 54, Loss: 0.4365, Accuracy: 0.8446, Test Loss: 0.3789, Test Accuracy: 0.8411\n",
      "Epoch 55, Loss: 0.4112, Accuracy: 0.8627, Test Loss: 0.3778, Test Accuracy: 0.8528\n",
      "Epoch 56, Loss: 0.4034, Accuracy: 0.8592, Test Loss: 0.4151, Test Accuracy: 0.8458\n",
      "Epoch 57, Loss: 0.4008, Accuracy: 0.8621, Test Loss: 0.3951, Test Accuracy: 0.8411\n",
      "Epoch 58, Loss: 0.4011, Accuracy: 0.8575, Test Loss: 0.3798, Test Accuracy: 0.8551\n",
      "Epoch 59, Loss: 0.3997, Accuracy: 0.8621, Test Loss: 0.4217, Test Accuracy: 0.8505\n",
      "Epoch 60, Loss: 0.3953, Accuracy: 0.8610, Test Loss: 0.4113, Test Accuracy: 0.8505\n",
      "Epoch 61, Loss: 0.3936, Accuracy: 0.8586, Test Loss: 0.3858, Test Accuracy: 0.8551\n",
      "Epoch 62, Loss: 0.3987, Accuracy: 0.8692, Test Loss: 0.4000, Test Accuracy: 0.8481\n",
      "Epoch 63, Loss: 0.3954, Accuracy: 0.8639, Test Loss: 0.4812, Test Accuracy: 0.8154\n",
      "Epoch 64, Loss: 0.3917, Accuracy: 0.8627, Test Loss: 0.4022, Test Accuracy: 0.8458\n",
      "Epoch 65, Loss: 0.3809, Accuracy: 0.8598, Test Loss: 0.4112, Test Accuracy: 0.8505\n",
      "Epoch 66, Loss: 0.3851, Accuracy: 0.8651, Test Loss: 0.3989, Test Accuracy: 0.8505\n",
      "Epoch 67, Loss: 0.3905, Accuracy: 0.8651, Test Loss: 0.3884, Test Accuracy: 0.8481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:40:28,289] Trial 66 finished with value: 0.8574766355140186 and parameters: {'batch_size': 32, 'num_gcn_layers': 2, 'gcn_hidden_dim_0': 54, 'gcn_hidden_dim_1': 173, 'num_fc_layers': 2, 'fc_hidden_dim_0': 134, 'fc_hidden_dim_1': 87, 'learning_rate': 0.004691007859631903, 'weight_decay': 0.00012484235105806566, 'pooling_method': 'max', 'gcn_batch_norm_flag_0': False, 'gcn_batch_norm_flag_1': True, 'gcn_momentum_1': 0.8648081766186982, 'gcn_eps_1': 0.00800330570479605, 'gcn_dropout_flag_0': False, 'gcn_dropout_flag_1': False, 'gcn_activation_0': 'leaky_relu', 'gcn_activation_1': 'relu', 'fc_batch_norm_flag_0': False, 'fc_batch_norm_flag_1': False, 'fc_dropout_flag_0': False, 'fc_dropout_flag_1': False, 'fc_activation_0': 'elu', 'fc_activation_1': 'leaky_relu', 'gcn_skip_connections_0': True, 'gcn_skip_connections_1': True, 'l1_lambda': 0.00010063087257346863, 'optimizer': 'Adam', 'beta1': 0.9625622283904557, 'beta2': 0.9989343086583419, 'lr_scheduler': 'OneCycleLR', 'max_lr_1': 0.02980802642416406, 'pct_start': 0.23579718885299641, 'loss_function': 'CrossEntropy'}. Best is trial 33 with value: 0.8714953271028038.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68, Loss: 0.4063, Accuracy: 0.8551, Test Loss: 0.4183, Test Accuracy: 0.7897\n",
      "Early stopping triggered\n",
      "Epoch 1, Loss: 0.5567, Accuracy: 0.6706, Test Loss: 0.1353, Test Accuracy: 0.7593\n",
      "Epoch 2, Loss: 0.3992, Accuracy: 0.7769, Test Loss: 0.1114, Test Accuracy: 0.7991\n",
      "Epoch 3, Loss: 0.3396, Accuracy: 0.8008, Test Loss: 0.1085, Test Accuracy: 0.8037\n",
      "Epoch 4, Loss: 0.3000, Accuracy: 0.8026, Test Loss: 0.0911, Test Accuracy: 0.8061\n",
      "Epoch 5, Loss: 0.2643, Accuracy: 0.8061, Test Loss: 0.0926, Test Accuracy: 0.8084\n",
      "Epoch 6, Loss: 0.2334, Accuracy: 0.8067, Test Loss: 0.0999, Test Accuracy: 0.8037\n",
      "Epoch 7, Loss: 0.2130, Accuracy: 0.8078, Test Loss: 0.0916, Test Accuracy: 0.8084\n",
      "Epoch 8, Loss: 0.1947, Accuracy: 0.8055, Test Loss: 0.0870, Test Accuracy: 0.8084\n",
      "Epoch 9, Loss: 0.1798, Accuracy: 0.8061, Test Loss: 0.0876, Test Accuracy: 0.8107\n",
      "Epoch 10, Loss: 0.1711, Accuracy: 0.8090, Test Loss: 0.0891, Test Accuracy: 0.8084\n",
      "Epoch 11, Loss: 0.1578, Accuracy: 0.8113, Test Loss: 0.0840, Test Accuracy: 0.8131\n",
      "Epoch 12, Loss: 0.1455, Accuracy: 0.8189, Test Loss: 0.0744, Test Accuracy: 0.8178\n",
      "Epoch 13, Loss: 0.1428, Accuracy: 0.8230, Test Loss: 0.0855, Test Accuracy: 0.8154\n",
      "Epoch 14, Loss: 0.1359, Accuracy: 0.8277, Test Loss: 0.0729, Test Accuracy: 0.8294\n",
      "Epoch 15, Loss: 0.1288, Accuracy: 0.8359, Test Loss: 0.0723, Test Accuracy: 0.8201\n",
      "Epoch 16, Loss: 0.1247, Accuracy: 0.8306, Test Loss: 0.0668, Test Accuracy: 0.8341\n",
      "Epoch 17, Loss: 0.1225, Accuracy: 0.8347, Test Loss: 0.0890, Test Accuracy: 0.8154\n",
      "Epoch 18, Loss: 0.1180, Accuracy: 0.8318, Test Loss: 0.0657, Test Accuracy: 0.8318\n",
      "Epoch 19, Loss: 0.1123, Accuracy: 0.8382, Test Loss: 0.0665, Test Accuracy: 0.8294\n",
      "Epoch 20, Loss: 0.1118, Accuracy: 0.8394, Test Loss: 0.0683, Test Accuracy: 0.8294\n",
      "Epoch 21, Loss: 0.1089, Accuracy: 0.8353, Test Loss: 0.0656, Test Accuracy: 0.8341\n",
      "Epoch 22, Loss: 0.1041, Accuracy: 0.8470, Test Loss: 0.0680, Test Accuracy: 0.8271\n",
      "Epoch 23, Loss: 0.1072, Accuracy: 0.8353, Test Loss: 0.0652, Test Accuracy: 0.8411\n",
      "Epoch 24, Loss: 0.1018, Accuracy: 0.8435, Test Loss: 0.0652, Test Accuracy: 0.8364\n",
      "Epoch 25, Loss: 0.0984, Accuracy: 0.8411, Test Loss: 0.0682, Test Accuracy: 0.8248\n",
      "Epoch 26, Loss: 0.1008, Accuracy: 0.8353, Test Loss: 0.0710, Test Accuracy: 0.8294\n",
      "Epoch 27, Loss: 0.0990, Accuracy: 0.8405, Test Loss: 0.0605, Test Accuracy: 0.8435\n",
      "Epoch 28, Loss: 0.0958, Accuracy: 0.8423, Test Loss: 0.0619, Test Accuracy: 0.8341\n",
      "Epoch 29, Loss: 0.0943, Accuracy: 0.8487, Test Loss: 0.0613, Test Accuracy: 0.8388\n",
      "Epoch 30, Loss: 0.0915, Accuracy: 0.8487, Test Loss: 0.0614, Test Accuracy: 0.8458\n",
      "Epoch 31, Loss: 0.0972, Accuracy: 0.8417, Test Loss: 0.0595, Test Accuracy: 0.8481\n",
      "Epoch 32, Loss: 0.0895, Accuracy: 0.8487, Test Loss: 0.0615, Test Accuracy: 0.8388\n",
      "Epoch 33, Loss: 0.0877, Accuracy: 0.8464, Test Loss: 0.0654, Test Accuracy: 0.8388\n",
      "Epoch 34, Loss: 0.0871, Accuracy: 0.8487, Test Loss: 0.0597, Test Accuracy: 0.8528\n",
      "Epoch 35, Loss: 0.0863, Accuracy: 0.8458, Test Loss: 0.0605, Test Accuracy: 0.8458\n",
      "Epoch 36, Loss: 0.0881, Accuracy: 0.8475, Test Loss: 0.0545, Test Accuracy: 0.8598\n",
      "Epoch 37, Loss: 0.0871, Accuracy: 0.8440, Test Loss: 0.0624, Test Accuracy: 0.8388\n",
      "Epoch 38, Loss: 0.0883, Accuracy: 0.8435, Test Loss: 0.0568, Test Accuracy: 0.8481\n",
      "Epoch 39, Loss: 0.0852, Accuracy: 0.8481, Test Loss: 0.0595, Test Accuracy: 0.8505\n",
      "Epoch 40, Loss: 0.0871, Accuracy: 0.8446, Test Loss: 0.0581, Test Accuracy: 0.8528\n",
      "Epoch 41, Loss: 0.0847, Accuracy: 0.8452, Test Loss: 0.0565, Test Accuracy: 0.8505\n",
      "Epoch 42, Loss: 0.0811, Accuracy: 0.8499, Test Loss: 0.0646, Test Accuracy: 0.8341\n",
      "Epoch 43, Loss: 0.0817, Accuracy: 0.8540, Test Loss: 0.0645, Test Accuracy: 0.8341\n",
      "Epoch 44, Loss: 0.0811, Accuracy: 0.8505, Test Loss: 0.0573, Test Accuracy: 0.8551\n",
      "Epoch 45, Loss: 0.0819, Accuracy: 0.8464, Test Loss: 0.0569, Test Accuracy: 0.8621\n",
      "Epoch 46, Loss: 0.0802, Accuracy: 0.8487, Test Loss: 0.0573, Test Accuracy: 0.8435\n",
      "Epoch 47, Loss: 0.0810, Accuracy: 0.8511, Test Loss: 0.0567, Test Accuracy: 0.8458\n",
      "Epoch 48, Loss: 0.0835, Accuracy: 0.8458, Test Loss: 0.0757, Test Accuracy: 0.8294\n",
      "Epoch 49, Loss: 0.0822, Accuracy: 0.8487, Test Loss: 0.0607, Test Accuracy: 0.8435\n",
      "Epoch 50, Loss: 0.0787, Accuracy: 0.8511, Test Loss: 0.0543, Test Accuracy: 0.8551\n",
      "Epoch 51, Loss: 0.0799, Accuracy: 0.8481, Test Loss: 0.0583, Test Accuracy: 0.8551\n",
      "Epoch 52, Loss: 0.0782, Accuracy: 0.8493, Test Loss: 0.0547, Test Accuracy: 0.8575\n",
      "Epoch 53, Loss: 0.0778, Accuracy: 0.8505, Test Loss: 0.0518, Test Accuracy: 0.8575\n",
      "Epoch 54, Loss: 0.0763, Accuracy: 0.8528, Test Loss: 0.0592, Test Accuracy: 0.8481\n",
      "Epoch 55, Loss: 0.0766, Accuracy: 0.8481, Test Loss: 0.0555, Test Accuracy: 0.8505\n",
      "Epoch 56, Loss: 0.0784, Accuracy: 0.8475, Test Loss: 0.0579, Test Accuracy: 0.8435\n",
      "Epoch 57, Loss: 0.0743, Accuracy: 0.8528, Test Loss: 0.0539, Test Accuracy: 0.8621\n",
      "Epoch 58, Loss: 0.0776, Accuracy: 0.8516, Test Loss: 0.0555, Test Accuracy: 0.8458\n",
      "Epoch 59, Loss: 0.0789, Accuracy: 0.8487, Test Loss: 0.0597, Test Accuracy: 0.8435\n",
      "Epoch 60, Loss: 0.0798, Accuracy: 0.8458, Test Loss: 0.0540, Test Accuracy: 0.8481\n",
      "Epoch 61, Loss: 0.0775, Accuracy: 0.8505, Test Loss: 0.0538, Test Accuracy: 0.8551\n",
      "Epoch 62, Loss: 0.0743, Accuracy: 0.8511, Test Loss: 0.0543, Test Accuracy: 0.8575\n",
      "Epoch 63, Loss: 0.0750, Accuracy: 0.8475, Test Loss: 0.0557, Test Accuracy: 0.8575\n",
      "Epoch 64, Loss: 0.0807, Accuracy: 0.8394, Test Loss: 0.0564, Test Accuracy: 0.8505\n",
      "Epoch 65, Loss: 0.0781, Accuracy: 0.8499, Test Loss: 0.0605, Test Accuracy: 0.8411\n",
      "Epoch 66, Loss: 0.0753, Accuracy: 0.8505, Test Loss: 0.0568, Test Accuracy: 0.8575\n",
      "Epoch 67, Loss: 0.0736, Accuracy: 0.8487, Test Loss: 0.0559, Test Accuracy: 0.8551\n",
      "Epoch 68, Loss: 0.0726, Accuracy: 0.8540, Test Loss: 0.0582, Test Accuracy: 0.8528\n",
      "Epoch 69, Loss: 0.0740, Accuracy: 0.8516, Test Loss: 0.0598, Test Accuracy: 0.8481\n",
      "Epoch 70, Loss: 0.0744, Accuracy: 0.8487, Test Loss: 0.0732, Test Accuracy: 0.8388\n",
      "Epoch 71, Loss: 0.0734, Accuracy: 0.8481, Test Loss: 0.0528, Test Accuracy: 0.8575\n",
      "Epoch 72, Loss: 0.0745, Accuracy: 0.8487, Test Loss: 0.0540, Test Accuracy: 0.8575\n",
      "Epoch 73, Loss: 0.0767, Accuracy: 0.8464, Test Loss: 0.0598, Test Accuracy: 0.8458\n",
      "Epoch 74, Loss: 0.0733, Accuracy: 0.8499, Test Loss: 0.0557, Test Accuracy: 0.8458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:42:51,123] Trial 67 finished with value: 0.8621495327102804 and parameters: {'batch_size': 32, 'num_gcn_layers': 2, 'gcn_hidden_dim_0': 90, 'gcn_hidden_dim_1': 170, 'num_fc_layers': 2, 'fc_hidden_dim_0': 149, 'fc_hidden_dim_1': 73, 'learning_rate': 0.0020141354457956975, 'weight_decay': 0.00011135933478359481, 'pooling_method': 'max', 'gcn_batch_norm_flag_0': False, 'gcn_batch_norm_flag_1': True, 'gcn_momentum_1': 0.8171475554991641, 'gcn_eps_1': 0.008079166966397445, 'gcn_dropout_flag_0': False, 'gcn_dropout_flag_1': False, 'gcn_activation_0': 'leaky_relu', 'gcn_activation_1': 'relu', 'fc_batch_norm_flag_0': False, 'fc_batch_norm_flag_1': False, 'fc_dropout_flag_0': False, 'fc_dropout_flag_1': False, 'fc_activation_0': 'elu', 'fc_activation_1': 'leaky_relu', 'gcn_skip_connections_0': True, 'gcn_skip_connections_1': True, 'l1_lambda': 8.134641927894464e-05, 'optimizer': 'Adam', 'beta1': 0.961765017479785, 'beta2': 0.9896829737393797, 'lr_scheduler': 'OneCycleLR', 'max_lr_1': 0.027599220459317376, 'pct_start': 0.22763250945938007, 'loss_function': 'MultiMargin'}. Best is trial 33 with value: 0.8714953271028038.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75, Loss: 0.0731, Accuracy: 0.8499, Test Loss: 0.0558, Test Accuracy: 0.8621\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:42:53,172] Trial 68 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6045, Accuracy: 0.6495, Test Loss: 0.1438, Test Accuracy: 0.7220\n",
      "Epoch 1, Loss: 0.5906, Accuracy: 0.6320, Test Loss: 0.1711, Test Accuracy: 0.7523\n",
      "Epoch 2, Loss: 0.4255, Accuracy: 0.7202, Test Loss: 0.1810, Test Accuracy: 0.7804\n",
      "Epoch 3, Loss: 0.3545, Accuracy: 0.7296, Test Loss: 0.1910, Test Accuracy: 0.7804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:43:00,663] Trial 69 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.3101, Accuracy: 0.7500, Test Loss: 0.1483, Test Accuracy: 0.7640\n",
      "Epoch 1, Loss: 0.9927, Accuracy: 0.7056, Test Loss: 0.1174, Test Accuracy: 0.7780\n",
      "Epoch 2, Loss: 0.7774, Accuracy: 0.7833, Test Loss: 0.1020, Test Accuracy: 0.8084\n",
      "Epoch 3, Loss: 0.6218, Accuracy: 0.7956, Test Loss: 0.0987, Test Accuracy: 0.7874\n",
      "Epoch 4, Loss: 0.4966, Accuracy: 0.8032, Test Loss: 0.1028, Test Accuracy: 0.8107\n",
      "Epoch 5, Loss: 0.4029, Accuracy: 0.8043, Test Loss: 0.0949, Test Accuracy: 0.8037\n",
      "Epoch 6, Loss: 0.3297, Accuracy: 0.8026, Test Loss: 0.0903, Test Accuracy: 0.8131\n",
      "Epoch 7, Loss: 0.2836, Accuracy: 0.8026, Test Loss: 0.0899, Test Accuracy: 0.8084\n",
      "Epoch 8, Loss: 0.2420, Accuracy: 0.8049, Test Loss: 0.0912, Test Accuracy: 0.8084\n",
      "Epoch 9, Loss: 0.2175, Accuracy: 0.8055, Test Loss: 0.0878, Test Accuracy: 0.8154\n",
      "Epoch 10, Loss: 0.1979, Accuracy: 0.8102, Test Loss: 0.0847, Test Accuracy: 0.8154\n",
      "Epoch 11, Loss: 0.1829, Accuracy: 0.8096, Test Loss: 0.0762, Test Accuracy: 0.8154\n",
      "Epoch 12, Loss: 0.1744, Accuracy: 0.8078, Test Loss: 0.0819, Test Accuracy: 0.8131\n",
      "Epoch 13, Loss: 0.1637, Accuracy: 0.8119, Test Loss: 0.0763, Test Accuracy: 0.8154\n",
      "Epoch 14, Loss: 0.1543, Accuracy: 0.8183, Test Loss: 0.0752, Test Accuracy: 0.8178\n",
      "Epoch 15, Loss: 0.1498, Accuracy: 0.8183, Test Loss: 0.0758, Test Accuracy: 0.8178\n",
      "Epoch 16, Loss: 0.1447, Accuracy: 0.8178, Test Loss: 0.0773, Test Accuracy: 0.8178\n",
      "Epoch 17, Loss: 0.1387, Accuracy: 0.8160, Test Loss: 0.0762, Test Accuracy: 0.8248\n",
      "Epoch 18, Loss: 0.1340, Accuracy: 0.8195, Test Loss: 0.0718, Test Accuracy: 0.8248\n",
      "Epoch 19, Loss: 0.1306, Accuracy: 0.8189, Test Loss: 0.0730, Test Accuracy: 0.8271\n",
      "Epoch 20, Loss: 0.1279, Accuracy: 0.8195, Test Loss: 0.0699, Test Accuracy: 0.8271\n",
      "Epoch 21, Loss: 0.1244, Accuracy: 0.8218, Test Loss: 0.0684, Test Accuracy: 0.8248\n",
      "Epoch 22, Loss: 0.1222, Accuracy: 0.8224, Test Loss: 0.0714, Test Accuracy: 0.8201\n",
      "Epoch 23, Loss: 0.1174, Accuracy: 0.8224, Test Loss: 0.0670, Test Accuracy: 0.8318\n",
      "Epoch 24, Loss: 0.1123, Accuracy: 0.8353, Test Loss: 0.0722, Test Accuracy: 0.8341\n",
      "Epoch 25, Loss: 0.1089, Accuracy: 0.8341, Test Loss: 0.0637, Test Accuracy: 0.8481\n",
      "Epoch 26, Loss: 0.1032, Accuracy: 0.8470, Test Loss: 0.0616, Test Accuracy: 0.8505\n",
      "Epoch 27, Loss: 0.1027, Accuracy: 0.8435, Test Loss: 0.0582, Test Accuracy: 0.8528\n",
      "Epoch 28, Loss: 0.0999, Accuracy: 0.8511, Test Loss: 0.0547, Test Accuracy: 0.8621\n",
      "Epoch 29, Loss: 0.0998, Accuracy: 0.8487, Test Loss: 0.0552, Test Accuracy: 0.8598\n",
      "Epoch 30, Loss: 0.0986, Accuracy: 0.8499, Test Loss: 0.0554, Test Accuracy: 0.8598\n",
      "Epoch 31, Loss: 0.0964, Accuracy: 0.8487, Test Loss: 0.0594, Test Accuracy: 0.8458\n",
      "Epoch 32, Loss: 0.0979, Accuracy: 0.8446, Test Loss: 0.0556, Test Accuracy: 0.8505\n",
      "Epoch 33, Loss: 0.0959, Accuracy: 0.8493, Test Loss: 0.0559, Test Accuracy: 0.8575\n",
      "Epoch 34, Loss: 0.0947, Accuracy: 0.8516, Test Loss: 0.0663, Test Accuracy: 0.8364\n",
      "Epoch 35, Loss: 0.0970, Accuracy: 0.8429, Test Loss: 0.0544, Test Accuracy: 0.8598\n",
      "Epoch 36, Loss: 0.0955, Accuracy: 0.8493, Test Loss: 0.0620, Test Accuracy: 0.8458\n",
      "Epoch 37, Loss: 0.0952, Accuracy: 0.8511, Test Loss: 0.0595, Test Accuracy: 0.8505\n",
      "Epoch 38, Loss: 0.0942, Accuracy: 0.8464, Test Loss: 0.0571, Test Accuracy: 0.8481\n",
      "Epoch 39, Loss: 0.0937, Accuracy: 0.8475, Test Loss: 0.0572, Test Accuracy: 0.8435\n",
      "Epoch 40, Loss: 0.0945, Accuracy: 0.8470, Test Loss: 0.0672, Test Accuracy: 0.8411\n",
      "Epoch 41, Loss: 0.0955, Accuracy: 0.8382, Test Loss: 0.0586, Test Accuracy: 0.8528\n",
      "Epoch 42, Loss: 0.0930, Accuracy: 0.8464, Test Loss: 0.0627, Test Accuracy: 0.8481\n",
      "Epoch 43, Loss: 0.0918, Accuracy: 0.8499, Test Loss: 0.0571, Test Accuracy: 0.8528\n",
      "Epoch 44, Loss: 0.0904, Accuracy: 0.8470, Test Loss: 0.0567, Test Accuracy: 0.8528\n",
      "Epoch 45, Loss: 0.0904, Accuracy: 0.8493, Test Loss: 0.0622, Test Accuracy: 0.8481\n",
      "Epoch 46, Loss: 0.0870, Accuracy: 0.8540, Test Loss: 0.0601, Test Accuracy: 0.8481\n",
      "Epoch 47, Loss: 0.0886, Accuracy: 0.8475, Test Loss: 0.0606, Test Accuracy: 0.8528\n",
      "Epoch 48, Loss: 0.0888, Accuracy: 0.8493, Test Loss: 0.0556, Test Accuracy: 0.8458\n",
      "Epoch 49, Loss: 0.0877, Accuracy: 0.8470, Test Loss: 0.0540, Test Accuracy: 0.8505\n",
      "Epoch 50, Loss: 0.0873, Accuracy: 0.8499, Test Loss: 0.0532, Test Accuracy: 0.8551\n",
      "Epoch 51, Loss: 0.0882, Accuracy: 0.8481, Test Loss: 0.0557, Test Accuracy: 0.8645\n",
      "Epoch 52, Loss: 0.0855, Accuracy: 0.8528, Test Loss: 0.0569, Test Accuracy: 0.8481\n",
      "Epoch 53, Loss: 0.0856, Accuracy: 0.8516, Test Loss: 0.0521, Test Accuracy: 0.8598\n",
      "Epoch 54, Loss: 0.0845, Accuracy: 0.8528, Test Loss: 0.0559, Test Accuracy: 0.8528\n",
      "Epoch 55, Loss: 0.0875, Accuracy: 0.8475, Test Loss: 0.0555, Test Accuracy: 0.8528\n",
      "Epoch 56, Loss: 0.0861, Accuracy: 0.8516, Test Loss: 0.0601, Test Accuracy: 0.8411\n",
      "Epoch 57, Loss: 0.0859, Accuracy: 0.8493, Test Loss: 0.0528, Test Accuracy: 0.8621\n",
      "Epoch 58, Loss: 0.0859, Accuracy: 0.8505, Test Loss: 0.0559, Test Accuracy: 0.8598\n",
      "Epoch 59, Loss: 0.0874, Accuracy: 0.8446, Test Loss: 0.0538, Test Accuracy: 0.8551\n",
      "Epoch 60, Loss: 0.0863, Accuracy: 0.8493, Test Loss: 0.0534, Test Accuracy: 0.8621\n",
      "Epoch 61, Loss: 0.0861, Accuracy: 0.8499, Test Loss: 0.0512, Test Accuracy: 0.8645\n",
      "Epoch 62, Loss: 0.0848, Accuracy: 0.8505, Test Loss: 0.0578, Test Accuracy: 0.8528\n",
      "Epoch 63, Loss: 0.0833, Accuracy: 0.8516, Test Loss: 0.0592, Test Accuracy: 0.8528\n",
      "Epoch 64, Loss: 0.0823, Accuracy: 0.8516, Test Loss: 0.0530, Test Accuracy: 0.8645\n",
      "Epoch 65, Loss: 0.0832, Accuracy: 0.8516, Test Loss: 0.0579, Test Accuracy: 0.8458\n",
      "Epoch 66, Loss: 0.0836, Accuracy: 0.8487, Test Loss: 0.0526, Test Accuracy: 0.8551\n",
      "Epoch 67, Loss: 0.0824, Accuracy: 0.8528, Test Loss: 0.0586, Test Accuracy: 0.8435\n",
      "Epoch 68, Loss: 0.0877, Accuracy: 0.8493, Test Loss: 0.0600, Test Accuracy: 0.8458\n",
      "Epoch 69, Loss: 0.0843, Accuracy: 0.8470, Test Loss: 0.0579, Test Accuracy: 0.8505\n",
      "Epoch 70, Loss: 0.0836, Accuracy: 0.8522, Test Loss: 0.0599, Test Accuracy: 0.8505\n",
      "Epoch 71, Loss: 0.0835, Accuracy: 0.8516, Test Loss: 0.0530, Test Accuracy: 0.8575\n",
      "Epoch 72, Loss: 0.0825, Accuracy: 0.8546, Test Loss: 0.0556, Test Accuracy: 0.8575\n",
      "Epoch 73, Loss: 0.0817, Accuracy: 0.8511, Test Loss: 0.0594, Test Accuracy: 0.8551\n",
      "Epoch 74, Loss: 0.0838, Accuracy: 0.8522, Test Loss: 0.0562, Test Accuracy: 0.8575\n",
      "Epoch 75, Loss: 0.0831, Accuracy: 0.8505, Test Loss: 0.0552, Test Accuracy: 0.8645\n",
      "Epoch 76, Loss: 0.0810, Accuracy: 0.8505, Test Loss: 0.0521, Test Accuracy: 0.8598\n",
      "Epoch 77, Loss: 0.0822, Accuracy: 0.8499, Test Loss: 0.0529, Test Accuracy: 0.8551\n",
      "Epoch 78, Loss: 0.0812, Accuracy: 0.8511, Test Loss: 0.0583, Test Accuracy: 0.8505\n",
      "Epoch 79, Loss: 0.0801, Accuracy: 0.8557, Test Loss: 0.0532, Test Accuracy: 0.8598\n",
      "Epoch 80, Loss: 0.0801, Accuracy: 0.8522, Test Loss: 0.0573, Test Accuracy: 0.8598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:45:48,913] Trial 70 finished with value: 0.8644859813084113 and parameters: {'batch_size': 32, 'num_gcn_layers': 2, 'gcn_hidden_dim_0': 119, 'gcn_hidden_dim_1': 193, 'num_fc_layers': 2, 'fc_hidden_dim_0': 187, 'fc_hidden_dim_1': 69, 'learning_rate': 0.004163724355704378, 'weight_decay': 0.00012740094506649726, 'pooling_method': 'max', 'gcn_batch_norm_flag_0': False, 'gcn_batch_norm_flag_1': True, 'gcn_momentum_1': 0.9215131646343839, 'gcn_eps_1': 0.00896661862860916, 'gcn_dropout_flag_0': False, 'gcn_dropout_flag_1': False, 'gcn_activation_0': 'leaky_relu', 'gcn_activation_1': 'relu', 'fc_batch_norm_flag_0': False, 'fc_batch_norm_flag_1': True, 'fc_momentum_1': 0.5478955040955209, 'fc_eps_1': 0.0029454438609194757, 'fc_dropout_flag_0': False, 'fc_dropout_flag_1': True, 'fc_dropout_rate_1': 0.19533640973128796, 'fc_activation_0': 'elu', 'fc_activation_1': 'leaky_relu', 'gcn_skip_connections_0': False, 'gcn_skip_connections_1': True, 'l1_lambda': 0.00016528188611109192, 'optimizer': 'Adam', 'beta1': 0.9633061377324038, 'beta2': 0.9951382785087535, 'lr_scheduler': 'OneCycleLR', 'max_lr_1': 0.03171175076789733, 'pct_start': 0.18302735463526834, 'loss_function': 'MultiMargin'}. Best is trial 33 with value: 0.8714953271028038.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81, Loss: 0.0796, Accuracy: 0.8540, Test Loss: 0.0577, Test Accuracy: 0.8551\n",
      "Early stopping triggered\n",
      "Epoch 1, Loss: 1.0033, Accuracy: 0.7044, Test Loss: 0.1198, Test Accuracy: 0.7734\n",
      "Epoch 2, Loss: 0.7800, Accuracy: 0.7897, Test Loss: 0.1023, Test Accuracy: 0.8037\n",
      "Epoch 3, Loss: 0.6421, Accuracy: 0.8002, Test Loss: 0.1026, Test Accuracy: 0.8061\n",
      "Epoch 4, Loss: 0.5293, Accuracy: 0.8008, Test Loss: 0.0954, Test Accuracy: 0.8084\n",
      "Epoch 5, Loss: 0.4318, Accuracy: 0.8049, Test Loss: 0.0901, Test Accuracy: 0.8084\n",
      "Epoch 6, Loss: 0.3564, Accuracy: 0.8061, Test Loss: 0.0976, Test Accuracy: 0.8107\n",
      "Epoch 7, Loss: 0.3014, Accuracy: 0.8049, Test Loss: 0.0818, Test Accuracy: 0.8107\n",
      "Epoch 8, Loss: 0.2594, Accuracy: 0.8107, Test Loss: 0.0844, Test Accuracy: 0.8107\n",
      "Epoch 9, Loss: 0.2350, Accuracy: 0.8102, Test Loss: 0.0874, Test Accuracy: 0.8178\n",
      "Epoch 10, Loss: 0.2096, Accuracy: 0.8172, Test Loss: 0.0774, Test Accuracy: 0.8341\n",
      "Epoch 11, Loss: 0.1871, Accuracy: 0.8259, Test Loss: 0.0736, Test Accuracy: 0.8294\n",
      "Epoch 12, Loss: 0.1754, Accuracy: 0.8382, Test Loss: 0.0689, Test Accuracy: 0.8388\n",
      "Epoch 13, Loss: 0.1674, Accuracy: 0.8324, Test Loss: 0.0690, Test Accuracy: 0.8341\n",
      "Epoch 14, Loss: 0.1560, Accuracy: 0.8364, Test Loss: 0.0661, Test Accuracy: 0.8458\n",
      "Epoch 15, Loss: 0.1514, Accuracy: 0.8423, Test Loss: 0.0669, Test Accuracy: 0.8294\n",
      "Epoch 16, Loss: 0.1447, Accuracy: 0.8458, Test Loss: 0.0623, Test Accuracy: 0.8598\n",
      "Epoch 17, Loss: 0.1379, Accuracy: 0.8382, Test Loss: 0.0680, Test Accuracy: 0.8411\n",
      "Epoch 18, Loss: 0.1371, Accuracy: 0.8341, Test Loss: 0.0708, Test Accuracy: 0.8435\n",
      "Epoch 19, Loss: 0.1324, Accuracy: 0.8411, Test Loss: 0.0598, Test Accuracy: 0.8481\n",
      "Epoch 20, Loss: 0.1253, Accuracy: 0.8429, Test Loss: 0.0581, Test Accuracy: 0.8575\n",
      "Epoch 21, Loss: 0.1218, Accuracy: 0.8405, Test Loss: 0.0616, Test Accuracy: 0.8481\n",
      "Epoch 22, Loss: 0.1227, Accuracy: 0.8417, Test Loss: 0.0643, Test Accuracy: 0.8458\n",
      "Epoch 23, Loss: 0.1173, Accuracy: 0.8464, Test Loss: 0.0656, Test Accuracy: 0.8411\n",
      "Epoch 24, Loss: 0.1144, Accuracy: 0.8464, Test Loss: 0.0690, Test Accuracy: 0.8458\n",
      "Epoch 25, Loss: 0.1120, Accuracy: 0.8435, Test Loss: 0.0658, Test Accuracy: 0.8411\n",
      "Epoch 26, Loss: 0.1088, Accuracy: 0.8499, Test Loss: 0.0599, Test Accuracy: 0.8621\n",
      "Epoch 27, Loss: 0.1103, Accuracy: 0.8400, Test Loss: 0.0749, Test Accuracy: 0.8364\n",
      "Epoch 28, Loss: 0.1072, Accuracy: 0.8464, Test Loss: 0.0562, Test Accuracy: 0.8528\n",
      "Epoch 29, Loss: 0.1027, Accuracy: 0.8487, Test Loss: 0.0563, Test Accuracy: 0.8575\n",
      "Epoch 30, Loss: 0.1046, Accuracy: 0.8464, Test Loss: 0.0710, Test Accuracy: 0.8411\n",
      "Epoch 31, Loss: 0.1031, Accuracy: 0.8446, Test Loss: 0.0567, Test Accuracy: 0.8621\n",
      "Epoch 32, Loss: 0.1016, Accuracy: 0.8458, Test Loss: 0.0619, Test Accuracy: 0.8458\n",
      "Epoch 33, Loss: 0.1009, Accuracy: 0.8464, Test Loss: 0.0549, Test Accuracy: 0.8551\n",
      "Epoch 34, Loss: 0.1005, Accuracy: 0.8446, Test Loss: 0.0596, Test Accuracy: 0.8505\n",
      "Epoch 35, Loss: 0.0994, Accuracy: 0.8481, Test Loss: 0.0582, Test Accuracy: 0.8598\n",
      "Epoch 36, Loss: 0.1001, Accuracy: 0.8429, Test Loss: 0.0645, Test Accuracy: 0.8388\n",
      "Epoch 37, Loss: 0.0969, Accuracy: 0.8458, Test Loss: 0.0551, Test Accuracy: 0.8575\n",
      "Epoch 38, Loss: 0.0982, Accuracy: 0.8458, Test Loss: 0.0578, Test Accuracy: 0.8551\n",
      "Epoch 39, Loss: 0.0982, Accuracy: 0.8481, Test Loss: 0.0585, Test Accuracy: 0.8458\n",
      "Epoch 40, Loss: 0.0995, Accuracy: 0.8429, Test Loss: 0.0598, Test Accuracy: 0.8388\n",
      "Epoch 41, Loss: 0.0978, Accuracy: 0.8400, Test Loss: 0.0583, Test Accuracy: 0.8505\n",
      "Epoch 42, Loss: 0.1000, Accuracy: 0.8411, Test Loss: 0.0648, Test Accuracy: 0.8458\n",
      "Epoch 43, Loss: 0.0961, Accuracy: 0.8446, Test Loss: 0.0582, Test Accuracy: 0.8551\n",
      "Epoch 44, Loss: 0.0933, Accuracy: 0.8487, Test Loss: 0.0552, Test Accuracy: 0.8598\n",
      "Epoch 45, Loss: 0.0970, Accuracy: 0.8429, Test Loss: 0.0636, Test Accuracy: 0.8481\n",
      "Epoch 46, Loss: 0.0934, Accuracy: 0.8475, Test Loss: 0.0601, Test Accuracy: 0.8645\n",
      "Epoch 47, Loss: 0.0926, Accuracy: 0.8475, Test Loss: 0.0648, Test Accuracy: 0.8505\n",
      "Epoch 48, Loss: 0.0940, Accuracy: 0.8475, Test Loss: 0.0594, Test Accuracy: 0.8575\n",
      "Epoch 49, Loss: 0.0924, Accuracy: 0.8481, Test Loss: 0.0576, Test Accuracy: 0.8505\n",
      "Epoch 50, Loss: 0.0914, Accuracy: 0.8499, Test Loss: 0.0559, Test Accuracy: 0.8481\n",
      "Epoch 51, Loss: 0.0889, Accuracy: 0.8499, Test Loss: 0.0573, Test Accuracy: 0.8575\n",
      "Epoch 52, Loss: 0.0935, Accuracy: 0.8435, Test Loss: 0.0590, Test Accuracy: 0.8435\n",
      "Epoch 53, Loss: 0.0894, Accuracy: 0.8511, Test Loss: 0.0597, Test Accuracy: 0.8551\n",
      "Epoch 54, Loss: 0.0903, Accuracy: 0.8452, Test Loss: 0.0547, Test Accuracy: 0.8668\n",
      "Epoch 55, Loss: 0.0880, Accuracy: 0.8493, Test Loss: 0.0572, Test Accuracy: 0.8575\n",
      "Epoch 56, Loss: 0.0877, Accuracy: 0.8528, Test Loss: 0.0572, Test Accuracy: 0.8551\n",
      "Epoch 57, Loss: 0.0884, Accuracy: 0.8493, Test Loss: 0.0585, Test Accuracy: 0.8551\n",
      "Epoch 58, Loss: 0.0868, Accuracy: 0.8511, Test Loss: 0.0633, Test Accuracy: 0.8435\n",
      "Epoch 59, Loss: 0.0873, Accuracy: 0.8499, Test Loss: 0.0729, Test Accuracy: 0.8271\n",
      "Epoch 60, Loss: 0.0882, Accuracy: 0.8481, Test Loss: 0.0554, Test Accuracy: 0.8551\n",
      "Epoch 61, Loss: 0.0843, Accuracy: 0.8540, Test Loss: 0.0578, Test Accuracy: 0.8575\n",
      "Epoch 62, Loss: 0.0854, Accuracy: 0.8522, Test Loss: 0.0550, Test Accuracy: 0.8575\n",
      "Epoch 63, Loss: 0.0846, Accuracy: 0.8534, Test Loss: 0.0589, Test Accuracy: 0.8575\n",
      "Epoch 64, Loss: 0.0840, Accuracy: 0.8540, Test Loss: 0.0540, Test Accuracy: 0.8575\n",
      "Epoch 65, Loss: 0.0863, Accuracy: 0.8499, Test Loss: 0.0565, Test Accuracy: 0.8692\n",
      "Epoch 66, Loss: 0.0853, Accuracy: 0.8522, Test Loss: 0.0619, Test Accuracy: 0.8411\n",
      "Epoch 67, Loss: 0.0844, Accuracy: 0.8540, Test Loss: 0.0570, Test Accuracy: 0.8645\n",
      "Epoch 68, Loss: 0.0833, Accuracy: 0.8557, Test Loss: 0.0588, Test Accuracy: 0.8528\n",
      "Epoch 69, Loss: 0.0842, Accuracy: 0.8505, Test Loss: 0.0610, Test Accuracy: 0.8505\n",
      "Epoch 70, Loss: 0.0809, Accuracy: 0.8551, Test Loss: 0.0601, Test Accuracy: 0.8505\n",
      "Epoch 71, Loss: 0.0816, Accuracy: 0.8522, Test Loss: 0.0566, Test Accuracy: 0.8551\n",
      "Epoch 72, Loss: 0.0856, Accuracy: 0.8475, Test Loss: 0.0560, Test Accuracy: 0.8528\n",
      "Epoch 73, Loss: 0.0905, Accuracy: 0.8446, Test Loss: 0.0577, Test Accuracy: 0.8598\n",
      "Epoch 74, Loss: 0.0878, Accuracy: 0.8446, Test Loss: 0.0569, Test Accuracy: 0.8598\n",
      "Epoch 75, Loss: 0.0849, Accuracy: 0.8516, Test Loss: 0.0587, Test Accuracy: 0.8598\n",
      "Epoch 76, Loss: 0.0857, Accuracy: 0.8511, Test Loss: 0.0640, Test Accuracy: 0.8528\n",
      "Epoch 77, Loss: 0.0846, Accuracy: 0.8499, Test Loss: 0.0558, Test Accuracy: 0.8598\n",
      "Epoch 78, Loss: 0.0850, Accuracy: 0.8487, Test Loss: 0.0599, Test Accuracy: 0.8481\n",
      "Epoch 79, Loss: 0.0847, Accuracy: 0.8511, Test Loss: 0.0617, Test Accuracy: 0.8505\n",
      "Epoch 80, Loss: 0.0827, Accuracy: 0.8522, Test Loss: 0.0536, Test Accuracy: 0.8598\n",
      "Epoch 81, Loss: 0.0824, Accuracy: 0.8522, Test Loss: 0.0544, Test Accuracy: 0.8551\n",
      "Epoch 82, Loss: 0.0818, Accuracy: 0.8511, Test Loss: 0.0572, Test Accuracy: 0.8551\n",
      "Epoch 83, Loss: 0.0847, Accuracy: 0.8493, Test Loss: 0.0525, Test Accuracy: 0.8645\n",
      "Epoch 84, Loss: 0.0829, Accuracy: 0.8528, Test Loss: 0.0582, Test Accuracy: 0.8575\n",
      "Epoch 85, Loss: 0.0845, Accuracy: 0.8493, Test Loss: 0.0599, Test Accuracy: 0.8551\n",
      "Epoch 86, Loss: 0.0838, Accuracy: 0.8487, Test Loss: 0.0592, Test Accuracy: 0.8598\n",
      "Epoch 87, Loss: 0.0844, Accuracy: 0.8505, Test Loss: 0.0608, Test Accuracy: 0.8411\n",
      "Epoch 88, Loss: 0.0846, Accuracy: 0.8470, Test Loss: 0.0557, Test Accuracy: 0.8598\n",
      "Epoch 89, Loss: 0.0845, Accuracy: 0.8481, Test Loss: 0.0556, Test Accuracy: 0.8528\n",
      "Epoch 90, Loss: 0.0835, Accuracy: 0.8481, Test Loss: 0.0570, Test Accuracy: 0.8551\n",
      "Epoch 91, Loss: 0.0815, Accuracy: 0.8540, Test Loss: 0.0532, Test Accuracy: 0.8645\n",
      "Epoch 92, Loss: 0.0802, Accuracy: 0.8569, Test Loss: 0.0579, Test Accuracy: 0.8505\n",
      "Epoch 93, Loss: 0.0825, Accuracy: 0.8516, Test Loss: 0.0606, Test Accuracy: 0.8505\n",
      "Epoch 94, Loss: 0.0817, Accuracy: 0.8546, Test Loss: 0.0524, Test Accuracy: 0.8598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:48:54,196] Trial 71 finished with value: 0.8691588785046729 and parameters: {'batch_size': 32, 'num_gcn_layers': 2, 'gcn_hidden_dim_0': 104, 'gcn_hidden_dim_1': 189, 'num_fc_layers': 2, 'fc_hidden_dim_0': 190, 'fc_hidden_dim_1': 55, 'learning_rate': 0.004857951325613948, 'weight_decay': 6.673454326953518e-05, 'pooling_method': 'max', 'gcn_batch_norm_flag_0': False, 'gcn_batch_norm_flag_1': True, 'gcn_momentum_1': 0.9300105749830784, 'gcn_eps_1': 0.009076645737887343, 'gcn_dropout_flag_0': False, 'gcn_dropout_flag_1': False, 'gcn_activation_0': 'leaky_relu', 'gcn_activation_1': 'relu', 'fc_batch_norm_flag_0': False, 'fc_batch_norm_flag_1': True, 'fc_momentum_1': 0.5519387480998934, 'fc_eps_1': 0.0031123238616837527, 'fc_dropout_flag_0': False, 'fc_dropout_flag_1': True, 'fc_dropout_rate_1': 0.19713986891438723, 'fc_activation_0': 'elu', 'fc_activation_1': 'leaky_relu', 'gcn_skip_connections_0': False, 'gcn_skip_connections_1': True, 'l1_lambda': 0.00017360622156543422, 'optimizer': 'Adam', 'beta1': 0.9614198355234179, 'beta2': 0.9960191555073256, 'lr_scheduler': 'OneCycleLR', 'max_lr_1': 0.03178526918326632, 'pct_start': 0.17487844109895162, 'loss_function': 'MultiMargin'}. Best is trial 33 with value: 0.8714953271028038.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95, Loss: 0.0802, Accuracy: 0.8557, Test Loss: 0.0589, Test Accuracy: 0.8551\n",
      "Early stopping triggered\n",
      "Epoch 1, Loss: 1.0338, Accuracy: 0.7167, Test Loss: 0.1105, Test Accuracy: 0.7874\n",
      "Epoch 2, Loss: 0.7655, Accuracy: 0.7956, Test Loss: 0.0939, Test Accuracy: 0.8061\n",
      "Epoch 3, Loss: 0.5879, Accuracy: 0.7996, Test Loss: 0.0914, Test Accuracy: 0.8084\n",
      "Epoch 4, Loss: 0.4450, Accuracy: 0.8032, Test Loss: 0.0895, Test Accuracy: 0.8084\n",
      "Epoch 5, Loss: 0.3439, Accuracy: 0.8037, Test Loss: 0.0903, Test Accuracy: 0.8084\n",
      "Epoch 6, Loss: 0.2721, Accuracy: 0.8078, Test Loss: 0.0848, Test Accuracy: 0.8131\n",
      "Epoch 7, Loss: 0.2372, Accuracy: 0.8043, Test Loss: 0.0856, Test Accuracy: 0.8061\n",
      "Epoch 8, Loss: 0.2097, Accuracy: 0.8049, Test Loss: 0.0834, Test Accuracy: 0.8131\n",
      "Epoch 9, Loss: 0.1890, Accuracy: 0.8072, Test Loss: 0.0874, Test Accuracy: 0.8131\n",
      "Epoch 10, Loss: 0.1729, Accuracy: 0.8137, Test Loss: 0.0791, Test Accuracy: 0.8154\n",
      "Epoch 11, Loss: 0.1639, Accuracy: 0.8125, Test Loss: 0.0752, Test Accuracy: 0.8154\n",
      "Epoch 12, Loss: 0.1508, Accuracy: 0.8189, Test Loss: 0.0747, Test Accuracy: 0.8435\n",
      "Epoch 13, Loss: 0.1378, Accuracy: 0.8353, Test Loss: 0.0688, Test Accuracy: 0.8224\n",
      "Epoch 14, Loss: 0.1331, Accuracy: 0.8347, Test Loss: 0.0712, Test Accuracy: 0.8318\n",
      "Epoch 15, Loss: 0.1244, Accuracy: 0.8470, Test Loss: 0.0605, Test Accuracy: 0.8435\n",
      "Epoch 16, Loss: 0.1203, Accuracy: 0.8417, Test Loss: 0.0651, Test Accuracy: 0.8341\n",
      "Epoch 17, Loss: 0.1182, Accuracy: 0.8347, Test Loss: 0.0662, Test Accuracy: 0.8528\n",
      "Epoch 18, Loss: 0.1166, Accuracy: 0.8400, Test Loss: 0.0649, Test Accuracy: 0.8505\n",
      "Epoch 19, Loss: 0.1087, Accuracy: 0.8464, Test Loss: 0.0615, Test Accuracy: 0.8505\n",
      "Epoch 20, Loss: 0.1067, Accuracy: 0.8481, Test Loss: 0.0577, Test Accuracy: 0.8528\n",
      "Epoch 21, Loss: 0.1057, Accuracy: 0.8405, Test Loss: 0.0623, Test Accuracy: 0.8411\n",
      "Epoch 22, Loss: 0.1058, Accuracy: 0.8382, Test Loss: 0.0584, Test Accuracy: 0.8458\n",
      "Epoch 23, Loss: 0.1034, Accuracy: 0.8452, Test Loss: 0.0615, Test Accuracy: 0.8481\n",
      "Epoch 24, Loss: 0.1008, Accuracy: 0.8481, Test Loss: 0.0573, Test Accuracy: 0.8551\n",
      "Epoch 25, Loss: 0.1022, Accuracy: 0.8405, Test Loss: 0.0574, Test Accuracy: 0.8528\n",
      "Epoch 26, Loss: 0.1011, Accuracy: 0.8458, Test Loss: 0.0565, Test Accuracy: 0.8505\n",
      "Epoch 27, Loss: 0.0992, Accuracy: 0.8411, Test Loss: 0.0566, Test Accuracy: 0.8551\n",
      "Epoch 28, Loss: 0.0992, Accuracy: 0.8470, Test Loss: 0.0626, Test Accuracy: 0.8528\n",
      "Epoch 29, Loss: 0.0993, Accuracy: 0.8464, Test Loss: 0.0561, Test Accuracy: 0.8458\n",
      "Epoch 30, Loss: 0.0975, Accuracy: 0.8417, Test Loss: 0.0579, Test Accuracy: 0.8575\n",
      "Epoch 31, Loss: 0.0939, Accuracy: 0.8475, Test Loss: 0.0585, Test Accuracy: 0.8528\n",
      "Epoch 32, Loss: 0.0935, Accuracy: 0.8511, Test Loss: 0.0604, Test Accuracy: 0.8505\n",
      "Epoch 33, Loss: 0.0944, Accuracy: 0.8487, Test Loss: 0.0571, Test Accuracy: 0.8551\n",
      "Epoch 34, Loss: 0.0932, Accuracy: 0.8481, Test Loss: 0.0596, Test Accuracy: 0.8458\n",
      "Epoch 35, Loss: 0.0942, Accuracy: 0.8481, Test Loss: 0.0636, Test Accuracy: 0.8528\n",
      "Epoch 36, Loss: 0.0927, Accuracy: 0.8481, Test Loss: 0.0568, Test Accuracy: 0.8505\n",
      "Epoch 37, Loss: 0.0916, Accuracy: 0.8493, Test Loss: 0.0591, Test Accuracy: 0.8528\n",
      "Epoch 38, Loss: 0.0920, Accuracy: 0.8481, Test Loss: 0.0549, Test Accuracy: 0.8481\n",
      "Epoch 39, Loss: 0.0898, Accuracy: 0.8487, Test Loss: 0.0561, Test Accuracy: 0.8551\n",
      "Epoch 40, Loss: 0.0934, Accuracy: 0.8458, Test Loss: 0.0612, Test Accuracy: 0.8435\n",
      "Epoch 41, Loss: 0.0908, Accuracy: 0.8481, Test Loss: 0.0549, Test Accuracy: 0.8528\n",
      "Epoch 42, Loss: 0.0899, Accuracy: 0.8493, Test Loss: 0.0549, Test Accuracy: 0.8575\n",
      "Epoch 43, Loss: 0.0885, Accuracy: 0.8505, Test Loss: 0.0556, Test Accuracy: 0.8575\n",
      "Epoch 44, Loss: 0.0872, Accuracy: 0.8528, Test Loss: 0.0540, Test Accuracy: 0.8575\n",
      "Epoch 45, Loss: 0.0900, Accuracy: 0.8446, Test Loss: 0.0537, Test Accuracy: 0.8598\n",
      "Epoch 46, Loss: 0.0909, Accuracy: 0.8487, Test Loss: 0.0613, Test Accuracy: 0.8435\n",
      "Epoch 47, Loss: 0.0881, Accuracy: 0.8534, Test Loss: 0.0536, Test Accuracy: 0.8551\n",
      "Epoch 48, Loss: 0.0898, Accuracy: 0.8475, Test Loss: 0.0585, Test Accuracy: 0.8528\n",
      "Epoch 49, Loss: 0.0889, Accuracy: 0.8534, Test Loss: 0.0519, Test Accuracy: 0.8575\n",
      "Epoch 50, Loss: 0.0863, Accuracy: 0.8528, Test Loss: 0.0517, Test Accuracy: 0.8598\n",
      "Epoch 51, Loss: 0.0882, Accuracy: 0.8511, Test Loss: 0.0570, Test Accuracy: 0.8505\n",
      "Epoch 52, Loss: 0.0872, Accuracy: 0.8534, Test Loss: 0.0525, Test Accuracy: 0.8621\n",
      "Epoch 53, Loss: 0.0876, Accuracy: 0.8499, Test Loss: 0.0530, Test Accuracy: 0.8645\n",
      "Epoch 54, Loss: 0.0842, Accuracy: 0.8540, Test Loss: 0.0529, Test Accuracy: 0.8621\n",
      "Epoch 55, Loss: 0.0836, Accuracy: 0.8540, Test Loss: 0.0535, Test Accuracy: 0.8575\n",
      "Epoch 56, Loss: 0.0841, Accuracy: 0.8528, Test Loss: 0.0533, Test Accuracy: 0.8575\n",
      "Epoch 57, Loss: 0.0870, Accuracy: 0.8470, Test Loss: 0.0624, Test Accuracy: 0.8505\n",
      "Epoch 58, Loss: 0.0900, Accuracy: 0.8446, Test Loss: 0.0541, Test Accuracy: 0.8621\n",
      "Epoch 59, Loss: 0.0852, Accuracy: 0.8505, Test Loss: 0.0577, Test Accuracy: 0.8505\n",
      "Epoch 60, Loss: 0.0875, Accuracy: 0.8481, Test Loss: 0.0603, Test Accuracy: 0.8388\n",
      "Epoch 61, Loss: 0.0846, Accuracy: 0.8534, Test Loss: 0.0554, Test Accuracy: 0.8528\n",
      "Epoch 62, Loss: 0.0851, Accuracy: 0.8493, Test Loss: 0.0637, Test Accuracy: 0.8458\n",
      "Epoch 63, Loss: 0.0849, Accuracy: 0.8499, Test Loss: 0.0545, Test Accuracy: 0.8435\n",
      "Epoch 64, Loss: 0.0826, Accuracy: 0.8534, Test Loss: 0.0521, Test Accuracy: 0.8598\n",
      "Epoch 65, Loss: 0.0873, Accuracy: 0.8470, Test Loss: 0.0559, Test Accuracy: 0.8458\n",
      "Epoch 66, Loss: 0.0867, Accuracy: 0.8505, Test Loss: 0.0604, Test Accuracy: 0.8528\n",
      "Epoch 67, Loss: 0.0846, Accuracy: 0.8528, Test Loss: 0.0512, Test Accuracy: 0.8551\n",
      "Epoch 68, Loss: 0.0828, Accuracy: 0.8546, Test Loss: 0.0520, Test Accuracy: 0.8598\n",
      "Epoch 69, Loss: 0.0815, Accuracy: 0.8575, Test Loss: 0.0519, Test Accuracy: 0.8645\n",
      "Epoch 70, Loss: 0.0819, Accuracy: 0.8551, Test Loss: 0.0531, Test Accuracy: 0.8551\n",
      "Epoch 71, Loss: 0.0841, Accuracy: 0.8464, Test Loss: 0.0544, Test Accuracy: 0.8575\n",
      "Epoch 72, Loss: 0.0812, Accuracy: 0.8528, Test Loss: 0.0571, Test Accuracy: 0.8458\n",
      "Epoch 73, Loss: 0.0801, Accuracy: 0.8546, Test Loss: 0.0543, Test Accuracy: 0.8598\n",
      "Epoch 74, Loss: 0.0818, Accuracy: 0.8528, Test Loss: 0.0559, Test Accuracy: 0.8458\n",
      "Epoch 75, Loss: 0.0814, Accuracy: 0.8546, Test Loss: 0.0637, Test Accuracy: 0.8411\n",
      "Epoch 76, Loss: 0.0823, Accuracy: 0.8551, Test Loss: 0.0516, Test Accuracy: 0.8551\n",
      "Epoch 77, Loss: 0.0848, Accuracy: 0.8458, Test Loss: 0.0499, Test Accuracy: 0.8621\n",
      "Epoch 78, Loss: 0.0826, Accuracy: 0.8528, Test Loss: 0.0550, Test Accuracy: 0.8481\n",
      "Epoch 79, Loss: 0.0812, Accuracy: 0.8522, Test Loss: 0.0531, Test Accuracy: 0.8575\n",
      "Epoch 80, Loss: 0.0809, Accuracy: 0.8528, Test Loss: 0.0531, Test Accuracy: 0.8575\n",
      "Epoch 81, Loss: 0.0823, Accuracy: 0.8487, Test Loss: 0.0607, Test Accuracy: 0.8481\n",
      "Epoch 82, Loss: 0.0822, Accuracy: 0.8470, Test Loss: 0.0534, Test Accuracy: 0.8528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:51:45,757] Trial 72 finished with value: 0.8644859813084113 and parameters: {'batch_size': 32, 'num_gcn_layers': 2, 'gcn_hidden_dim_0': 118, 'gcn_hidden_dim_1': 197, 'num_fc_layers': 2, 'fc_hidden_dim_0': 190, 'fc_hidden_dim_1': 54, 'learning_rate': 0.003906321948238241, 'weight_decay': 4.990502669580872e-05, 'pooling_method': 'max', 'gcn_batch_norm_flag_0': False, 'gcn_batch_norm_flag_1': True, 'gcn_momentum_1': 0.923636652406087, 'gcn_eps_1': 0.00918112424340333, 'gcn_dropout_flag_0': False, 'gcn_dropout_flag_1': False, 'gcn_activation_0': 'leaky_relu', 'gcn_activation_1': 'relu', 'fc_batch_norm_flag_0': False, 'fc_batch_norm_flag_1': True, 'fc_momentum_1': 0.5367279779235763, 'fc_eps_1': 0.0031354048403611687, 'fc_dropout_flag_0': False, 'fc_dropout_flag_1': True, 'fc_dropout_rate_1': 0.19295041662400633, 'fc_activation_0': 'elu', 'fc_activation_1': 'leaky_relu', 'gcn_skip_connections_0': False, 'gcn_skip_connections_1': True, 'l1_lambda': 0.00017491380041839602, 'optimizer': 'Adam', 'beta1': 0.9485514554435464, 'beta2': 0.9910684211712, 'lr_scheduler': 'OneCycleLR', 'max_lr_1': 0.035771307866196145, 'pct_start': 0.16603801208612043, 'loss_function': 'MultiMargin'}. Best is trial 33 with value: 0.8714953271028038.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83, Loss: 0.0840, Accuracy: 0.8505, Test Loss: 0.0519, Test Accuracy: 0.8621\n",
      "Early stopping triggered\n",
      "Epoch 1, Loss: 0.9096, Accuracy: 0.7190, Test Loss: 0.1062, Test Accuracy: 0.7804\n",
      "Epoch 2, Loss: 0.6974, Accuracy: 0.7950, Test Loss: 0.0995, Test Accuracy: 0.7944\n",
      "Epoch 3, Loss: 0.5626, Accuracy: 0.8002, Test Loss: 0.0927, Test Accuracy: 0.8061\n",
      "Epoch 4, Loss: 0.4498, Accuracy: 0.8084, Test Loss: 0.0882, Test Accuracy: 0.8107\n",
      "Epoch 5, Loss: 0.3619, Accuracy: 0.8043, Test Loss: 0.0905, Test Accuracy: 0.8084\n",
      "Epoch 6, Loss: 0.3005, Accuracy: 0.8049, Test Loss: 0.0803, Test Accuracy: 0.8154\n",
      "Epoch 7, Loss: 0.2526, Accuracy: 0.8102, Test Loss: 0.0904, Test Accuracy: 0.8061\n",
      "Epoch 8, Loss: 0.2229, Accuracy: 0.8072, Test Loss: 0.0851, Test Accuracy: 0.8154\n",
      "Epoch 9, Loss: 0.1954, Accuracy: 0.8125, Test Loss: 0.0846, Test Accuracy: 0.8131\n",
      "Epoch 10, Loss: 0.1768, Accuracy: 0.8137, Test Loss: 0.0780, Test Accuracy: 0.8154\n",
      "Epoch 11, Loss: 0.1583, Accuracy: 0.8353, Test Loss: 0.0723, Test Accuracy: 0.8131\n",
      "Epoch 12, Loss: 0.1583, Accuracy: 0.8259, Test Loss: 0.0675, Test Accuracy: 0.8364\n",
      "Epoch 13, Loss: 0.1441, Accuracy: 0.8400, Test Loss: 0.0726, Test Accuracy: 0.8341\n",
      "Epoch 14, Loss: 0.1408, Accuracy: 0.8324, Test Loss: 0.0674, Test Accuracy: 0.8388\n",
      "Epoch 15, Loss: 0.1325, Accuracy: 0.8423, Test Loss: 0.0720, Test Accuracy: 0.8364\n",
      "Epoch 16, Loss: 0.1274, Accuracy: 0.8440, Test Loss: 0.0622, Test Accuracy: 0.8411\n",
      "Epoch 17, Loss: 0.1231, Accuracy: 0.8446, Test Loss: 0.0718, Test Accuracy: 0.8411\n",
      "Epoch 18, Loss: 0.1197, Accuracy: 0.8464, Test Loss: 0.0668, Test Accuracy: 0.8388\n",
      "Epoch 19, Loss: 0.1146, Accuracy: 0.8475, Test Loss: 0.0623, Test Accuracy: 0.8411\n",
      "Epoch 20, Loss: 0.1115, Accuracy: 0.8417, Test Loss: 0.0673, Test Accuracy: 0.8435\n",
      "Epoch 21, Loss: 0.1103, Accuracy: 0.8464, Test Loss: 0.0633, Test Accuracy: 0.8364\n",
      "Epoch 22, Loss: 0.1058, Accuracy: 0.8458, Test Loss: 0.0656, Test Accuracy: 0.8318\n",
      "Epoch 23, Loss: 0.1056, Accuracy: 0.8452, Test Loss: 0.0607, Test Accuracy: 0.8458\n",
      "Epoch 24, Loss: 0.1023, Accuracy: 0.8452, Test Loss: 0.0621, Test Accuracy: 0.8458\n",
      "Epoch 25, Loss: 0.1042, Accuracy: 0.8417, Test Loss: 0.0618, Test Accuracy: 0.8481\n",
      "Epoch 26, Loss: 0.1020, Accuracy: 0.8470, Test Loss: 0.0581, Test Accuracy: 0.8528\n",
      "Epoch 27, Loss: 0.0984, Accuracy: 0.8475, Test Loss: 0.0640, Test Accuracy: 0.8481\n",
      "Epoch 28, Loss: 0.0995, Accuracy: 0.8464, Test Loss: 0.0607, Test Accuracy: 0.8458\n",
      "Epoch 29, Loss: 0.0973, Accuracy: 0.8499, Test Loss: 0.0565, Test Accuracy: 0.8575\n",
      "Epoch 30, Loss: 0.0972, Accuracy: 0.8499, Test Loss: 0.0658, Test Accuracy: 0.8458\n",
      "Epoch 31, Loss: 0.0982, Accuracy: 0.8446, Test Loss: 0.0560, Test Accuracy: 0.8528\n",
      "Epoch 32, Loss: 0.0965, Accuracy: 0.8487, Test Loss: 0.0542, Test Accuracy: 0.8551\n",
      "Epoch 33, Loss: 0.0953, Accuracy: 0.8435, Test Loss: 0.0587, Test Accuracy: 0.8481\n",
      "Epoch 34, Loss: 0.0946, Accuracy: 0.8493, Test Loss: 0.0561, Test Accuracy: 0.8598\n",
      "Epoch 35, Loss: 0.0937, Accuracy: 0.8511, Test Loss: 0.0602, Test Accuracy: 0.8551\n",
      "Epoch 36, Loss: 0.0911, Accuracy: 0.8505, Test Loss: 0.0738, Test Accuracy: 0.8318\n",
      "Epoch 37, Loss: 0.0926, Accuracy: 0.8493, Test Loss: 0.0529, Test Accuracy: 0.8598\n",
      "Epoch 38, Loss: 0.0914, Accuracy: 0.8493, Test Loss: 0.0598, Test Accuracy: 0.8481\n",
      "Epoch 39, Loss: 0.0937, Accuracy: 0.8499, Test Loss: 0.0559, Test Accuracy: 0.8598\n",
      "Epoch 40, Loss: 0.0901, Accuracy: 0.8458, Test Loss: 0.0613, Test Accuracy: 0.8435\n",
      "Epoch 41, Loss: 0.0892, Accuracy: 0.8475, Test Loss: 0.0602, Test Accuracy: 0.8388\n",
      "Epoch 42, Loss: 0.0894, Accuracy: 0.8458, Test Loss: 0.0534, Test Accuracy: 0.8598\n",
      "Epoch 43, Loss: 0.0868, Accuracy: 0.8528, Test Loss: 0.0601, Test Accuracy: 0.8528\n",
      "Epoch 44, Loss: 0.0894, Accuracy: 0.8475, Test Loss: 0.0604, Test Accuracy: 0.8528\n",
      "Epoch 45, Loss: 0.0872, Accuracy: 0.8534, Test Loss: 0.0571, Test Accuracy: 0.8528\n",
      "Epoch 46, Loss: 0.0891, Accuracy: 0.8499, Test Loss: 0.0566, Test Accuracy: 0.8575\n",
      "Epoch 47, Loss: 0.0862, Accuracy: 0.8511, Test Loss: 0.0573, Test Accuracy: 0.8505\n",
      "Epoch 48, Loss: 0.0832, Accuracy: 0.8551, Test Loss: 0.0525, Test Accuracy: 0.8551\n",
      "Epoch 49, Loss: 0.0857, Accuracy: 0.8493, Test Loss: 0.0531, Test Accuracy: 0.8598\n",
      "Epoch 50, Loss: 0.0862, Accuracy: 0.8493, Test Loss: 0.0549, Test Accuracy: 0.8598\n",
      "Epoch 51, Loss: 0.0846, Accuracy: 0.8511, Test Loss: 0.0545, Test Accuracy: 0.8551\n",
      "Epoch 52, Loss: 0.0829, Accuracy: 0.8546, Test Loss: 0.0564, Test Accuracy: 0.8645\n",
      "Epoch 53, Loss: 0.0849, Accuracy: 0.8528, Test Loss: 0.0595, Test Accuracy: 0.8528\n",
      "Epoch 54, Loss: 0.0843, Accuracy: 0.8493, Test Loss: 0.0560, Test Accuracy: 0.8575\n",
      "Epoch 55, Loss: 0.0845, Accuracy: 0.8470, Test Loss: 0.0538, Test Accuracy: 0.8551\n",
      "Epoch 56, Loss: 0.0832, Accuracy: 0.8534, Test Loss: 0.0536, Test Accuracy: 0.8598\n",
      "Epoch 57, Loss: 0.0834, Accuracy: 0.8505, Test Loss: 0.0550, Test Accuracy: 0.8575\n",
      "Epoch 58, Loss: 0.0820, Accuracy: 0.8534, Test Loss: 0.0634, Test Accuracy: 0.8411\n",
      "Epoch 59, Loss: 0.0858, Accuracy: 0.8464, Test Loss: 0.0583, Test Accuracy: 0.8505\n",
      "Epoch 60, Loss: 0.0838, Accuracy: 0.8505, Test Loss: 0.0566, Test Accuracy: 0.8505\n",
      "Epoch 61, Loss: 0.0823, Accuracy: 0.8534, Test Loss: 0.0530, Test Accuracy: 0.8575\n",
      "Epoch 62, Loss: 0.0829, Accuracy: 0.8511, Test Loss: 0.0525, Test Accuracy: 0.8575\n",
      "Epoch 63, Loss: 0.0839, Accuracy: 0.8511, Test Loss: 0.0573, Test Accuracy: 0.8575\n",
      "Epoch 64, Loss: 0.0833, Accuracy: 0.8540, Test Loss: 0.0620, Test Accuracy: 0.8458\n",
      "Epoch 65, Loss: 0.0811, Accuracy: 0.8551, Test Loss: 0.0630, Test Accuracy: 0.8505\n",
      "Epoch 66, Loss: 0.0843, Accuracy: 0.8493, Test Loss: 0.0541, Test Accuracy: 0.8645\n",
      "Epoch 67, Loss: 0.0824, Accuracy: 0.8534, Test Loss: 0.0546, Test Accuracy: 0.8528\n",
      "Epoch 68, Loss: 0.0821, Accuracy: 0.8546, Test Loss: 0.0649, Test Accuracy: 0.8435\n",
      "Epoch 69, Loss: 0.0814, Accuracy: 0.8551, Test Loss: 0.0540, Test Accuracy: 0.8551\n",
      "Epoch 70, Loss: 0.0821, Accuracy: 0.8516, Test Loss: 0.0583, Test Accuracy: 0.8481\n",
      "Epoch 71, Loss: 0.0808, Accuracy: 0.8534, Test Loss: 0.0523, Test Accuracy: 0.8505\n",
      "Epoch 72, Loss: 0.0835, Accuracy: 0.8499, Test Loss: 0.0518, Test Accuracy: 0.8598\n",
      "Epoch 73, Loss: 0.0794, Accuracy: 0.8557, Test Loss: 0.0578, Test Accuracy: 0.8528\n",
      "Epoch 74, Loss: 0.0803, Accuracy: 0.8551, Test Loss: 0.0533, Test Accuracy: 0.8575\n",
      "Epoch 75, Loss: 0.0800, Accuracy: 0.8557, Test Loss: 0.0557, Test Accuracy: 0.8575\n",
      "Epoch 76, Loss: 0.0811, Accuracy: 0.8534, Test Loss: 0.0718, Test Accuracy: 0.8341\n",
      "Epoch 77, Loss: 0.0800, Accuracy: 0.8522, Test Loss: 0.0519, Test Accuracy: 0.8645\n",
      "Epoch 78, Loss: 0.0791, Accuracy: 0.8581, Test Loss: 0.0580, Test Accuracy: 0.8575\n",
      "Epoch 79, Loss: 0.0800, Accuracy: 0.8557, Test Loss: 0.0550, Test Accuracy: 0.8645\n",
      "Epoch 80, Loss: 0.0812, Accuracy: 0.8534, Test Loss: 0.0680, Test Accuracy: 0.8364\n",
      "Epoch 81, Loss: 0.0789, Accuracy: 0.8540, Test Loss: 0.0606, Test Accuracy: 0.8411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:54:29,153] Trial 73 finished with value: 0.8644859813084113 and parameters: {'batch_size': 32, 'num_gcn_layers': 2, 'gcn_hidden_dim_0': 100, 'gcn_hidden_dim_1': 195, 'num_fc_layers': 2, 'fc_hidden_dim_0': 186, 'fc_hidden_dim_1': 61, 'learning_rate': 0.0020206278528430237, 'weight_decay': 3.9345320198825574e-05, 'pooling_method': 'max', 'gcn_batch_norm_flag_0': False, 'gcn_batch_norm_flag_1': True, 'gcn_momentum_1': 0.9860265245023455, 'gcn_eps_1': 0.00881124300292427, 'gcn_dropout_flag_0': False, 'gcn_dropout_flag_1': False, 'gcn_activation_0': 'leaky_relu', 'gcn_activation_1': 'relu', 'fc_batch_norm_flag_0': False, 'fc_batch_norm_flag_1': True, 'fc_momentum_1': 0.5439475959501766, 'fc_eps_1': 0.0030196073358553827, 'fc_dropout_flag_0': False, 'fc_dropout_flag_1': True, 'fc_dropout_rate_1': 0.20136243796590797, 'fc_activation_0': 'elu', 'fc_activation_1': 'leaky_relu', 'gcn_skip_connections_0': False, 'gcn_skip_connections_1': True, 'l1_lambda': 0.00015830634043496167, 'optimizer': 'Adam', 'beta1': 0.9483733790153511, 'beta2': 0.9937958295618634, 'lr_scheduler': 'OneCycleLR', 'max_lr_1': 0.038741893497299944, 'pct_start': 0.1585801964018787, 'loss_function': 'MultiMargin'}. Best is trial 33 with value: 0.8714953271028038.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82, Loss: 0.0780, Accuracy: 0.8569, Test Loss: 0.0543, Test Accuracy: 0.8598\n",
      "Early stopping triggered\n",
      "Epoch 1, Loss: 0.9435, Accuracy: 0.7331, Test Loss: 0.1143, Test Accuracy: 0.7757\n",
      "Epoch 2, Loss: 0.7027, Accuracy: 0.7909, Test Loss: 0.1028, Test Accuracy: 0.7921\n",
      "Epoch 3, Loss: 0.5467, Accuracy: 0.7961, Test Loss: 0.0993, Test Accuracy: 0.8107\n",
      "Epoch 4, Loss: 0.4209, Accuracy: 0.8020, Test Loss: 0.0959, Test Accuracy: 0.8084\n",
      "Epoch 5, Loss: 0.3412, Accuracy: 0.8008, Test Loss: 0.0946, Test Accuracy: 0.8084\n",
      "Epoch 6, Loss: 0.2822, Accuracy: 0.8002, Test Loss: 0.0870, Test Accuracy: 0.8084\n",
      "Epoch 7, Loss: 0.2375, Accuracy: 0.8072, Test Loss: 0.1025, Test Accuracy: 0.8107\n",
      "Epoch 8, Loss: 0.2136, Accuracy: 0.8096, Test Loss: 0.0806, Test Accuracy: 0.8084\n",
      "Epoch 9, Loss: 0.1914, Accuracy: 0.8096, Test Loss: 0.0781, Test Accuracy: 0.8224\n",
      "Epoch 10, Loss: 0.1729, Accuracy: 0.8248, Test Loss: 0.0785, Test Accuracy: 0.8201\n",
      "Epoch 11, Loss: 0.1608, Accuracy: 0.8230, Test Loss: 0.0683, Test Accuracy: 0.8411\n",
      "Epoch 12, Loss: 0.1469, Accuracy: 0.8359, Test Loss: 0.0652, Test Accuracy: 0.8318\n",
      "Epoch 13, Loss: 0.1421, Accuracy: 0.8271, Test Loss: 0.0675, Test Accuracy: 0.8388\n",
      "Epoch 14, Loss: 0.1339, Accuracy: 0.8359, Test Loss: 0.0626, Test Accuracy: 0.8458\n",
      "Epoch 15, Loss: 0.1268, Accuracy: 0.8394, Test Loss: 0.0667, Test Accuracy: 0.8388\n",
      "Epoch 16, Loss: 0.1230, Accuracy: 0.8394, Test Loss: 0.0649, Test Accuracy: 0.8458\n",
      "Epoch 17, Loss: 0.1177, Accuracy: 0.8347, Test Loss: 0.0680, Test Accuracy: 0.8481\n",
      "Epoch 18, Loss: 0.1141, Accuracy: 0.8440, Test Loss: 0.0625, Test Accuracy: 0.8481\n",
      "Epoch 19, Loss: 0.1107, Accuracy: 0.8429, Test Loss: 0.0689, Test Accuracy: 0.8271\n",
      "Epoch 20, Loss: 0.1109, Accuracy: 0.8417, Test Loss: 0.0588, Test Accuracy: 0.8458\n",
      "Epoch 21, Loss: 0.1029, Accuracy: 0.8475, Test Loss: 0.0664, Test Accuracy: 0.8411\n",
      "Epoch 22, Loss: 0.1039, Accuracy: 0.8376, Test Loss: 0.0631, Test Accuracy: 0.8458\n",
      "Epoch 23, Loss: 0.1035, Accuracy: 0.8400, Test Loss: 0.0576, Test Accuracy: 0.8598\n",
      "Epoch 24, Loss: 0.1016, Accuracy: 0.8440, Test Loss: 0.0612, Test Accuracy: 0.8505\n",
      "Epoch 25, Loss: 0.0998, Accuracy: 0.8458, Test Loss: 0.0593, Test Accuracy: 0.8598\n",
      "Epoch 26, Loss: 0.0962, Accuracy: 0.8487, Test Loss: 0.0584, Test Accuracy: 0.8551\n",
      "Epoch 27, Loss: 0.0992, Accuracy: 0.8423, Test Loss: 0.0618, Test Accuracy: 0.8318\n",
      "Epoch 28, Loss: 0.0974, Accuracy: 0.8440, Test Loss: 0.0574, Test Accuracy: 0.8481\n",
      "Epoch 29, Loss: 0.0973, Accuracy: 0.8423, Test Loss: 0.0628, Test Accuracy: 0.8481\n",
      "Epoch 30, Loss: 0.0970, Accuracy: 0.8429, Test Loss: 0.0545, Test Accuracy: 0.8505\n",
      "Epoch 31, Loss: 0.0930, Accuracy: 0.8464, Test Loss: 0.0569, Test Accuracy: 0.8528\n",
      "Epoch 32, Loss: 0.0913, Accuracy: 0.8516, Test Loss: 0.0602, Test Accuracy: 0.8528\n",
      "Epoch 33, Loss: 0.0905, Accuracy: 0.8475, Test Loss: 0.0580, Test Accuracy: 0.8411\n",
      "Epoch 34, Loss: 0.0939, Accuracy: 0.8452, Test Loss: 0.0585, Test Accuracy: 0.8551\n",
      "Epoch 35, Loss: 0.0929, Accuracy: 0.8446, Test Loss: 0.0601, Test Accuracy: 0.8528\n",
      "Epoch 36, Loss: 0.0898, Accuracy: 0.8487, Test Loss: 0.0565, Test Accuracy: 0.8505\n",
      "Epoch 37, Loss: 0.0889, Accuracy: 0.8487, Test Loss: 0.0524, Test Accuracy: 0.8645\n",
      "Epoch 38, Loss: 0.0888, Accuracy: 0.8470, Test Loss: 0.0546, Test Accuracy: 0.8621\n",
      "Epoch 39, Loss: 0.0882, Accuracy: 0.8522, Test Loss: 0.0524, Test Accuracy: 0.8551\n",
      "Epoch 40, Loss: 0.0873, Accuracy: 0.8470, Test Loss: 0.0542, Test Accuracy: 0.8645\n",
      "Epoch 41, Loss: 0.0872, Accuracy: 0.8511, Test Loss: 0.0589, Test Accuracy: 0.8435\n",
      "Epoch 42, Loss: 0.0913, Accuracy: 0.8487, Test Loss: 0.0649, Test Accuracy: 0.8458\n",
      "Epoch 43, Loss: 0.0882, Accuracy: 0.8516, Test Loss: 0.0563, Test Accuracy: 0.8458\n",
      "Epoch 44, Loss: 0.0903, Accuracy: 0.8429, Test Loss: 0.0517, Test Accuracy: 0.8621\n",
      "Epoch 45, Loss: 0.0868, Accuracy: 0.8475, Test Loss: 0.0626, Test Accuracy: 0.8505\n",
      "Epoch 46, Loss: 0.0876, Accuracy: 0.8487, Test Loss: 0.0636, Test Accuracy: 0.8411\n",
      "Epoch 47, Loss: 0.0841, Accuracy: 0.8540, Test Loss: 0.0561, Test Accuracy: 0.8528\n",
      "Epoch 48, Loss: 0.0860, Accuracy: 0.8505, Test Loss: 0.0529, Test Accuracy: 0.8551\n",
      "Epoch 49, Loss: 0.0858, Accuracy: 0.8516, Test Loss: 0.0584, Test Accuracy: 0.8528\n",
      "Epoch 50, Loss: 0.0878, Accuracy: 0.8499, Test Loss: 0.0502, Test Accuracy: 0.8621\n",
      "Epoch 51, Loss: 0.0837, Accuracy: 0.8563, Test Loss: 0.0577, Test Accuracy: 0.8505\n",
      "Epoch 52, Loss: 0.0845, Accuracy: 0.8505, Test Loss: 0.0663, Test Accuracy: 0.8341\n",
      "Epoch 53, Loss: 0.0834, Accuracy: 0.8505, Test Loss: 0.0558, Test Accuracy: 0.8575\n",
      "Epoch 54, Loss: 0.0830, Accuracy: 0.8534, Test Loss: 0.0590, Test Accuracy: 0.8528\n",
      "Epoch 55, Loss: 0.0821, Accuracy: 0.8516, Test Loss: 0.0692, Test Accuracy: 0.8388\n",
      "Epoch 56, Loss: 0.0828, Accuracy: 0.8516, Test Loss: 0.0548, Test Accuracy: 0.8505\n",
      "Epoch 57, Loss: 0.0827, Accuracy: 0.8487, Test Loss: 0.0576, Test Accuracy: 0.8528\n",
      "Epoch 58, Loss: 0.0831, Accuracy: 0.8511, Test Loss: 0.0662, Test Accuracy: 0.8318\n",
      "Epoch 59, Loss: 0.0840, Accuracy: 0.8487, Test Loss: 0.0636, Test Accuracy: 0.8458\n",
      "Epoch 60, Loss: 0.0809, Accuracy: 0.8569, Test Loss: 0.0519, Test Accuracy: 0.8598\n",
      "Epoch 61, Loss: 0.0822, Accuracy: 0.8522, Test Loss: 0.0527, Test Accuracy: 0.8621\n",
      "Epoch 62, Loss: 0.0805, Accuracy: 0.8546, Test Loss: 0.0561, Test Accuracy: 0.8528\n",
      "Epoch 63, Loss: 0.0836, Accuracy: 0.8493, Test Loss: 0.0542, Test Accuracy: 0.8528\n",
      "Epoch 64, Loss: 0.0815, Accuracy: 0.8516, Test Loss: 0.0538, Test Accuracy: 0.8575\n",
      "Epoch 65, Loss: 0.0824, Accuracy: 0.8522, Test Loss: 0.0520, Test Accuracy: 0.8621\n",
      "Epoch 66, Loss: 0.0813, Accuracy: 0.8516, Test Loss: 0.0605, Test Accuracy: 0.8481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:56:43,031] Trial 74 finished with value: 0.8644859813084113 and parameters: {'batch_size': 32, 'num_gcn_layers': 2, 'gcn_hidden_dim_0': 104, 'gcn_hidden_dim_1': 202, 'num_fc_layers': 2, 'fc_hidden_dim_0': 187, 'fc_hidden_dim_1': 55, 'learning_rate': 0.0027666430888017546, 'weight_decay': 7.051159839776655e-05, 'pooling_method': 'max', 'gcn_batch_norm_flag_0': False, 'gcn_batch_norm_flag_1': True, 'gcn_momentum_1': 0.9572212481618483, 'gcn_eps_1': 0.009127902600945577, 'gcn_dropout_flag_0': False, 'gcn_dropout_flag_1': False, 'gcn_activation_0': 'leaky_relu', 'gcn_activation_1': 'relu', 'fc_batch_norm_flag_0': False, 'fc_batch_norm_flag_1': True, 'fc_momentum_1': 0.521541546579795, 'fc_eps_1': 0.0031361733481226647, 'fc_dropout_flag_0': False, 'fc_dropout_flag_1': True, 'fc_dropout_rate_1': 0.18885400101309202, 'fc_activation_0': 'elu', 'fc_activation_1': 'leaky_relu', 'gcn_skip_connections_0': False, 'gcn_skip_connections_1': True, 'l1_lambda': 0.00016610565770139646, 'optimizer': 'Adam', 'beta1': 0.9487642829235824, 'beta2': 0.9952537886154882, 'lr_scheduler': 'OneCycleLR', 'max_lr_1': 0.038246506180314124, 'pct_start': 0.15373016832557956, 'loss_function': 'MultiMargin'}. Best is trial 33 with value: 0.8714953271028038.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67, Loss: 0.0824, Accuracy: 0.8499, Test Loss: 0.0513, Test Accuracy: 0.8621\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:56:45,385] Trial 75 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.3782, Accuracy: 0.5859, Test Loss: 0.1784, Test Accuracy: 0.6893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 13:56:47,312] Trial 76 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.5084, Accuracy: 0.6636, Test Loss: 0.1561, Test Accuracy: 0.7407\n",
      "Epoch 1, Loss: 0.2126, Accuracy: 0.7278, Test Loss: 0.1069, Test Accuracy: 0.7897\n",
      "Epoch 2, Loss: 0.1478, Accuracy: 0.7921, Test Loss: 0.1089, Test Accuracy: 0.8084\n",
      "Epoch 3, Loss: 0.1377, Accuracy: 0.7991, Test Loss: 0.0925, Test Accuracy: 0.8061\n",
      "Epoch 4, Loss: 0.1300, Accuracy: 0.7979, Test Loss: 0.1017, Test Accuracy: 0.8084\n",
      "Epoch 5, Loss: 0.1259, Accuracy: 0.8055, Test Loss: 0.0849, Test Accuracy: 0.8107\n",
      "Epoch 6, Loss: 0.1227, Accuracy: 0.8078, Test Loss: 0.0896, Test Accuracy: 0.8107\n",
      "Epoch 7, Loss: 0.1181, Accuracy: 0.8067, Test Loss: 0.0806, Test Accuracy: 0.8131\n",
      "Epoch 8, Loss: 0.1108, Accuracy: 0.8172, Test Loss: 0.0765, Test Accuracy: 0.8154\n",
      "Epoch 9, Loss: 0.1041, Accuracy: 0.8218, Test Loss: 0.0770, Test Accuracy: 0.8271\n",
      "Epoch 10, Loss: 0.0969, Accuracy: 0.8324, Test Loss: 0.0697, Test Accuracy: 0.8294\n",
      "Epoch 11, Loss: 0.0957, Accuracy: 0.8283, Test Loss: 0.0670, Test Accuracy: 0.8248\n",
      "Epoch 12, Loss: 0.0900, Accuracy: 0.8411, Test Loss: 0.0640, Test Accuracy: 0.8435\n",
      "Epoch 13, Loss: 0.0843, Accuracy: 0.8435, Test Loss: 0.0678, Test Accuracy: 0.8411\n",
      "Epoch 14, Loss: 0.0823, Accuracy: 0.8429, Test Loss: 0.0762, Test Accuracy: 0.8435\n",
      "Epoch 15, Loss: 0.0804, Accuracy: 0.8411, Test Loss: 0.0636, Test Accuracy: 0.8458\n",
      "Epoch 16, Loss: 0.0812, Accuracy: 0.8411, Test Loss: 0.0665, Test Accuracy: 0.8364\n",
      "Epoch 17, Loss: 0.0769, Accuracy: 0.8464, Test Loss: 0.0643, Test Accuracy: 0.8364\n",
      "Epoch 18, Loss: 0.0804, Accuracy: 0.8423, Test Loss: 0.0652, Test Accuracy: 0.8388\n",
      "Epoch 19, Loss: 0.0780, Accuracy: 0.8423, Test Loss: 0.0934, Test Accuracy: 0.8107\n",
      "Epoch 20, Loss: 0.0781, Accuracy: 0.8411, Test Loss: 0.0729, Test Accuracy: 0.8364\n",
      "Epoch 21, Loss: 0.0730, Accuracy: 0.8464, Test Loss: 0.0546, Test Accuracy: 0.8598\n",
      "Epoch 22, Loss: 0.0732, Accuracy: 0.8475, Test Loss: 0.0545, Test Accuracy: 0.8598\n",
      "Epoch 23, Loss: 0.0796, Accuracy: 0.8376, Test Loss: 0.0667, Test Accuracy: 0.8458\n",
      "Epoch 24, Loss: 0.0721, Accuracy: 0.8481, Test Loss: 0.0664, Test Accuracy: 0.8411\n",
      "Epoch 25, Loss: 0.0759, Accuracy: 0.8429, Test Loss: 0.0646, Test Accuracy: 0.8458\n",
      "Epoch 26, Loss: 0.0721, Accuracy: 0.8499, Test Loss: 0.0565, Test Accuracy: 0.8528\n",
      "Epoch 27, Loss: 0.0699, Accuracy: 0.8493, Test Loss: 0.0662, Test Accuracy: 0.8528\n",
      "Epoch 28, Loss: 0.0725, Accuracy: 0.8470, Test Loss: 0.0568, Test Accuracy: 0.8481\n",
      "Epoch 29, Loss: 0.0705, Accuracy: 0.8446, Test Loss: 0.0595, Test Accuracy: 0.8621\n",
      "Epoch 30, Loss: 0.0685, Accuracy: 0.8458, Test Loss: 0.0524, Test Accuracy: 0.8621\n",
      "Epoch 31, Loss: 0.0681, Accuracy: 0.8475, Test Loss: 0.0575, Test Accuracy: 0.8598\n",
      "Epoch 32, Loss: 0.0666, Accuracy: 0.8487, Test Loss: 0.0614, Test Accuracy: 0.8481\n",
      "Epoch 33, Loss: 0.0685, Accuracy: 0.8470, Test Loss: 0.0655, Test Accuracy: 0.8458\n",
      "Epoch 34, Loss: 0.0675, Accuracy: 0.8470, Test Loss: 0.0551, Test Accuracy: 0.8505\n",
      "Epoch 35, Loss: 0.0718, Accuracy: 0.8446, Test Loss: 0.0666, Test Accuracy: 0.8411\n",
      "Epoch 36, Loss: 0.0685, Accuracy: 0.8487, Test Loss: 0.0529, Test Accuracy: 0.8551\n",
      "Epoch 37, Loss: 0.0687, Accuracy: 0.8458, Test Loss: 0.0543, Test Accuracy: 0.8598\n",
      "Epoch 38, Loss: 0.0742, Accuracy: 0.8400, Test Loss: 0.0529, Test Accuracy: 0.8598\n",
      "Epoch 39, Loss: 0.0677, Accuracy: 0.8464, Test Loss: 0.0557, Test Accuracy: 0.8621\n",
      "Epoch 40, Loss: 0.0652, Accuracy: 0.8505, Test Loss: 0.0715, Test Accuracy: 0.8388\n",
      "Epoch 41, Loss: 0.0672, Accuracy: 0.8452, Test Loss: 0.0720, Test Accuracy: 0.8364\n",
      "Epoch 42, Loss: 0.0641, Accuracy: 0.8528, Test Loss: 0.0669, Test Accuracy: 0.8481\n",
      "Epoch 43, Loss: 0.0676, Accuracy: 0.8464, Test Loss: 0.0560, Test Accuracy: 0.8458\n",
      "Epoch 44, Loss: 0.0654, Accuracy: 0.8522, Test Loss: 0.0699, Test Accuracy: 0.8364\n",
      "Epoch 45, Loss: 0.0672, Accuracy: 0.8487, Test Loss: 0.0589, Test Accuracy: 0.8575\n",
      "Epoch 46, Loss: 0.0639, Accuracy: 0.8522, Test Loss: 0.0661, Test Accuracy: 0.8318\n",
      "Epoch 47, Loss: 0.0623, Accuracy: 0.8511, Test Loss: 0.0540, Test Accuracy: 0.8598\n",
      "Epoch 48, Loss: 0.0625, Accuracy: 0.8551, Test Loss: 0.0677, Test Accuracy: 0.8388\n",
      "Epoch 49, Loss: 0.0634, Accuracy: 0.8557, Test Loss: 0.0539, Test Accuracy: 0.8481\n",
      "Epoch 50, Loss: 0.0622, Accuracy: 0.8528, Test Loss: 0.0546, Test Accuracy: 0.8598\n",
      "Epoch 51, Loss: 0.0612, Accuracy: 0.8493, Test Loss: 0.0530, Test Accuracy: 0.8621\n",
      "Epoch 52, Loss: 0.0623, Accuracy: 0.8516, Test Loss: 0.0630, Test Accuracy: 0.8411\n",
      "Epoch 53, Loss: 0.0644, Accuracy: 0.8540, Test Loss: 0.0570, Test Accuracy: 0.8575\n",
      "Epoch 54, Loss: 0.0630, Accuracy: 0.8511, Test Loss: 0.0572, Test Accuracy: 0.8575\n",
      "Epoch 55, Loss: 0.0629, Accuracy: 0.8534, Test Loss: 0.0637, Test Accuracy: 0.8598\n",
      "Epoch 56, Loss: 0.0632, Accuracy: 0.8499, Test Loss: 0.0536, Test Accuracy: 0.8528\n",
      "Epoch 57, Loss: 0.0615, Accuracy: 0.8534, Test Loss: 0.0607, Test Accuracy: 0.8505\n",
      "Epoch 58, Loss: 0.0636, Accuracy: 0.8487, Test Loss: 0.0580, Test Accuracy: 0.8481\n",
      "Epoch 59, Loss: 0.0615, Accuracy: 0.8540, Test Loss: 0.0536, Test Accuracy: 0.8668\n",
      "Epoch 60, Loss: 0.0613, Accuracy: 0.8528, Test Loss: 0.0783, Test Accuracy: 0.8318\n",
      "Epoch 61, Loss: 0.0621, Accuracy: 0.8516, Test Loss: 0.0674, Test Accuracy: 0.8178\n",
      "Epoch 62, Loss: 0.0625, Accuracy: 0.8505, Test Loss: 0.0663, Test Accuracy: 0.8435\n",
      "Epoch 63, Loss: 0.0618, Accuracy: 0.8499, Test Loss: 0.0573, Test Accuracy: 0.8528\n",
      "Epoch 64, Loss: 0.0627, Accuracy: 0.8493, Test Loss: 0.0702, Test Accuracy: 0.8458\n",
      "Epoch 65, Loss: 0.0645, Accuracy: 0.8493, Test Loss: 0.0593, Test Accuracy: 0.8505\n",
      "Epoch 66, Loss: 0.0626, Accuracy: 0.8540, Test Loss: 0.0566, Test Accuracy: 0.8575\n",
      "Epoch 67, Loss: 0.0637, Accuracy: 0.8516, Test Loss: 0.0597, Test Accuracy: 0.8551\n",
      "Epoch 68, Loss: 0.0621, Accuracy: 0.8516, Test Loss: 0.0566, Test Accuracy: 0.8598\n",
      "Epoch 69, Loss: 0.0615, Accuracy: 0.8540, Test Loss: 0.0523, Test Accuracy: 0.8598\n",
      "Epoch 70, Loss: 0.0601, Accuracy: 0.8546, Test Loss: 0.0557, Test Accuracy: 0.8551\n",
      "Epoch 71, Loss: 0.0577, Accuracy: 0.8575, Test Loss: 0.0519, Test Accuracy: 0.8645\n",
      "Epoch 72, Loss: 0.0598, Accuracy: 0.8557, Test Loss: 0.0816, Test Accuracy: 0.8201\n",
      "Epoch 73, Loss: 0.0612, Accuracy: 0.8493, Test Loss: 0.0705, Test Accuracy: 0.8201\n",
      "Epoch 74, Loss: 0.0598, Accuracy: 0.8569, Test Loss: 0.1226, Test Accuracy: 0.7687\n",
      "Epoch 75, Loss: 0.0627, Accuracy: 0.8546, Test Loss: 0.0579, Test Accuracy: 0.8598\n",
      "Epoch 76, Loss: 0.0618, Accuracy: 0.8499, Test Loss: 0.0579, Test Accuracy: 0.8598\n",
      "Epoch 77, Loss: 0.0584, Accuracy: 0.8592, Test Loss: 0.0578, Test Accuracy: 0.8458\n",
      "Epoch 78, Loss: 0.0640, Accuracy: 0.8487, Test Loss: 0.0545, Test Accuracy: 0.8598\n",
      "Epoch 79, Loss: 0.0609, Accuracy: 0.8522, Test Loss: 0.0554, Test Accuracy: 0.8598\n",
      "Epoch 80, Loss: 0.0597, Accuracy: 0.8557, Test Loss: 0.0548, Test Accuracy: 0.8621\n",
      "Epoch 81, Loss: 0.0580, Accuracy: 0.8575, Test Loss: 0.0548, Test Accuracy: 0.8575\n",
      "Epoch 82, Loss: 0.0624, Accuracy: 0.8534, Test Loss: 0.1704, Test Accuracy: 0.7056\n",
      "Epoch 83, Loss: 0.0642, Accuracy: 0.8458, Test Loss: 0.0521, Test Accuracy: 0.8598\n",
      "Epoch 84, Loss: 0.0613, Accuracy: 0.8551, Test Loss: 0.0549, Test Accuracy: 0.8551\n",
      "Epoch 85, Loss: 0.0631, Accuracy: 0.8493, Test Loss: 0.0596, Test Accuracy: 0.8528\n",
      "Epoch 86, Loss: 0.0599, Accuracy: 0.8540, Test Loss: 0.0575, Test Accuracy: 0.8575\n",
      "Epoch 87, Loss: 0.0619, Accuracy: 0.8522, Test Loss: 0.0574, Test Accuracy: 0.8575\n",
      "Epoch 88, Loss: 0.0587, Accuracy: 0.8563, Test Loss: 0.0752, Test Accuracy: 0.8318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:00:08,803] Trial 77 finished with value: 0.866822429906542 and parameters: {'batch_size': 32, 'num_gcn_layers': 2, 'gcn_hidden_dim_0': 130, 'gcn_hidden_dim_1': 189, 'num_fc_layers': 2, 'fc_hidden_dim_0': 194, 'fc_hidden_dim_1': 63, 'learning_rate': 0.0057582318110682975, 'weight_decay': 7.494336201310705e-05, 'pooling_method': 'max', 'gcn_batch_norm_flag_0': False, 'gcn_batch_norm_flag_1': True, 'gcn_momentum_1': 0.9315629428031004, 'gcn_eps_1': 0.00995338231576617, 'gcn_dropout_flag_0': False, 'gcn_dropout_flag_1': False, 'gcn_activation_0': 'softplus', 'gcn_activation_1': 'relu', 'fc_batch_norm_flag_0': False, 'fc_batch_norm_flag_1': True, 'fc_momentum_1': 0.40118639307382725, 'fc_eps_1': 0.0019691255708882416, 'fc_dropout_flag_0': False, 'fc_dropout_flag_1': True, 'fc_dropout_rate_1': 0.19573171418780483, 'fc_activation_0': 'elu', 'fc_activation_1': 'leaky_relu', 'gcn_skip_connections_0': False, 'gcn_skip_connections_1': True, 'l1_lambda': 7.033966235449465e-06, 'optimizer': 'Adam', 'beta1': 0.9560738935782187, 'beta2': 0.9932573141447748, 'lr_scheduler': 'OneCycleLR', 'max_lr_1': 0.053703252514348335, 'pct_start': 0.11685016540964713, 'loss_function': 'MultiMargin'}. Best is trial 33 with value: 0.8714953271028038.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89, Loss: 0.0591, Accuracy: 0.8546, Test Loss: 0.0602, Test Accuracy: 0.8528\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:00:09,966] Trial 78 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6386, Accuracy: 0.3668, Test Loss: 0.9607, Test Accuracy: 0.2150\n",
      "Epoch 1, Loss: 1.9213, Accuracy: 0.7074, Test Loss: 0.1103, Test Accuracy: 0.7804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:00:13,600] Trial 79 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 1.5347, Accuracy: 0.7821, Test Loss: 0.1007, Test Accuracy: 0.7921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:00:18,126] Trial 80 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6189, Accuracy: 0.5911, Test Loss: 0.1593, Test Accuracy: 0.7407\n",
      "Epoch 1, Loss: 1.1113, Accuracy: 0.7401, Test Loss: 0.1046, Test Accuracy: 0.7897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:00:22,643] Trial 81 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.8550, Accuracy: 0.7886, Test Loss: 0.1015, Test Accuracy: 0.7921\n",
      "Epoch 1, Loss: 1.1555, Accuracy: 0.7284, Test Loss: 0.1072, Test Accuracy: 0.7757\n",
      "Epoch 2, Loss: 0.7490, Accuracy: 0.7868, Test Loss: 0.1089, Test Accuracy: 0.8037\n",
      "Epoch 3, Loss: 0.4767, Accuracy: 0.7996, Test Loss: 0.1799, Test Accuracy: 0.7009\n",
      "Epoch 4, Loss: 0.3346, Accuracy: 0.7967, Test Loss: 0.0890, Test Accuracy: 0.8084\n",
      "Epoch 5, Loss: 0.2537, Accuracy: 0.8043, Test Loss: 0.0911, Test Accuracy: 0.8107\n",
      "Epoch 6, Loss: 0.2177, Accuracy: 0.8032, Test Loss: 0.0905, Test Accuracy: 0.8154\n",
      "Epoch 7, Loss: 0.1874, Accuracy: 0.8166, Test Loss: 0.0844, Test Accuracy: 0.8131\n",
      "Epoch 8, Loss: 0.1658, Accuracy: 0.8218, Test Loss: 0.0924, Test Accuracy: 0.8154\n",
      "Epoch 9, Loss: 0.1518, Accuracy: 0.8341, Test Loss: 0.0669, Test Accuracy: 0.8318\n",
      "Epoch 10, Loss: 0.1434, Accuracy: 0.8388, Test Loss: 0.0795, Test Accuracy: 0.8435\n",
      "Epoch 11, Loss: 0.1354, Accuracy: 0.8400, Test Loss: 0.0905, Test Accuracy: 0.8154\n",
      "Epoch 12, Loss: 0.1305, Accuracy: 0.8353, Test Loss: 0.0629, Test Accuracy: 0.8411\n",
      "Epoch 13, Loss: 0.1242, Accuracy: 0.8370, Test Loss: 0.0620, Test Accuracy: 0.8481\n",
      "Epoch 14, Loss: 0.1175, Accuracy: 0.8493, Test Loss: 0.0608, Test Accuracy: 0.8435\n",
      "Epoch 15, Loss: 0.1165, Accuracy: 0.8400, Test Loss: 0.0642, Test Accuracy: 0.8551\n",
      "Epoch 16, Loss: 0.1147, Accuracy: 0.8435, Test Loss: 0.0561, Test Accuracy: 0.8551\n",
      "Epoch 17, Loss: 0.1156, Accuracy: 0.8435, Test Loss: 0.0592, Test Accuracy: 0.8551\n",
      "Epoch 18, Loss: 0.1096, Accuracy: 0.8481, Test Loss: 0.0732, Test Accuracy: 0.8294\n",
      "Epoch 19, Loss: 0.1124, Accuracy: 0.8458, Test Loss: 0.0664, Test Accuracy: 0.8645\n",
      "Epoch 20, Loss: 0.1122, Accuracy: 0.8388, Test Loss: 0.0545, Test Accuracy: 0.8575\n",
      "Epoch 21, Loss: 0.1092, Accuracy: 0.8470, Test Loss: 0.0638, Test Accuracy: 0.8364\n",
      "Epoch 22, Loss: 0.1106, Accuracy: 0.8440, Test Loss: 0.0568, Test Accuracy: 0.8551\n",
      "Epoch 23, Loss: 0.1053, Accuracy: 0.8464, Test Loss: 0.0610, Test Accuracy: 0.8364\n",
      "Epoch 24, Loss: 0.1118, Accuracy: 0.8376, Test Loss: 0.0665, Test Accuracy: 0.8271\n",
      "Epoch 25, Loss: 0.1065, Accuracy: 0.8505, Test Loss: 0.0620, Test Accuracy: 0.8458\n",
      "Epoch 26, Loss: 0.1059, Accuracy: 0.8458, Test Loss: 0.0582, Test Accuracy: 0.8551\n",
      "Epoch 27, Loss: 0.1033, Accuracy: 0.8458, Test Loss: 0.0686, Test Accuracy: 0.8411\n",
      "Epoch 28, Loss: 0.1026, Accuracy: 0.8487, Test Loss: 0.0573, Test Accuracy: 0.8505\n",
      "Epoch 29, Loss: 0.1003, Accuracy: 0.8493, Test Loss: 0.0583, Test Accuracy: 0.8505\n",
      "Epoch 30, Loss: 0.0992, Accuracy: 0.8470, Test Loss: 0.0562, Test Accuracy: 0.8645\n",
      "Epoch 31, Loss: 0.0958, Accuracy: 0.8534, Test Loss: 0.0658, Test Accuracy: 0.8388\n",
      "Epoch 32, Loss: 0.0994, Accuracy: 0.8458, Test Loss: 0.0537, Test Accuracy: 0.8621\n",
      "Epoch 33, Loss: 0.1012, Accuracy: 0.8417, Test Loss: 0.0581, Test Accuracy: 0.8551\n",
      "Epoch 34, Loss: 0.0950, Accuracy: 0.8511, Test Loss: 0.0564, Test Accuracy: 0.8528\n",
      "Epoch 35, Loss: 0.0972, Accuracy: 0.8458, Test Loss: 0.0560, Test Accuracy: 0.8575\n",
      "Epoch 36, Loss: 0.0949, Accuracy: 0.8511, Test Loss: 0.0531, Test Accuracy: 0.8621\n",
      "Epoch 37, Loss: 0.0985, Accuracy: 0.8423, Test Loss: 0.0537, Test Accuracy: 0.8598\n",
      "Epoch 38, Loss: 0.0958, Accuracy: 0.8516, Test Loss: 0.0561, Test Accuracy: 0.8668\n",
      "Epoch 39, Loss: 0.0959, Accuracy: 0.8487, Test Loss: 0.0601, Test Accuracy: 0.8435\n",
      "Epoch 40, Loss: 0.0966, Accuracy: 0.8475, Test Loss: 0.0505, Test Accuracy: 0.8621\n",
      "Epoch 41, Loss: 0.0965, Accuracy: 0.8435, Test Loss: 0.0558, Test Accuracy: 0.8551\n",
      "Epoch 42, Loss: 0.0954, Accuracy: 0.8458, Test Loss: 0.0651, Test Accuracy: 0.8505\n",
      "Epoch 43, Loss: 0.0964, Accuracy: 0.8464, Test Loss: 0.0600, Test Accuracy: 0.8551\n",
      "Epoch 44, Loss: 0.0943, Accuracy: 0.8516, Test Loss: 0.0504, Test Accuracy: 0.8645\n",
      "Epoch 45, Loss: 0.0939, Accuracy: 0.8475, Test Loss: 0.0539, Test Accuracy: 0.8598\n",
      "Epoch 46, Loss: 0.0912, Accuracy: 0.8528, Test Loss: 0.0549, Test Accuracy: 0.8598\n",
      "Epoch 47, Loss: 0.0919, Accuracy: 0.8487, Test Loss: 0.0582, Test Accuracy: 0.8575\n",
      "Epoch 48, Loss: 0.0958, Accuracy: 0.8423, Test Loss: 0.0532, Test Accuracy: 0.8528\n",
      "Epoch 49, Loss: 0.0913, Accuracy: 0.8499, Test Loss: 0.0493, Test Accuracy: 0.8668\n",
      "Epoch 50, Loss: 0.0896, Accuracy: 0.8516, Test Loss: 0.0511, Test Accuracy: 0.8645\n",
      "Epoch 51, Loss: 0.0919, Accuracy: 0.8464, Test Loss: 0.0541, Test Accuracy: 0.8528\n",
      "Epoch 52, Loss: 0.0895, Accuracy: 0.8481, Test Loss: 0.0612, Test Accuracy: 0.8388\n",
      "Epoch 53, Loss: 0.0905, Accuracy: 0.8475, Test Loss: 0.0512, Test Accuracy: 0.8645\n",
      "Epoch 54, Loss: 0.0875, Accuracy: 0.8540, Test Loss: 0.0519, Test Accuracy: 0.8621\n",
      "Epoch 55, Loss: 0.0879, Accuracy: 0.8516, Test Loss: 0.0579, Test Accuracy: 0.8481\n",
      "Epoch 56, Loss: 0.0913, Accuracy: 0.8475, Test Loss: 0.0623, Test Accuracy: 0.8505\n",
      "Epoch 57, Loss: 0.0892, Accuracy: 0.8534, Test Loss: 0.0551, Test Accuracy: 0.8621\n",
      "Epoch 58, Loss: 0.0897, Accuracy: 0.8487, Test Loss: 0.0711, Test Accuracy: 0.8364\n",
      "Epoch 59, Loss: 0.0887, Accuracy: 0.8499, Test Loss: 0.0530, Test Accuracy: 0.8575\n",
      "Epoch 60, Loss: 0.0859, Accuracy: 0.8534, Test Loss: 0.0517, Test Accuracy: 0.8598\n",
      "Epoch 61, Loss: 0.0862, Accuracy: 0.8499, Test Loss: 0.0519, Test Accuracy: 0.8621\n",
      "Epoch 62, Loss: 0.0890, Accuracy: 0.8499, Test Loss: 0.0532, Test Accuracy: 0.8551\n",
      "Epoch 63, Loss: 0.0862, Accuracy: 0.8534, Test Loss: 0.0525, Test Accuracy: 0.8598\n",
      "Epoch 64, Loss: 0.0865, Accuracy: 0.8528, Test Loss: 0.0590, Test Accuracy: 0.8551\n",
      "Epoch 65, Loss: 0.0914, Accuracy: 0.8499, Test Loss: 0.0539, Test Accuracy: 0.8575\n",
      "Epoch 66, Loss: 0.0899, Accuracy: 0.8511, Test Loss: 0.0547, Test Accuracy: 0.8551\n",
      "Epoch 67, Loss: 0.0924, Accuracy: 0.8475, Test Loss: 0.0523, Test Accuracy: 0.8645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:02:41,516] Trial 82 finished with value: 0.866822429906542 and parameters: {'batch_size': 32, 'num_gcn_layers': 2, 'gcn_hidden_dim_0': 118, 'gcn_hidden_dim_1': 184, 'num_fc_layers': 2, 'fc_hidden_dim_0': 204, 'fc_hidden_dim_1': 63, 'learning_rate': 0.006243983658718531, 'weight_decay': 7.926328154412378e-05, 'pooling_method': 'max', 'gcn_batch_norm_flag_0': False, 'gcn_batch_norm_flag_1': True, 'gcn_momentum_1': 0.9866852551853744, 'gcn_eps_1': 0.008895572109644917, 'gcn_dropout_flag_0': False, 'gcn_dropout_flag_1': False, 'gcn_activation_0': 'relu', 'gcn_activation_1': 'relu', 'fc_batch_norm_flag_0': False, 'fc_batch_norm_flag_1': True, 'fc_momentum_1': 0.5360237939334885, 'fc_eps_1': 0.002778115613186908, 'fc_dropout_flag_0': False, 'fc_dropout_flag_1': True, 'fc_dropout_rate_1': 0.17173765380408101, 'fc_activation_0': 'elu', 'fc_activation_1': 'leaky_relu', 'gcn_skip_connections_0': False, 'gcn_skip_connections_1': True, 'l1_lambda': 0.00021989555782785062, 'optimizer': 'Adam', 'beta1': 0.926341628593397, 'beta2': 0.9859657543734875, 'lr_scheduler': 'OneCycleLR', 'max_lr_1': 0.05141865504869723, 'pct_start': 0.13158640822182494, 'loss_function': 'MultiMargin'}. Best is trial 33 with value: 0.8714953271028038.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68, Loss: 0.0893, Accuracy: 0.8493, Test Loss: 0.0527, Test Accuracy: 0.8598\n",
      "Early stopping triggered\n",
      "Epoch 1, Loss: 1.2399, Accuracy: 0.7407, Test Loss: 0.1097, Test Accuracy: 0.7897\n",
      "Epoch 2, Loss: 0.7517, Accuracy: 0.7932, Test Loss: 0.0977, Test Accuracy: 0.7944\n",
      "Epoch 3, Loss: 0.4494, Accuracy: 0.7956, Test Loss: 0.1110, Test Accuracy: 0.7944\n",
      "Epoch 4, Loss: 0.3034, Accuracy: 0.8002, Test Loss: 0.0896, Test Accuracy: 0.8084\n",
      "Epoch 5, Loss: 0.2365, Accuracy: 0.8037, Test Loss: 0.0869, Test Accuracy: 0.8084\n",
      "Epoch 6, Loss: 0.2026, Accuracy: 0.8032, Test Loss: 0.0911, Test Accuracy: 0.8084\n",
      "Epoch 7, Loss: 0.1809, Accuracy: 0.8061, Test Loss: 0.0880, Test Accuracy: 0.8084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:02:58,497] Trial 83 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 0.1653, Accuracy: 0.8078, Test Loss: 0.0881, Test Accuracy: 0.8084\n",
      "Epoch 1, Loss: 1.5760, Accuracy: 0.7360, Test Loss: 0.1052, Test Accuracy: 0.7780\n",
      "Epoch 2, Loss: 0.8326, Accuracy: 0.7991, Test Loss: 0.0967, Test Accuracy: 0.8084\n",
      "Epoch 3, Loss: 0.4397, Accuracy: 0.8002, Test Loss: 0.0928, Test Accuracy: 0.7991\n",
      "Epoch 4, Loss: 0.2863, Accuracy: 0.8043, Test Loss: 0.1016, Test Accuracy: 0.8014\n",
      "Epoch 5, Loss: 0.2214, Accuracy: 0.8026, Test Loss: 0.0897, Test Accuracy: 0.8061\n",
      "Epoch 6, Loss: 0.1923, Accuracy: 0.8049, Test Loss: 0.0999, Test Accuracy: 0.8061\n",
      "Epoch 7, Loss: 0.1761, Accuracy: 0.8037, Test Loss: 0.0917, Test Accuracy: 0.8084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:03:17,089] Trial 84 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 0.1687, Accuracy: 0.8032, Test Loss: 0.0898, Test Accuracy: 0.8084\n",
      "Epoch 1, Loss: 0.9188, Accuracy: 0.6916, Test Loss: 0.1343, Test Accuracy: 0.7710\n",
      "Epoch 2, Loss: 0.6638, Accuracy: 0.7804, Test Loss: 0.1110, Test Accuracy: 0.7967\n",
      "Epoch 3, Loss: 0.5440, Accuracy: 0.7950, Test Loss: 0.0959, Test Accuracy: 0.8061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:03:23,035] Trial 85 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.4372, Accuracy: 0.7967, Test Loss: 0.0957, Test Accuracy: 0.7991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:03:26,132] Trial 86 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.8617, Accuracy: 0.6671, Test Loss: 0.2435, Test Accuracy: 0.6542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:03:30,934] Trial 87 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 5.0071, Accuracy: 0.6192, Test Loss: 0.1605, Test Accuracy: 0.7196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:03:31,823] Trial 88 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.1983, Accuracy: 0.1314, Test Loss: 0.7627, Test Accuracy: 0.3084\n",
      "Epoch 1, Loss: 0.6537, Accuracy: 0.6711, Test Loss: 0.1903, Test Accuracy: 0.7944\n",
      "Epoch 2, Loss: 0.5225, Accuracy: 0.7821, Test Loss: 0.1829, Test Accuracy: 0.7523\n",
      "Epoch 3, Loss: 0.5013, Accuracy: 0.7938, Test Loss: 0.1520, Test Accuracy: 0.8061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:03:40,528] Trial 89 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.4870, Accuracy: 0.7967, Test Loss: 0.1107, Test Accuracy: 0.8014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:03:44,468] Trial 90 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.3813, Accuracy: 0.4749, Test Loss: 0.2729, Test Accuracy: 0.5257\n",
      "Epoch 1, Loss: 0.9042, Accuracy: 0.7331, Test Loss: 0.1073, Test Accuracy: 0.7874\n",
      "Epoch 2, Loss: 0.7055, Accuracy: 0.7961, Test Loss: 0.0981, Test Accuracy: 0.7991\n",
      "Epoch 3, Loss: 0.5750, Accuracy: 0.7967, Test Loss: 0.0941, Test Accuracy: 0.7991\n",
      "Epoch 4, Loss: 0.4597, Accuracy: 0.8072, Test Loss: 0.0908, Test Accuracy: 0.8107\n",
      "Epoch 5, Loss: 0.3746, Accuracy: 0.8084, Test Loss: 0.0833, Test Accuracy: 0.8154\n",
      "Epoch 6, Loss: 0.3157, Accuracy: 0.8084, Test Loss: 0.0848, Test Accuracy: 0.8107\n",
      "Epoch 7, Loss: 0.2666, Accuracy: 0.8166, Test Loss: 0.0896, Test Accuracy: 0.8107\n",
      "Epoch 8, Loss: 0.2312, Accuracy: 0.8224, Test Loss: 0.0780, Test Accuracy: 0.8201\n",
      "Epoch 9, Loss: 0.2069, Accuracy: 0.8283, Test Loss: 0.0733, Test Accuracy: 0.8224\n",
      "Epoch 10, Loss: 0.1823, Accuracy: 0.8388, Test Loss: 0.0754, Test Accuracy: 0.8201\n",
      "Epoch 11, Loss: 0.1707, Accuracy: 0.8324, Test Loss: 0.0726, Test Accuracy: 0.8294\n",
      "Epoch 12, Loss: 0.1592, Accuracy: 0.8394, Test Loss: 0.0657, Test Accuracy: 0.8411\n",
      "Epoch 13, Loss: 0.1496, Accuracy: 0.8394, Test Loss: 0.0674, Test Accuracy: 0.8318\n",
      "Epoch 14, Loss: 0.1491, Accuracy: 0.8329, Test Loss: 0.0792, Test Accuracy: 0.8154\n",
      "Epoch 15, Loss: 0.1394, Accuracy: 0.8376, Test Loss: 0.0608, Test Accuracy: 0.8458\n",
      "Epoch 16, Loss: 0.1318, Accuracy: 0.8458, Test Loss: 0.0670, Test Accuracy: 0.8481\n",
      "Epoch 17, Loss: 0.1291, Accuracy: 0.8376, Test Loss: 0.0593, Test Accuracy: 0.8388\n",
      "Epoch 18, Loss: 0.1275, Accuracy: 0.8341, Test Loss: 0.0654, Test Accuracy: 0.8481\n",
      "Epoch 19, Loss: 0.1241, Accuracy: 0.8440, Test Loss: 0.0580, Test Accuracy: 0.8505\n",
      "Epoch 20, Loss: 0.1197, Accuracy: 0.8411, Test Loss: 0.0669, Test Accuracy: 0.8458\n",
      "Epoch 21, Loss: 0.1145, Accuracy: 0.8470, Test Loss: 0.0619, Test Accuracy: 0.8481\n",
      "Epoch 22, Loss: 0.1104, Accuracy: 0.8493, Test Loss: 0.0613, Test Accuracy: 0.8435\n",
      "Epoch 23, Loss: 0.1070, Accuracy: 0.8475, Test Loss: 0.0569, Test Accuracy: 0.8528\n",
      "Epoch 24, Loss: 0.1064, Accuracy: 0.8458, Test Loss: 0.0596, Test Accuracy: 0.8551\n",
      "Epoch 25, Loss: 0.1031, Accuracy: 0.8435, Test Loss: 0.0569, Test Accuracy: 0.8458\n",
      "Epoch 26, Loss: 0.1016, Accuracy: 0.8481, Test Loss: 0.0549, Test Accuracy: 0.8528\n",
      "Epoch 27, Loss: 0.1013, Accuracy: 0.8440, Test Loss: 0.0773, Test Accuracy: 0.8224\n",
      "Epoch 28, Loss: 0.1030, Accuracy: 0.8411, Test Loss: 0.0654, Test Accuracy: 0.8435\n",
      "Epoch 29, Loss: 0.0984, Accuracy: 0.8470, Test Loss: 0.0578, Test Accuracy: 0.8505\n",
      "Epoch 30, Loss: 0.0980, Accuracy: 0.8475, Test Loss: 0.0588, Test Accuracy: 0.8458\n",
      "Epoch 31, Loss: 0.0947, Accuracy: 0.8499, Test Loss: 0.0554, Test Accuracy: 0.8575\n",
      "Epoch 32, Loss: 0.0933, Accuracy: 0.8528, Test Loss: 0.0543, Test Accuracy: 0.8505\n",
      "Epoch 33, Loss: 0.0951, Accuracy: 0.8511, Test Loss: 0.0561, Test Accuracy: 0.8598\n",
      "Epoch 34, Loss: 0.0946, Accuracy: 0.8458, Test Loss: 0.0621, Test Accuracy: 0.8458\n",
      "Epoch 35, Loss: 0.0919, Accuracy: 0.8511, Test Loss: 0.0594, Test Accuracy: 0.8505\n",
      "Epoch 36, Loss: 0.0909, Accuracy: 0.8481, Test Loss: 0.0555, Test Accuracy: 0.8575\n",
      "Epoch 37, Loss: 0.0911, Accuracy: 0.8516, Test Loss: 0.0746, Test Accuracy: 0.8318\n",
      "Epoch 38, Loss: 0.0900, Accuracy: 0.8487, Test Loss: 0.0548, Test Accuracy: 0.8598\n",
      "Epoch 39, Loss: 0.0897, Accuracy: 0.8511, Test Loss: 0.0559, Test Accuracy: 0.8551\n",
      "Epoch 40, Loss: 0.0890, Accuracy: 0.8487, Test Loss: 0.0540, Test Accuracy: 0.8621\n",
      "Epoch 41, Loss: 0.0872, Accuracy: 0.8551, Test Loss: 0.0528, Test Accuracy: 0.8575\n",
      "Epoch 42, Loss: 0.0882, Accuracy: 0.8481, Test Loss: 0.0712, Test Accuracy: 0.8318\n",
      "Epoch 43, Loss: 0.0869, Accuracy: 0.8522, Test Loss: 0.0578, Test Accuracy: 0.8528\n",
      "Epoch 44, Loss: 0.0896, Accuracy: 0.8475, Test Loss: 0.0571, Test Accuracy: 0.8505\n",
      "Epoch 45, Loss: 0.0881, Accuracy: 0.8499, Test Loss: 0.0559, Test Accuracy: 0.8458\n",
      "Epoch 46, Loss: 0.0854, Accuracy: 0.8534, Test Loss: 0.0511, Test Accuracy: 0.8645\n",
      "Epoch 47, Loss: 0.0891, Accuracy: 0.8440, Test Loss: 0.0745, Test Accuracy: 0.8364\n",
      "Epoch 48, Loss: 0.0889, Accuracy: 0.8470, Test Loss: 0.0545, Test Accuracy: 0.8575\n",
      "Epoch 49, Loss: 0.0860, Accuracy: 0.8470, Test Loss: 0.0591, Test Accuracy: 0.8528\n",
      "Epoch 50, Loss: 0.0862, Accuracy: 0.8516, Test Loss: 0.0561, Test Accuracy: 0.8645\n",
      "Epoch 51, Loss: 0.0852, Accuracy: 0.8516, Test Loss: 0.0538, Test Accuracy: 0.8621\n",
      "Epoch 52, Loss: 0.0834, Accuracy: 0.8493, Test Loss: 0.0540, Test Accuracy: 0.8458\n",
      "Epoch 53, Loss: 0.0831, Accuracy: 0.8540, Test Loss: 0.0530, Test Accuracy: 0.8575\n",
      "Epoch 54, Loss: 0.0817, Accuracy: 0.8534, Test Loss: 0.0544, Test Accuracy: 0.8598\n",
      "Epoch 55, Loss: 0.0822, Accuracy: 0.8516, Test Loss: 0.0596, Test Accuracy: 0.8435\n",
      "Epoch 56, Loss: 0.0816, Accuracy: 0.8563, Test Loss: 0.0523, Test Accuracy: 0.8551\n",
      "Epoch 57, Loss: 0.0851, Accuracy: 0.8516, Test Loss: 0.0665, Test Accuracy: 0.8435\n",
      "Epoch 58, Loss: 0.0852, Accuracy: 0.8505, Test Loss: 0.0563, Test Accuracy: 0.8458\n",
      "Epoch 59, Loss: 0.0850, Accuracy: 0.8487, Test Loss: 0.0523, Test Accuracy: 0.8668\n",
      "Epoch 60, Loss: 0.0837, Accuracy: 0.8470, Test Loss: 0.0559, Test Accuracy: 0.8458\n",
      "Epoch 61, Loss: 0.0830, Accuracy: 0.8528, Test Loss: 0.0537, Test Accuracy: 0.8598\n",
      "Epoch 62, Loss: 0.0819, Accuracy: 0.8516, Test Loss: 0.0550, Test Accuracy: 0.8505\n",
      "Epoch 63, Loss: 0.0809, Accuracy: 0.8534, Test Loss: 0.0570, Test Accuracy: 0.8481\n",
      "Epoch 64, Loss: 0.0813, Accuracy: 0.8511, Test Loss: 0.0520, Test Accuracy: 0.8645\n",
      "Epoch 65, Loss: 0.0815, Accuracy: 0.8511, Test Loss: 0.0528, Test Accuracy: 0.8598\n",
      "Epoch 66, Loss: 0.0800, Accuracy: 0.8563, Test Loss: 0.0537, Test Accuracy: 0.8598\n",
      "Epoch 67, Loss: 0.0800, Accuracy: 0.8557, Test Loss: 0.0542, Test Accuracy: 0.8575\n",
      "Epoch 68, Loss: 0.0807, Accuracy: 0.8546, Test Loss: 0.0527, Test Accuracy: 0.8575\n",
      "Epoch 69, Loss: 0.0798, Accuracy: 0.8534, Test Loss: 0.0534, Test Accuracy: 0.8551\n",
      "Epoch 70, Loss: 0.0820, Accuracy: 0.8534, Test Loss: 0.0578, Test Accuracy: 0.8528\n",
      "Epoch 71, Loss: 0.0806, Accuracy: 0.8516, Test Loss: 0.0516, Test Accuracy: 0.8645\n",
      "Epoch 72, Loss: 0.0793, Accuracy: 0.8563, Test Loss: 0.0537, Test Accuracy: 0.8575\n",
      "Epoch 73, Loss: 0.0780, Accuracy: 0.8540, Test Loss: 0.0521, Test Accuracy: 0.8598\n",
      "Epoch 74, Loss: 0.0796, Accuracy: 0.8540, Test Loss: 0.0528, Test Accuracy: 0.8621\n",
      "Epoch 75, Loss: 0.0818, Accuracy: 0.8505, Test Loss: 0.0527, Test Accuracy: 0.8621\n",
      "Epoch 76, Loss: 0.0795, Accuracy: 0.8546, Test Loss: 0.0614, Test Accuracy: 0.8458\n",
      "Epoch 77, Loss: 0.0808, Accuracy: 0.8516, Test Loss: 0.0555, Test Accuracy: 0.8528\n",
      "Epoch 78, Loss: 0.0789, Accuracy: 0.8528, Test Loss: 0.0561, Test Accuracy: 0.8551\n",
      "Epoch 79, Loss: 0.0791, Accuracy: 0.8546, Test Loss: 0.0608, Test Accuracy: 0.8481\n",
      "Epoch 80, Loss: 0.0792, Accuracy: 0.8551, Test Loss: 0.0546, Test Accuracy: 0.8505\n",
      "Epoch 81, Loss: 0.0778, Accuracy: 0.8534, Test Loss: 0.0554, Test Accuracy: 0.8575\n",
      "Epoch 82, Loss: 0.0788, Accuracy: 0.8528, Test Loss: 0.0522, Test Accuracy: 0.8505\n",
      "Epoch 83, Loss: 0.0779, Accuracy: 0.8546, Test Loss: 0.0551, Test Accuracy: 0.8528\n",
      "Epoch 84, Loss: 0.0790, Accuracy: 0.8534, Test Loss: 0.0583, Test Accuracy: 0.8505\n",
      "Epoch 85, Loss: 0.0803, Accuracy: 0.8499, Test Loss: 0.0543, Test Accuracy: 0.8598\n",
      "Epoch 86, Loss: 0.0789, Accuracy: 0.8546, Test Loss: 0.0519, Test Accuracy: 0.8645\n",
      "Epoch 87, Loss: 0.0770, Accuracy: 0.8551, Test Loss: 0.0558, Test Accuracy: 0.8528\n",
      "Epoch 88, Loss: 0.0777, Accuracy: 0.8528, Test Loss: 0.0657, Test Accuracy: 0.8458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:06:46,480] Trial 91 finished with value: 0.866822429906542 and parameters: {'batch_size': 32, 'num_gcn_layers': 2, 'gcn_hidden_dim_0': 104, 'gcn_hidden_dim_1': 204, 'num_fc_layers': 2, 'fc_hidden_dim_0': 189, 'fc_hidden_dim_1': 70, 'learning_rate': 0.0031179033417759947, 'weight_decay': 5.92350302825215e-05, 'pooling_method': 'max', 'gcn_batch_norm_flag_0': False, 'gcn_batch_norm_flag_1': True, 'gcn_momentum_1': 0.9870889310062115, 'gcn_eps_1': 0.008295568395525936, 'gcn_dropout_flag_0': False, 'gcn_dropout_flag_1': False, 'gcn_activation_0': 'leaky_relu', 'gcn_activation_1': 'relu', 'fc_batch_norm_flag_0': False, 'fc_batch_norm_flag_1': True, 'fc_momentum_1': 0.5351729694541637, 'fc_eps_1': 0.0032912031493049134, 'fc_dropout_flag_0': False, 'fc_dropout_flag_1': True, 'fc_dropout_rate_1': 0.20375493331418626, 'fc_activation_0': 'elu', 'fc_activation_1': 'leaky_relu', 'gcn_skip_connections_0': False, 'gcn_skip_connections_1': True, 'l1_lambda': 0.0001523567963736073, 'optimizer': 'Adam', 'beta1': 0.9462326320533697, 'beta2': 0.9970849692413881, 'lr_scheduler': 'OneCycleLR', 'max_lr_1': 0.03446437706784801, 'pct_start': 0.17055268102021812, 'loss_function': 'MultiMargin'}. Best is trial 33 with value: 0.8714953271028038.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89, Loss: 0.0793, Accuracy: 0.8522, Test Loss: 0.0595, Test Accuracy: 0.8481\n",
      "Early stopping triggered\n",
      "Epoch 1, Loss: 0.9027, Accuracy: 0.7138, Test Loss: 0.1128, Test Accuracy: 0.7874\n",
      "Epoch 2, Loss: 0.6945, Accuracy: 0.7862, Test Loss: 0.1048, Test Accuracy: 0.8014\n",
      "Epoch 3, Loss: 0.5696, Accuracy: 0.7991, Test Loss: 0.0924, Test Accuracy: 0.8084\n",
      "Epoch 4, Loss: 0.4632, Accuracy: 0.8043, Test Loss: 0.1042, Test Accuracy: 0.7991\n",
      "Epoch 5, Loss: 0.3835, Accuracy: 0.8037, Test Loss: 0.0881, Test Accuracy: 0.8061\n",
      "Epoch 6, Loss: 0.3234, Accuracy: 0.8026, Test Loss: 0.0892, Test Accuracy: 0.8061\n",
      "Epoch 7, Loss: 0.2773, Accuracy: 0.8020, Test Loss: 0.0905, Test Accuracy: 0.8131\n",
      "Epoch 8, Loss: 0.2464, Accuracy: 0.8049, Test Loss: 0.0928, Test Accuracy: 0.8061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:07:04,343] Trial 92 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 0.2151, Accuracy: 0.8102, Test Loss: 0.0829, Test Accuracy: 0.8084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:07:06,609] Trial 93 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.5408, Accuracy: 0.6939, Test Loss: 0.1320, Test Accuracy: 0.7407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:07:09,086] Trial 94 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.1121, Accuracy: 0.6069, Test Loss: 0.2094, Test Accuracy: 0.6963\n",
      "Epoch 1, Loss: 1.6336, Accuracy: 0.7138, Test Loss: 0.1224, Test Accuracy: 0.7897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:07:11,772] Trial 95 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 1.2699, Accuracy: 0.7909, Test Loss: 0.1034, Test Accuracy: 0.7874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:07:12,998] Trial 96 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6297, Accuracy: 0.6758, Test Loss: 0.1360, Test Accuracy: 0.7430\n",
      "Epoch 1, Loss: 2.0602, Accuracy: 0.7342, Test Loss: 0.1303, Test Accuracy: 0.7780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:07:16,551] Trial 97 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.7699, Accuracy: 0.7868, Test Loss: 0.1818, Test Accuracy: 0.7827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:07:20,970] Trial 98 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 3.0932, Accuracy: 0.5333, Test Loss: 0.8044, Test Accuracy: 0.2150\n",
      "Epoch 1, Loss: 2.6713, Accuracy: 0.7126, Test Loss: 0.1120, Test Accuracy: 0.7757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:07:24,667] Trial 99 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 2.0560, Accuracy: 0.7874, Test Loss: 0.1084, Test Accuracy: 0.7897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:07:26,540] Trial 100 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.7457, Accuracy: 0.7342, Test Loss: 0.4960, Test Accuracy: 0.5491\n",
      "Epoch 1, Loss: 0.9069, Accuracy: 0.7120, Test Loss: 0.1155, Test Accuracy: 0.7827\n",
      "Epoch 2, Loss: 0.6800, Accuracy: 0.7891, Test Loss: 0.1070, Test Accuracy: 0.8037\n",
      "Epoch 3, Loss: 0.5342, Accuracy: 0.8037, Test Loss: 0.0912, Test Accuracy: 0.8037\n",
      "Epoch 4, Loss: 0.4153, Accuracy: 0.8037, Test Loss: 0.1058, Test Accuracy: 0.8084\n",
      "Epoch 5, Loss: 0.3476, Accuracy: 0.7973, Test Loss: 0.1034, Test Accuracy: 0.7991\n",
      "Epoch 6, Loss: 0.2793, Accuracy: 0.8037, Test Loss: 0.0858, Test Accuracy: 0.8131\n",
      "Epoch 7, Loss: 0.2394, Accuracy: 0.8049, Test Loss: 0.0947, Test Accuracy: 0.8014\n",
      "Epoch 8, Loss: 0.2094, Accuracy: 0.8061, Test Loss: 0.0927, Test Accuracy: 0.8201\n",
      "Epoch 9, Loss: 0.1892, Accuracy: 0.8154, Test Loss: 0.0841, Test Accuracy: 0.8061\n",
      "Epoch 10, Loss: 0.1705, Accuracy: 0.8189, Test Loss: 0.0757, Test Accuracy: 0.8154\n",
      "Epoch 11, Loss: 0.1592, Accuracy: 0.8277, Test Loss: 0.0756, Test Accuracy: 0.8318\n",
      "Epoch 12, Loss: 0.1457, Accuracy: 0.8318, Test Loss: 0.0662, Test Accuracy: 0.8481\n",
      "Epoch 13, Loss: 0.1405, Accuracy: 0.8394, Test Loss: 0.0688, Test Accuracy: 0.8294\n",
      "Epoch 14, Loss: 0.1332, Accuracy: 0.8446, Test Loss: 0.0665, Test Accuracy: 0.8458\n",
      "Epoch 15, Loss: 0.1273, Accuracy: 0.8417, Test Loss: 0.0688, Test Accuracy: 0.8411\n",
      "Epoch 16, Loss: 0.1210, Accuracy: 0.8417, Test Loss: 0.0713, Test Accuracy: 0.8481\n",
      "Epoch 17, Loss: 0.1162, Accuracy: 0.8429, Test Loss: 0.0626, Test Accuracy: 0.8481\n",
      "Epoch 18, Loss: 0.1131, Accuracy: 0.8376, Test Loss: 0.0685, Test Accuracy: 0.8481\n",
      "Epoch 19, Loss: 0.1085, Accuracy: 0.8458, Test Loss: 0.0565, Test Accuracy: 0.8528\n",
      "Epoch 20, Loss: 0.1112, Accuracy: 0.8376, Test Loss: 0.0613, Test Accuracy: 0.8528\n",
      "Epoch 21, Loss: 0.1084, Accuracy: 0.8417, Test Loss: 0.0606, Test Accuracy: 0.8458\n",
      "Epoch 22, Loss: 0.1057, Accuracy: 0.8464, Test Loss: 0.0594, Test Accuracy: 0.8575\n",
      "Epoch 23, Loss: 0.1057, Accuracy: 0.8429, Test Loss: 0.0635, Test Accuracy: 0.8505\n",
      "Epoch 24, Loss: 0.1020, Accuracy: 0.8417, Test Loss: 0.0603, Test Accuracy: 0.8481\n",
      "Epoch 25, Loss: 0.1024, Accuracy: 0.8446, Test Loss: 0.0595, Test Accuracy: 0.8505\n",
      "Epoch 26, Loss: 0.0972, Accuracy: 0.8481, Test Loss: 0.0539, Test Accuracy: 0.8575\n",
      "Epoch 27, Loss: 0.0954, Accuracy: 0.8516, Test Loss: 0.0592, Test Accuracy: 0.8551\n",
      "Epoch 28, Loss: 0.0958, Accuracy: 0.8481, Test Loss: 0.0552, Test Accuracy: 0.8575\n",
      "Epoch 29, Loss: 0.0955, Accuracy: 0.8452, Test Loss: 0.0657, Test Accuracy: 0.8481\n",
      "Epoch 30, Loss: 0.0955, Accuracy: 0.8429, Test Loss: 0.0598, Test Accuracy: 0.8481\n",
      "Epoch 31, Loss: 0.0966, Accuracy: 0.8452, Test Loss: 0.0575, Test Accuracy: 0.8645\n",
      "Epoch 32, Loss: 0.0957, Accuracy: 0.8493, Test Loss: 0.0560, Test Accuracy: 0.8575\n",
      "Epoch 33, Loss: 0.0939, Accuracy: 0.8452, Test Loss: 0.0561, Test Accuracy: 0.8575\n",
      "Epoch 34, Loss: 0.0921, Accuracy: 0.8505, Test Loss: 0.0587, Test Accuracy: 0.8551\n",
      "Epoch 35, Loss: 0.0932, Accuracy: 0.8470, Test Loss: 0.0601, Test Accuracy: 0.8575\n",
      "Epoch 36, Loss: 0.0909, Accuracy: 0.8516, Test Loss: 0.0618, Test Accuracy: 0.8458\n",
      "Epoch 37, Loss: 0.0904, Accuracy: 0.8528, Test Loss: 0.0549, Test Accuracy: 0.8621\n",
      "Epoch 38, Loss: 0.0875, Accuracy: 0.8516, Test Loss: 0.0555, Test Accuracy: 0.8505\n",
      "Epoch 39, Loss: 0.0879, Accuracy: 0.8505, Test Loss: 0.0555, Test Accuracy: 0.8621\n",
      "Epoch 40, Loss: 0.0970, Accuracy: 0.8376, Test Loss: 0.0664, Test Accuracy: 0.8364\n",
      "Epoch 41, Loss: 0.0903, Accuracy: 0.8481, Test Loss: 0.0571, Test Accuracy: 0.8575\n",
      "Epoch 42, Loss: 0.0882, Accuracy: 0.8499, Test Loss: 0.0561, Test Accuracy: 0.8598\n",
      "Epoch 43, Loss: 0.0878, Accuracy: 0.8505, Test Loss: 0.0656, Test Accuracy: 0.8435\n",
      "Epoch 44, Loss: 0.0871, Accuracy: 0.8511, Test Loss: 0.0535, Test Accuracy: 0.8505\n",
      "Epoch 45, Loss: 0.0880, Accuracy: 0.8499, Test Loss: 0.0604, Test Accuracy: 0.8528\n",
      "Epoch 46, Loss: 0.0882, Accuracy: 0.8487, Test Loss: 0.0581, Test Accuracy: 0.8551\n",
      "Epoch 47, Loss: 0.0847, Accuracy: 0.8546, Test Loss: 0.0529, Test Accuracy: 0.8598\n",
      "Epoch 48, Loss: 0.0864, Accuracy: 0.8481, Test Loss: 0.0578, Test Accuracy: 0.8505\n",
      "Epoch 49, Loss: 0.0862, Accuracy: 0.8522, Test Loss: 0.0599, Test Accuracy: 0.8505\n",
      "Epoch 50, Loss: 0.0865, Accuracy: 0.8475, Test Loss: 0.0584, Test Accuracy: 0.8528\n",
      "Epoch 51, Loss: 0.0863, Accuracy: 0.8481, Test Loss: 0.0551, Test Accuracy: 0.8598\n",
      "Epoch 52, Loss: 0.0849, Accuracy: 0.8534, Test Loss: 0.0563, Test Accuracy: 0.8621\n",
      "Epoch 53, Loss: 0.0849, Accuracy: 0.8528, Test Loss: 0.0558, Test Accuracy: 0.8575\n",
      "Epoch 54, Loss: 0.0865, Accuracy: 0.8475, Test Loss: 0.0544, Test Accuracy: 0.8621\n",
      "Epoch 55, Loss: 0.0845, Accuracy: 0.8528, Test Loss: 0.0693, Test Accuracy: 0.8435\n",
      "Epoch 56, Loss: 0.0861, Accuracy: 0.8516, Test Loss: 0.0567, Test Accuracy: 0.8551\n",
      "Epoch 57, Loss: 0.0851, Accuracy: 0.8493, Test Loss: 0.0547, Test Accuracy: 0.8575\n",
      "Epoch 58, Loss: 0.0820, Accuracy: 0.8522, Test Loss: 0.0585, Test Accuracy: 0.8575\n",
      "Epoch 59, Loss: 0.0843, Accuracy: 0.8499, Test Loss: 0.0580, Test Accuracy: 0.8505\n",
      "Epoch 60, Loss: 0.0838, Accuracy: 0.8493, Test Loss: 0.0526, Test Accuracy: 0.8528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:09:21,477] Trial 101 finished with value: 0.8644859813084113 and parameters: {'batch_size': 32, 'num_gcn_layers': 2, 'gcn_hidden_dim_0': 100, 'gcn_hidden_dim_1': 198, 'num_fc_layers': 2, 'fc_hidden_dim_0': 183, 'fc_hidden_dim_1': 57, 'learning_rate': 0.001963121099124029, 'weight_decay': 3.741926195441973e-05, 'pooling_method': 'max', 'gcn_batch_norm_flag_0': False, 'gcn_batch_norm_flag_1': True, 'gcn_momentum_1': 0.9703810327313238, 'gcn_eps_1': 0.008736281863251176, 'gcn_dropout_flag_0': False, 'gcn_dropout_flag_1': False, 'gcn_activation_0': 'leaky_relu', 'gcn_activation_1': 'relu', 'fc_batch_norm_flag_0': False, 'fc_batch_norm_flag_1': True, 'fc_momentum_1': 0.5419642476276941, 'fc_eps_1': 0.003023821768286952, 'fc_dropout_flag_0': False, 'fc_dropout_flag_1': True, 'fc_dropout_rate_1': 0.2009062498340911, 'fc_activation_0': 'elu', 'fc_activation_1': 'leaky_relu', 'gcn_skip_connections_0': False, 'gcn_skip_connections_1': True, 'l1_lambda': 0.00015546981199784265, 'optimizer': 'Adam', 'beta1': 0.9467754140461058, 'beta2': 0.9939318445168072, 'lr_scheduler': 'OneCycleLR', 'max_lr_1': 0.042599858784927475, 'pct_start': 0.46477001642729365, 'loss_function': 'MultiMargin'}. Best is trial 33 with value: 0.8714953271028038.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61, Loss: 0.0890, Accuracy: 0.8481, Test Loss: 0.0641, Test Accuracy: 0.8458\n",
      "Early stopping triggered\n",
      "Epoch 1, Loss: 0.7134, Accuracy: 0.7401, Test Loss: 0.1275, Test Accuracy: 0.7827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:09:25,311] Trial 102 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.4693, Accuracy: 0.7909, Test Loss: 0.1015, Test Accuracy: 0.7921\n",
      "Epoch 1, Loss: 1.0848, Accuracy: 0.7144, Test Loss: 0.1178, Test Accuracy: 0.7897\n",
      "Epoch 2, Loss: 0.7429, Accuracy: 0.7950, Test Loss: 0.1163, Test Accuracy: 0.7991\n",
      "Epoch 3, Loss: 0.5265, Accuracy: 0.7996, Test Loss: 0.0978, Test Accuracy: 0.8061\n",
      "Epoch 4, Loss: 0.3802, Accuracy: 0.8014, Test Loss: 0.0990, Test Accuracy: 0.8107\n",
      "Epoch 5, Loss: 0.2977, Accuracy: 0.7985, Test Loss: 0.0958, Test Accuracy: 0.8084\n",
      "Epoch 6, Loss: 0.2538, Accuracy: 0.8008, Test Loss: 0.0870, Test Accuracy: 0.8084\n",
      "Epoch 7, Loss: 0.2158, Accuracy: 0.8090, Test Loss: 0.1042, Test Accuracy: 0.8131\n",
      "Epoch 8, Loss: 0.1984, Accuracy: 0.8032, Test Loss: 0.0850, Test Accuracy: 0.8131\n",
      "Epoch 9, Loss: 0.1769, Accuracy: 0.8096, Test Loss: 0.0879, Test Accuracy: 0.8107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:09:44,304] Trial 103 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 0.1624, Accuracy: 0.8072, Test Loss: 0.0799, Test Accuracy: 0.8131\n",
      "Epoch 1, Loss: 0.4429, Accuracy: 0.7097, Test Loss: 0.1194, Test Accuracy: 0.7827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:09:47,604] Trial 104 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.3274, Accuracy: 0.7815, Test Loss: 0.0990, Test Accuracy: 0.7897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:09:49,873] Trial 105 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.9327, Accuracy: 0.6916, Test Loss: 0.1369, Test Accuracy: 0.7617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:09:51,143] Trial 106 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.3946, Accuracy: 0.1776, Test Loss: 0.8063, Test Accuracy: 0.1449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:09:52,139] Trial 107 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.8123, Accuracy: 0.4988, Test Loss: 0.1826, Test Accuracy: 0.7033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:09:55,899] Trial 108 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.9025, Accuracy: 0.2745, Test Loss: 0.4281, Test Accuracy: 0.4579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:09:58,741] Trial 109 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.8934, Accuracy: 0.6022, Test Loss: 0.4339, Test Accuracy: 0.4743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:10:00,182] Trial 110 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.0539, Accuracy: 0.6752, Test Loss: 0.1335, Test Accuracy: 0.7593\n",
      "Epoch 1, Loss: 0.9876, Accuracy: 0.7196, Test Loss: 0.1177, Test Accuracy: 0.7874\n",
      "Epoch 2, Loss: 0.6893, Accuracy: 0.7903, Test Loss: 0.1010, Test Accuracy: 0.8061\n",
      "Epoch 3, Loss: 0.4556, Accuracy: 0.8008, Test Loss: 0.0973, Test Accuracy: 0.8084\n",
      "Epoch 4, Loss: 0.3108, Accuracy: 0.8037, Test Loss: 0.0926, Test Accuracy: 0.8084\n",
      "Epoch 5, Loss: 0.2406, Accuracy: 0.8026, Test Loss: 0.0944, Test Accuracy: 0.8107\n",
      "Epoch 6, Loss: 0.2006, Accuracy: 0.8037, Test Loss: 0.0914, Test Accuracy: 0.8107\n",
      "Epoch 7, Loss: 0.1776, Accuracy: 0.8078, Test Loss: 0.0927, Test Accuracy: 0.8131\n",
      "Epoch 8, Loss: 0.1684, Accuracy: 0.8096, Test Loss: 0.1072, Test Accuracy: 0.8178\n",
      "Epoch 9, Loss: 0.1573, Accuracy: 0.8125, Test Loss: 0.0880, Test Accuracy: 0.8201\n",
      "Epoch 10, Loss: 0.1498, Accuracy: 0.8119, Test Loss: 0.0850, Test Accuracy: 0.8154\n",
      "Epoch 11, Loss: 0.1413, Accuracy: 0.8178, Test Loss: 0.0749, Test Accuracy: 0.8248\n",
      "Epoch 12, Loss: 0.1325, Accuracy: 0.8254, Test Loss: 0.0706, Test Accuracy: 0.8271\n",
      "Epoch 13, Loss: 0.1261, Accuracy: 0.8289, Test Loss: 0.0796, Test Accuracy: 0.8364\n",
      "Epoch 14, Loss: 0.1189, Accuracy: 0.8335, Test Loss: 0.0652, Test Accuracy: 0.8294\n",
      "Epoch 15, Loss: 0.1199, Accuracy: 0.8294, Test Loss: 0.0676, Test Accuracy: 0.8294\n",
      "Epoch 16, Loss: 0.1169, Accuracy: 0.8359, Test Loss: 0.0647, Test Accuracy: 0.8411\n",
      "Epoch 17, Loss: 0.1105, Accuracy: 0.8440, Test Loss: 0.0654, Test Accuracy: 0.8458\n",
      "Epoch 18, Loss: 0.1085, Accuracy: 0.8388, Test Loss: 0.0821, Test Accuracy: 0.8458\n",
      "Epoch 19, Loss: 0.1079, Accuracy: 0.8394, Test Loss: 0.0981, Test Accuracy: 0.8271\n",
      "Epoch 20, Loss: 0.1055, Accuracy: 0.8411, Test Loss: 0.0612, Test Accuracy: 0.8435\n",
      "Epoch 21, Loss: 0.1032, Accuracy: 0.8388, Test Loss: 0.0682, Test Accuracy: 0.8341\n",
      "Epoch 22, Loss: 0.1054, Accuracy: 0.8376, Test Loss: 0.0588, Test Accuracy: 0.8435\n",
      "Epoch 23, Loss: 0.1031, Accuracy: 0.8446, Test Loss: 0.0568, Test Accuracy: 0.8575\n",
      "Epoch 24, Loss: 0.1002, Accuracy: 0.8464, Test Loss: 0.0579, Test Accuracy: 0.8621\n",
      "Epoch 25, Loss: 0.0964, Accuracy: 0.8481, Test Loss: 0.0606, Test Accuracy: 0.8435\n",
      "Epoch 26, Loss: 0.0988, Accuracy: 0.8429, Test Loss: 0.0705, Test Accuracy: 0.8341\n",
      "Epoch 27, Loss: 0.0977, Accuracy: 0.8429, Test Loss: 0.0624, Test Accuracy: 0.8364\n",
      "Epoch 28, Loss: 0.1001, Accuracy: 0.8411, Test Loss: 0.0733, Test Accuracy: 0.8294\n",
      "Epoch 29, Loss: 0.1006, Accuracy: 0.8452, Test Loss: 0.0800, Test Accuracy: 0.8178\n",
      "Epoch 30, Loss: 0.0975, Accuracy: 0.8452, Test Loss: 0.0588, Test Accuracy: 0.8435\n",
      "Epoch 31, Loss: 0.0954, Accuracy: 0.8440, Test Loss: 0.0539, Test Accuracy: 0.8575\n",
      "Epoch 32, Loss: 0.0954, Accuracy: 0.8464, Test Loss: 0.0580, Test Accuracy: 0.8598\n",
      "Epoch 33, Loss: 0.0946, Accuracy: 0.8440, Test Loss: 0.0584, Test Accuracy: 0.8481\n",
      "Epoch 34, Loss: 0.0927, Accuracy: 0.8411, Test Loss: 0.0592, Test Accuracy: 0.8575\n",
      "Epoch 35, Loss: 0.0904, Accuracy: 0.8487, Test Loss: 0.0610, Test Accuracy: 0.8458\n",
      "Epoch 36, Loss: 0.0919, Accuracy: 0.8493, Test Loss: 0.0598, Test Accuracy: 0.8481\n",
      "Epoch 37, Loss: 0.0919, Accuracy: 0.8493, Test Loss: 0.0640, Test Accuracy: 0.8411\n",
      "Epoch 38, Loss: 0.0932, Accuracy: 0.8440, Test Loss: 0.0644, Test Accuracy: 0.8411\n",
      "Epoch 39, Loss: 0.0889, Accuracy: 0.8481, Test Loss: 0.0585, Test Accuracy: 0.8528\n",
      "Epoch 40, Loss: 0.0900, Accuracy: 0.8481, Test Loss: 0.0619, Test Accuracy: 0.8505\n",
      "Epoch 41, Loss: 0.0902, Accuracy: 0.8475, Test Loss: 0.0585, Test Accuracy: 0.8528\n",
      "Epoch 42, Loss: 0.0873, Accuracy: 0.8499, Test Loss: 0.0606, Test Accuracy: 0.8598\n",
      "Epoch 43, Loss: 0.0894, Accuracy: 0.8505, Test Loss: 0.0542, Test Accuracy: 0.8575\n",
      "Epoch 44, Loss: 0.0865, Accuracy: 0.8487, Test Loss: 0.0586, Test Accuracy: 0.8505\n",
      "Epoch 45, Loss: 0.0859, Accuracy: 0.8505, Test Loss: 0.0591, Test Accuracy: 0.8481\n",
      "Epoch 46, Loss: 0.0866, Accuracy: 0.8505, Test Loss: 0.0520, Test Accuracy: 0.8598\n",
      "Epoch 47, Loss: 0.0882, Accuracy: 0.8505, Test Loss: 0.0626, Test Accuracy: 0.8411\n",
      "Epoch 48, Loss: 0.0879, Accuracy: 0.8475, Test Loss: 0.0542, Test Accuracy: 0.8598\n",
      "Epoch 49, Loss: 0.0868, Accuracy: 0.8481, Test Loss: 0.0558, Test Accuracy: 0.8551\n",
      "Epoch 50, Loss: 0.0857, Accuracy: 0.8511, Test Loss: 0.0559, Test Accuracy: 0.8598\n",
      "Epoch 51, Loss: 0.0840, Accuracy: 0.8511, Test Loss: 0.0541, Test Accuracy: 0.8621\n",
      "Epoch 52, Loss: 0.0874, Accuracy: 0.8493, Test Loss: 0.0576, Test Accuracy: 0.8551\n",
      "Epoch 53, Loss: 0.0873, Accuracy: 0.8417, Test Loss: 0.0628, Test Accuracy: 0.8458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:11:44,395] Trial 111 finished with value: 0.8621495327102804 and parameters: {'batch_size': 32, 'num_gcn_layers': 2, 'gcn_hidden_dim_0': 112, 'gcn_hidden_dim_1': 206, 'num_fc_layers': 2, 'fc_hidden_dim_0': 188, 'fc_hidden_dim_1': 48, 'learning_rate': 0.0028003222615148723, 'weight_decay': 6.701066098957371e-05, 'pooling_method': 'max', 'gcn_batch_norm_flag_0': False, 'gcn_batch_norm_flag_1': True, 'gcn_momentum_1': 0.9895533543838607, 'gcn_eps_1': 0.008929324584449201, 'gcn_dropout_flag_0': False, 'gcn_dropout_flag_1': False, 'gcn_activation_0': 'leaky_relu', 'gcn_activation_1': 'relu', 'fc_batch_norm_flag_0': False, 'fc_batch_norm_flag_1': True, 'fc_momentum_1': 0.8168323316323769, 'fc_eps_1': 0.003169459511692269, 'fc_dropout_flag_0': False, 'fc_dropout_flag_1': True, 'fc_dropout_rate_1': 0.18096684955232276, 'fc_activation_0': 'elu', 'fc_activation_1': 'leaky_relu', 'gcn_skip_connections_0': False, 'gcn_skip_connections_1': True, 'l1_lambda': 0.00017122995068920893, 'optimizer': 'Adam', 'beta1': 0.949539716668717, 'beta2': 0.9695433383294175, 'lr_scheduler': 'OneCycleLR', 'max_lr_1': 0.039404298161702996, 'pct_start': 0.14984355742705163, 'loss_function': 'MultiMargin'}. Best is trial 33 with value: 0.8714953271028038.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54, Loss: 0.0871, Accuracy: 0.8464, Test Loss: 0.0562, Test Accuracy: 0.8621\n",
      "Early stopping triggered\n",
      "Epoch 1, Loss: 1.0793, Accuracy: 0.7079, Test Loss: 0.1074, Test Accuracy: 0.7991\n",
      "Epoch 2, Loss: 0.7929, Accuracy: 0.7973, Test Loss: 0.0983, Test Accuracy: 0.8084\n",
      "Epoch 3, Loss: 0.6051, Accuracy: 0.8032, Test Loss: 0.0996, Test Accuracy: 0.8037\n",
      "Epoch 4, Loss: 0.4564, Accuracy: 0.8061, Test Loss: 0.0931, Test Accuracy: 0.8107\n",
      "Epoch 5, Loss: 0.3619, Accuracy: 0.8008, Test Loss: 0.0961, Test Accuracy: 0.8131\n",
      "Epoch 6, Loss: 0.3015, Accuracy: 0.7996, Test Loss: 0.0876, Test Accuracy: 0.8084\n",
      "Epoch 7, Loss: 0.2558, Accuracy: 0.8020, Test Loss: 0.0824, Test Accuracy: 0.8178\n",
      "Epoch 8, Loss: 0.2226, Accuracy: 0.8084, Test Loss: 0.0803, Test Accuracy: 0.8131\n",
      "Epoch 9, Loss: 0.2038, Accuracy: 0.8137, Test Loss: 0.0919, Test Accuracy: 0.8107\n",
      "Epoch 10, Loss: 0.1894, Accuracy: 0.8102, Test Loss: 0.0773, Test Accuracy: 0.8178\n",
      "Epoch 11, Loss: 0.1738, Accuracy: 0.8248, Test Loss: 0.0858, Test Accuracy: 0.8224\n",
      "Epoch 12, Loss: 0.1600, Accuracy: 0.8347, Test Loss: 0.0632, Test Accuracy: 0.8458\n",
      "Epoch 13, Loss: 0.1522, Accuracy: 0.8335, Test Loss: 0.0676, Test Accuracy: 0.8341\n",
      "Epoch 14, Loss: 0.1493, Accuracy: 0.8283, Test Loss: 0.0648, Test Accuracy: 0.8505\n",
      "Epoch 15, Loss: 0.1378, Accuracy: 0.8364, Test Loss: 0.0663, Test Accuracy: 0.8435\n",
      "Epoch 16, Loss: 0.1322, Accuracy: 0.8400, Test Loss: 0.0628, Test Accuracy: 0.8505\n",
      "Epoch 17, Loss: 0.1298, Accuracy: 0.8359, Test Loss: 0.0603, Test Accuracy: 0.8505\n",
      "Epoch 18, Loss: 0.1263, Accuracy: 0.8388, Test Loss: 0.0628, Test Accuracy: 0.8481\n",
      "Epoch 19, Loss: 0.1185, Accuracy: 0.8446, Test Loss: 0.0638, Test Accuracy: 0.8435\n",
      "Epoch 20, Loss: 0.1187, Accuracy: 0.8446, Test Loss: 0.0588, Test Accuracy: 0.8481\n",
      "Epoch 21, Loss: 0.1166, Accuracy: 0.8429, Test Loss: 0.0607, Test Accuracy: 0.8364\n",
      "Epoch 22, Loss: 0.1144, Accuracy: 0.8452, Test Loss: 0.0716, Test Accuracy: 0.8435\n",
      "Epoch 23, Loss: 0.1170, Accuracy: 0.8376, Test Loss: 0.0724, Test Accuracy: 0.8364\n",
      "Epoch 24, Loss: 0.1124, Accuracy: 0.8411, Test Loss: 0.0604, Test Accuracy: 0.8411\n",
      "Epoch 25, Loss: 0.1096, Accuracy: 0.8458, Test Loss: 0.0577, Test Accuracy: 0.8481\n",
      "Epoch 26, Loss: 0.1099, Accuracy: 0.8464, Test Loss: 0.0642, Test Accuracy: 0.8551\n",
      "Epoch 27, Loss: 0.1106, Accuracy: 0.8423, Test Loss: 0.0565, Test Accuracy: 0.8551\n",
      "Epoch 28, Loss: 0.1053, Accuracy: 0.8487, Test Loss: 0.0549, Test Accuracy: 0.8598\n",
      "Epoch 29, Loss: 0.1049, Accuracy: 0.8452, Test Loss: 0.0556, Test Accuracy: 0.8598\n",
      "Epoch 30, Loss: 0.1053, Accuracy: 0.8435, Test Loss: 0.0617, Test Accuracy: 0.8505\n",
      "Epoch 31, Loss: 0.1033, Accuracy: 0.8511, Test Loss: 0.0561, Test Accuracy: 0.8598\n",
      "Epoch 32, Loss: 0.1021, Accuracy: 0.8446, Test Loss: 0.0641, Test Accuracy: 0.8481\n",
      "Epoch 33, Loss: 0.0990, Accuracy: 0.8470, Test Loss: 0.0562, Test Accuracy: 0.8598\n",
      "Epoch 34, Loss: 0.1025, Accuracy: 0.8417, Test Loss: 0.0605, Test Accuracy: 0.8528\n",
      "Epoch 35, Loss: 0.1030, Accuracy: 0.8440, Test Loss: 0.0544, Test Accuracy: 0.8598\n",
      "Epoch 36, Loss: 0.0998, Accuracy: 0.8475, Test Loss: 0.0555, Test Accuracy: 0.8645\n",
      "Epoch 37, Loss: 0.0990, Accuracy: 0.8417, Test Loss: 0.0657, Test Accuracy: 0.8435\n",
      "Epoch 38, Loss: 0.1023, Accuracy: 0.8440, Test Loss: 0.0568, Test Accuracy: 0.8551\n",
      "Epoch 39, Loss: 0.0978, Accuracy: 0.8481, Test Loss: 0.0653, Test Accuracy: 0.8505\n",
      "Epoch 40, Loss: 0.0967, Accuracy: 0.8499, Test Loss: 0.0545, Test Accuracy: 0.8621\n",
      "Epoch 41, Loss: 0.0957, Accuracy: 0.8464, Test Loss: 0.0559, Test Accuracy: 0.8551\n",
      "Epoch 42, Loss: 0.0938, Accuracy: 0.8511, Test Loss: 0.0531, Test Accuracy: 0.8598\n",
      "Epoch 43, Loss: 0.0933, Accuracy: 0.8522, Test Loss: 0.0611, Test Accuracy: 0.8458\n",
      "Epoch 44, Loss: 0.0944, Accuracy: 0.8470, Test Loss: 0.0603, Test Accuracy: 0.8481\n",
      "Epoch 45, Loss: 0.0953, Accuracy: 0.8464, Test Loss: 0.0578, Test Accuracy: 0.8551\n",
      "Epoch 46, Loss: 0.0915, Accuracy: 0.8563, Test Loss: 0.0569, Test Accuracy: 0.8528\n",
      "Epoch 47, Loss: 0.0912, Accuracy: 0.8528, Test Loss: 0.0568, Test Accuracy: 0.8528\n",
      "Epoch 48, Loss: 0.0919, Accuracy: 0.8464, Test Loss: 0.0525, Test Accuracy: 0.8621\n",
      "Epoch 49, Loss: 0.0892, Accuracy: 0.8516, Test Loss: 0.0547, Test Accuracy: 0.8621\n",
      "Epoch 50, Loss: 0.0902, Accuracy: 0.8458, Test Loss: 0.0629, Test Accuracy: 0.8481\n",
      "Epoch 51, Loss: 0.0906, Accuracy: 0.8475, Test Loss: 0.0519, Test Accuracy: 0.8668\n",
      "Epoch 52, Loss: 0.0894, Accuracy: 0.8522, Test Loss: 0.0504, Test Accuracy: 0.8621\n",
      "Epoch 53, Loss: 0.0904, Accuracy: 0.8546, Test Loss: 0.0529, Test Accuracy: 0.8575\n",
      "Epoch 54, Loss: 0.0890, Accuracy: 0.8493, Test Loss: 0.0524, Test Accuracy: 0.8551\n",
      "Epoch 55, Loss: 0.0945, Accuracy: 0.8475, Test Loss: 0.0606, Test Accuracy: 0.8458\n",
      "Epoch 56, Loss: 0.0917, Accuracy: 0.8423, Test Loss: 0.0538, Test Accuracy: 0.8598\n",
      "Epoch 57, Loss: 0.0920, Accuracy: 0.8458, Test Loss: 0.0543, Test Accuracy: 0.8621\n",
      "Epoch 58, Loss: 0.0904, Accuracy: 0.8511, Test Loss: 0.0563, Test Accuracy: 0.8598\n",
      "Epoch 59, Loss: 0.0907, Accuracy: 0.8475, Test Loss: 0.0541, Test Accuracy: 0.8598\n",
      "Epoch 60, Loss: 0.0884, Accuracy: 0.8534, Test Loss: 0.0530, Test Accuracy: 0.8621\n",
      "Epoch 61, Loss: 0.0894, Accuracy: 0.8464, Test Loss: 0.0563, Test Accuracy: 0.8505\n",
      "Epoch 62, Loss: 0.0874, Accuracy: 0.8522, Test Loss: 0.0551, Test Accuracy: 0.8481\n",
      "Epoch 63, Loss: 0.0869, Accuracy: 0.8581, Test Loss: 0.0514, Test Accuracy: 0.8598\n",
      "Epoch 64, Loss: 0.0870, Accuracy: 0.8557, Test Loss: 0.0537, Test Accuracy: 0.8551\n",
      "Epoch 65, Loss: 0.0886, Accuracy: 0.8528, Test Loss: 0.0507, Test Accuracy: 0.8621\n",
      "Epoch 66, Loss: 0.0873, Accuracy: 0.8534, Test Loss: 0.0532, Test Accuracy: 0.8598\n",
      "Epoch 67, Loss: 0.0866, Accuracy: 0.8505, Test Loss: 0.0533, Test Accuracy: 0.8621\n",
      "Epoch 68, Loss: 0.0884, Accuracy: 0.8522, Test Loss: 0.0565, Test Accuracy: 0.8551\n",
      "Epoch 69, Loss: 0.0872, Accuracy: 0.8493, Test Loss: 0.0598, Test Accuracy: 0.8435\n",
      "Epoch 70, Loss: 0.0861, Accuracy: 0.8516, Test Loss: 0.0523, Test Accuracy: 0.8575\n",
      "Epoch 71, Loss: 0.0871, Accuracy: 0.8481, Test Loss: 0.0526, Test Accuracy: 0.8668\n",
      "Epoch 72, Loss: 0.0870, Accuracy: 0.8511, Test Loss: 0.0569, Test Accuracy: 0.8528\n",
      "Epoch 73, Loss: 0.0881, Accuracy: 0.8475, Test Loss: 0.0529, Test Accuracy: 0.8598\n",
      "Epoch 74, Loss: 0.0843, Accuracy: 0.8493, Test Loss: 0.0555, Test Accuracy: 0.8551\n",
      "Epoch 75, Loss: 0.0853, Accuracy: 0.8511, Test Loss: 0.0512, Test Accuracy: 0.8598\n",
      "Epoch 76, Loss: 0.0841, Accuracy: 0.8522, Test Loss: 0.0540, Test Accuracy: 0.8598\n",
      "Epoch 77, Loss: 0.0872, Accuracy: 0.8499, Test Loss: 0.0576, Test Accuracy: 0.8458\n",
      "Epoch 78, Loss: 0.0879, Accuracy: 0.8481, Test Loss: 0.0553, Test Accuracy: 0.8575\n",
      "Epoch 79, Loss: 0.0861, Accuracy: 0.8511, Test Loss: 0.0537, Test Accuracy: 0.8621\n",
      "Epoch 80, Loss: 0.0840, Accuracy: 0.8546, Test Loss: 0.0507, Test Accuracy: 0.8668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:14:16,207] Trial 112 finished with value: 0.866822429906542 and parameters: {'batch_size': 32, 'num_gcn_layers': 2, 'gcn_hidden_dim_0': 72, 'gcn_hidden_dim_1': 201, 'num_fc_layers': 2, 'fc_hidden_dim_0': 194, 'fc_hidden_dim_1': 60, 'learning_rate': 0.002118822097994722, 'weight_decay': 3.1378033931227846e-05, 'pooling_method': 'max', 'gcn_batch_norm_flag_0': False, 'gcn_batch_norm_flag_1': True, 'gcn_momentum_1': 0.9121917214336007, 'gcn_eps_1': 0.00913462001132302, 'gcn_dropout_flag_0': False, 'gcn_dropout_flag_1': False, 'gcn_activation_0': 'leaky_relu', 'gcn_activation_1': 'relu', 'fc_batch_norm_flag_0': False, 'fc_batch_norm_flag_1': True, 'fc_momentum_1': 0.5238500483256684, 'fc_eps_1': 0.0036154560614731833, 'fc_dropout_flag_0': False, 'fc_dropout_flag_1': True, 'fc_dropout_rate_1': 0.1904481270719688, 'fc_activation_0': 'elu', 'fc_activation_1': 'leaky_relu', 'gcn_skip_connections_0': False, 'gcn_skip_connections_1': True, 'l1_lambda': 0.00021226196171960976, 'optimizer': 'Adam', 'beta1': 0.9487174612550159, 'beta2': 0.9948571128358327, 'lr_scheduler': 'OneCycleLR', 'max_lr_1': 0.04279242837319189, 'pct_start': 0.1635608382107225, 'loss_function': 'MultiMargin'}. Best is trial 33 with value: 0.8714953271028038.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81, Loss: 0.0863, Accuracy: 0.8493, Test Loss: 0.0585, Test Accuracy: 0.8528\n",
      "Early stopping triggered\n",
      "Epoch 1, Loss: 1.6703, Accuracy: 0.7354, Test Loss: 0.1105, Test Accuracy: 0.7850\n",
      "Epoch 2, Loss: 1.0838, Accuracy: 0.7921, Test Loss: 0.0976, Test Accuracy: 0.8037\n",
      "Epoch 3, Loss: 0.6914, Accuracy: 0.7985, Test Loss: 0.1055, Test Accuracy: 0.7921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:14:23,847] Trial 113 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.4896, Accuracy: 0.8008, Test Loss: 0.0980, Test Accuracy: 0.8037\n",
      "Epoch 1, Loss: 1.2316, Accuracy: 0.7518, Test Loss: 0.1069, Test Accuracy: 0.7734\n",
      "Epoch 2, Loss: 0.8702, Accuracy: 0.7932, Test Loss: 0.0999, Test Accuracy: 0.8014\n",
      "Epoch 3, Loss: 0.5974, Accuracy: 0.8002, Test Loss: 0.1014, Test Accuracy: 0.8061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:14:31,943] Trial 114 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.4257, Accuracy: 0.8037, Test Loss: 0.0959, Test Accuracy: 0.8014\n",
      "Epoch 1, Loss: 1.4855, Accuracy: 0.6928, Test Loss: 0.6774, Test Accuracy: 0.7874\n",
      "Epoch 2, Loss: 1.0916, Accuracy: 0.7915, Test Loss: 0.5561, Test Accuracy: 0.8061\n",
      "Epoch 3, Loss: 0.9647, Accuracy: 0.7926, Test Loss: 0.5392, Test Accuracy: 0.7991\n",
      "Epoch 4, Loss: 0.8766, Accuracy: 0.8037, Test Loss: 0.4848, Test Accuracy: 0.8131\n",
      "Epoch 5, Loss: 0.8282, Accuracy: 0.7944, Test Loss: 0.4880, Test Accuracy: 0.8107\n",
      "Epoch 6, Loss: 0.7607, Accuracy: 0.8078, Test Loss: 0.4449, Test Accuracy: 0.8294\n",
      "Epoch 7, Loss: 0.6974, Accuracy: 0.8178, Test Loss: 0.4294, Test Accuracy: 0.8224\n",
      "Epoch 8, Loss: 0.6498, Accuracy: 0.8277, Test Loss: 0.4187, Test Accuracy: 0.8224\n",
      "Epoch 9, Loss: 0.6341, Accuracy: 0.8300, Test Loss: 0.4472, Test Accuracy: 0.8131\n",
      "Epoch 10, Loss: 0.6066, Accuracy: 0.8370, Test Loss: 0.4075, Test Accuracy: 0.8364\n",
      "Epoch 11, Loss: 0.5928, Accuracy: 0.8347, Test Loss: 0.3961, Test Accuracy: 0.8388\n",
      "Epoch 12, Loss: 0.5663, Accuracy: 0.8411, Test Loss: 0.4008, Test Accuracy: 0.8411\n",
      "Epoch 13, Loss: 0.5637, Accuracy: 0.8370, Test Loss: 0.3973, Test Accuracy: 0.8458\n",
      "Epoch 14, Loss: 0.5455, Accuracy: 0.8364, Test Loss: 0.3942, Test Accuracy: 0.8481\n",
      "Epoch 15, Loss: 0.5354, Accuracy: 0.8411, Test Loss: 0.4246, Test Accuracy: 0.8248\n",
      "Epoch 16, Loss: 0.5338, Accuracy: 0.8364, Test Loss: 0.3859, Test Accuracy: 0.8481\n",
      "Epoch 17, Loss: 0.5268, Accuracy: 0.8417, Test Loss: 0.3842, Test Accuracy: 0.8458\n",
      "Epoch 18, Loss: 0.5214, Accuracy: 0.8394, Test Loss: 0.3892, Test Accuracy: 0.8388\n",
      "Epoch 19, Loss: 0.5138, Accuracy: 0.8429, Test Loss: 0.4297, Test Accuracy: 0.8364\n",
      "Epoch 20, Loss: 0.5068, Accuracy: 0.8411, Test Loss: 0.3750, Test Accuracy: 0.8505\n",
      "Epoch 21, Loss: 0.4987, Accuracy: 0.8423, Test Loss: 0.4037, Test Accuracy: 0.8388\n",
      "Epoch 22, Loss: 0.5000, Accuracy: 0.8417, Test Loss: 0.3885, Test Accuracy: 0.8458\n",
      "Epoch 23, Loss: 0.4939, Accuracy: 0.8405, Test Loss: 0.3903, Test Accuracy: 0.8388\n",
      "Epoch 24, Loss: 0.4765, Accuracy: 0.8505, Test Loss: 0.4052, Test Accuracy: 0.8388\n",
      "Epoch 25, Loss: 0.4690, Accuracy: 0.8511, Test Loss: 0.3660, Test Accuracy: 0.8505\n",
      "Epoch 26, Loss: 0.4707, Accuracy: 0.8446, Test Loss: 0.3556, Test Accuracy: 0.8621\n",
      "Epoch 27, Loss: 0.4692, Accuracy: 0.8458, Test Loss: 0.3685, Test Accuracy: 0.8551\n",
      "Epoch 28, Loss: 0.4673, Accuracy: 0.8452, Test Loss: 0.3695, Test Accuracy: 0.8458\n",
      "Epoch 29, Loss: 0.4727, Accuracy: 0.8475, Test Loss: 0.3741, Test Accuracy: 0.8528\n",
      "Epoch 30, Loss: 0.4656, Accuracy: 0.8446, Test Loss: 0.3678, Test Accuracy: 0.8528\n",
      "Epoch 31, Loss: 0.4686, Accuracy: 0.8481, Test Loss: 0.3555, Test Accuracy: 0.8621\n",
      "Epoch 32, Loss: 0.4556, Accuracy: 0.8499, Test Loss: 0.3840, Test Accuracy: 0.8435\n",
      "Epoch 33, Loss: 0.4637, Accuracy: 0.8493, Test Loss: 0.3649, Test Accuracy: 0.8621\n",
      "Epoch 34, Loss: 0.4616, Accuracy: 0.8458, Test Loss: 0.4465, Test Accuracy: 0.8411\n",
      "Epoch 35, Loss: 0.4684, Accuracy: 0.8440, Test Loss: 0.3702, Test Accuracy: 0.8388\n",
      "Epoch 36, Loss: 0.4576, Accuracy: 0.8470, Test Loss: 0.3679, Test Accuracy: 0.8505\n",
      "Epoch 37, Loss: 0.4540, Accuracy: 0.8464, Test Loss: 0.3680, Test Accuracy: 0.8575\n",
      "Epoch 38, Loss: 0.4623, Accuracy: 0.8440, Test Loss: 0.4144, Test Accuracy: 0.8294\n",
      "Epoch 39, Loss: 0.4533, Accuracy: 0.8493, Test Loss: 0.3693, Test Accuracy: 0.8551\n",
      "Epoch 40, Loss: 0.4476, Accuracy: 0.8487, Test Loss: 0.3754, Test Accuracy: 0.8505\n",
      "Epoch 41, Loss: 0.4406, Accuracy: 0.8528, Test Loss: 0.3675, Test Accuracy: 0.8575\n",
      "Epoch 42, Loss: 0.4458, Accuracy: 0.8505, Test Loss: 0.3696, Test Accuracy: 0.8528\n",
      "Epoch 43, Loss: 0.4379, Accuracy: 0.8493, Test Loss: 0.3589, Test Accuracy: 0.8575\n",
      "Epoch 44, Loss: 0.4337, Accuracy: 0.8475, Test Loss: 0.4168, Test Accuracy: 0.8341\n",
      "Epoch 45, Loss: 0.4454, Accuracy: 0.8464, Test Loss: 0.3512, Test Accuracy: 0.8575\n",
      "Epoch 46, Loss: 0.4431, Accuracy: 0.8493, Test Loss: 0.4182, Test Accuracy: 0.8341\n",
      "Epoch 47, Loss: 0.4328, Accuracy: 0.8505, Test Loss: 0.3915, Test Accuracy: 0.8411\n",
      "Epoch 48, Loss: 0.4237, Accuracy: 0.8511, Test Loss: 0.3853, Test Accuracy: 0.8388\n",
      "Epoch 49, Loss: 0.4314, Accuracy: 0.8534, Test Loss: 0.3949, Test Accuracy: 0.8341\n",
      "Epoch 50, Loss: 0.4303, Accuracy: 0.8540, Test Loss: 0.3709, Test Accuracy: 0.8621\n",
      "Epoch 51, Loss: 0.4267, Accuracy: 0.8546, Test Loss: 0.3788, Test Accuracy: 0.8388\n",
      "Epoch 52, Loss: 0.4307, Accuracy: 0.8505, Test Loss: 0.3622, Test Accuracy: 0.8505\n",
      "Epoch 53, Loss: 0.4304, Accuracy: 0.8440, Test Loss: 0.3641, Test Accuracy: 0.8528\n",
      "Epoch 54, Loss: 0.4220, Accuracy: 0.8540, Test Loss: 0.3578, Test Accuracy: 0.8621\n",
      "Epoch 55, Loss: 0.4286, Accuracy: 0.8470, Test Loss: 0.3731, Test Accuracy: 0.8505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:16:04,944] Trial 115 finished with value: 0.8621495327102804 and parameters: {'batch_size': 32, 'num_gcn_layers': 2, 'gcn_hidden_dim_0': 79, 'gcn_hidden_dim_1': 77, 'num_fc_layers': 2, 'fc_hidden_dim_0': 175, 'fc_hidden_dim_1': 60, 'learning_rate': 0.0014553844115551486, 'weight_decay': 0.0008892175180395941, 'pooling_method': 'max', 'gcn_batch_norm_flag_0': False, 'gcn_batch_norm_flag_1': True, 'gcn_momentum_1': 0.8148218224816994, 'gcn_eps_1': 0.008274972293373435, 'gcn_dropout_flag_0': False, 'gcn_dropout_flag_1': False, 'gcn_activation_0': 'softplus', 'gcn_activation_1': 'relu', 'fc_batch_norm_flag_0': False, 'fc_batch_norm_flag_1': True, 'fc_momentum_1': 0.5104433396761694, 'fc_eps_1': 0.004940823633789801, 'fc_dropout_flag_0': False, 'fc_dropout_flag_1': True, 'fc_dropout_rate_1': 0.21519890671811742, 'fc_activation_0': 'elu', 'fc_activation_1': 'leaky_relu', 'gcn_skip_connections_0': False, 'gcn_skip_connections_1': True, 'l1_lambda': 0.00020348352829316748, 'optimizer': 'Adam', 'beta1': 0.9531435271939106, 'beta2': 0.9832409633108807, 'lr_scheduler': 'OneCycleLR', 'max_lr_1': 0.031132843725277397, 'pct_start': 0.16955843349375746, 'loss_function': 'CrossEntropy'}. Best is trial 33 with value: 0.8714953271028038.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56, Loss: 0.4307, Accuracy: 0.8475, Test Loss: 0.4310, Test Accuracy: 0.8271\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:16:06,818] Trial 116 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.0993, Accuracy: 0.6612, Test Loss: 0.1253, Test Accuracy: 0.7570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:16:07,815] Trial 117 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.2389, Accuracy: 0.6659, Test Loss: 0.6944, Test Accuracy: 0.7547\n",
      "Epoch 1, Loss: 0.8406, Accuracy: 0.7085, Test Loss: 0.1242, Test Accuracy: 0.7734\n",
      "Epoch 2, Loss: 0.6750, Accuracy: 0.7915, Test Loss: 0.1030, Test Accuracy: 0.8084\n",
      "Epoch 3, Loss: 0.5982, Accuracy: 0.8055, Test Loss: 0.0910, Test Accuracy: 0.8107\n",
      "Epoch 4, Loss: 0.5410, Accuracy: 0.8084, Test Loss: 0.0886, Test Accuracy: 0.8107\n",
      "Epoch 5, Loss: 0.4854, Accuracy: 0.8107, Test Loss: 0.0815, Test Accuracy: 0.8154\n",
      "Epoch 6, Loss: 0.4447, Accuracy: 0.8107, Test Loss: 0.0884, Test Accuracy: 0.8084\n",
      "Epoch 7, Loss: 0.4150, Accuracy: 0.8061, Test Loss: 0.0817, Test Accuracy: 0.8131\n",
      "Epoch 8, Loss: 0.3804, Accuracy: 0.8125, Test Loss: 0.0794, Test Accuracy: 0.8178\n",
      "Epoch 9, Loss: 0.3531, Accuracy: 0.8154, Test Loss: 0.0794, Test Accuracy: 0.8178\n",
      "Epoch 10, Loss: 0.3307, Accuracy: 0.8242, Test Loss: 0.0800, Test Accuracy: 0.8224\n",
      "Epoch 11, Loss: 0.3122, Accuracy: 0.8312, Test Loss: 0.0758, Test Accuracy: 0.8318\n",
      "Epoch 12, Loss: 0.2917, Accuracy: 0.8423, Test Loss: 0.0737, Test Accuracy: 0.8271\n",
      "Epoch 13, Loss: 0.2770, Accuracy: 0.8376, Test Loss: 0.0806, Test Accuracy: 0.8201\n",
      "Epoch 14, Loss: 0.2649, Accuracy: 0.8440, Test Loss: 0.0846, Test Accuracy: 0.8201\n",
      "Epoch 15, Loss: 0.2615, Accuracy: 0.8294, Test Loss: 0.0703, Test Accuracy: 0.8271\n",
      "Epoch 16, Loss: 0.2486, Accuracy: 0.8382, Test Loss: 0.0679, Test Accuracy: 0.8364\n",
      "Epoch 17, Loss: 0.2354, Accuracy: 0.8429, Test Loss: 0.0637, Test Accuracy: 0.8364\n",
      "Epoch 18, Loss: 0.2245, Accuracy: 0.8446, Test Loss: 0.0630, Test Accuracy: 0.8364\n",
      "Epoch 19, Loss: 0.2200, Accuracy: 0.8370, Test Loss: 0.0666, Test Accuracy: 0.8435\n",
      "Epoch 20, Loss: 0.2182, Accuracy: 0.8364, Test Loss: 0.0707, Test Accuracy: 0.8528\n",
      "Epoch 21, Loss: 0.2078, Accuracy: 0.8400, Test Loss: 0.0645, Test Accuracy: 0.8458\n",
      "Epoch 22, Loss: 0.2040, Accuracy: 0.8405, Test Loss: 0.0602, Test Accuracy: 0.8551\n",
      "Epoch 23, Loss: 0.1978, Accuracy: 0.8417, Test Loss: 0.0675, Test Accuracy: 0.8318\n",
      "Epoch 24, Loss: 0.1920, Accuracy: 0.8452, Test Loss: 0.0763, Test Accuracy: 0.8248\n",
      "Epoch 25, Loss: 0.1903, Accuracy: 0.8440, Test Loss: 0.0738, Test Accuracy: 0.8318\n",
      "Epoch 26, Loss: 0.1850, Accuracy: 0.8429, Test Loss: 0.0595, Test Accuracy: 0.8528\n",
      "Epoch 27, Loss: 0.1795, Accuracy: 0.8505, Test Loss: 0.0636, Test Accuracy: 0.8364\n",
      "Epoch 28, Loss: 0.1808, Accuracy: 0.8405, Test Loss: 0.0638, Test Accuracy: 0.8435\n",
      "Epoch 29, Loss: 0.1733, Accuracy: 0.8464, Test Loss: 0.0631, Test Accuracy: 0.8411\n",
      "Epoch 30, Loss: 0.1701, Accuracy: 0.8429, Test Loss: 0.0698, Test Accuracy: 0.8481\n",
      "Epoch 31, Loss: 0.1639, Accuracy: 0.8458, Test Loss: 0.0684, Test Accuracy: 0.8388\n",
      "Epoch 32, Loss: 0.1651, Accuracy: 0.8487, Test Loss: 0.0589, Test Accuracy: 0.8481\n",
      "Epoch 33, Loss: 0.1666, Accuracy: 0.8400, Test Loss: 0.0652, Test Accuracy: 0.8481\n",
      "Epoch 34, Loss: 0.1593, Accuracy: 0.8452, Test Loss: 0.0701, Test Accuracy: 0.8341\n",
      "Epoch 35, Loss: 0.1571, Accuracy: 0.8423, Test Loss: 0.0645, Test Accuracy: 0.8551\n",
      "Epoch 36, Loss: 0.1575, Accuracy: 0.8423, Test Loss: 0.0923, Test Accuracy: 0.8201\n",
      "Epoch 37, Loss: 0.1526, Accuracy: 0.8440, Test Loss: 0.0616, Test Accuracy: 0.8505\n",
      "Epoch 38, Loss: 0.1485, Accuracy: 0.8446, Test Loss: 0.0594, Test Accuracy: 0.8481\n",
      "Epoch 39, Loss: 0.1445, Accuracy: 0.8487, Test Loss: 0.0671, Test Accuracy: 0.8435\n",
      "Epoch 40, Loss: 0.1416, Accuracy: 0.8511, Test Loss: 0.0597, Test Accuracy: 0.8481\n",
      "Epoch 41, Loss: 0.1399, Accuracy: 0.8493, Test Loss: 0.0582, Test Accuracy: 0.8435\n",
      "Epoch 42, Loss: 0.1418, Accuracy: 0.8411, Test Loss: 0.0774, Test Accuracy: 0.8364\n",
      "Epoch 43, Loss: 0.1377, Accuracy: 0.8481, Test Loss: 0.0625, Test Accuracy: 0.8505\n",
      "Epoch 44, Loss: 0.1370, Accuracy: 0.8464, Test Loss: 0.0660, Test Accuracy: 0.8528\n",
      "Epoch 45, Loss: 0.1356, Accuracy: 0.8481, Test Loss: 0.0576, Test Accuracy: 0.8551\n",
      "Epoch 46, Loss: 0.1324, Accuracy: 0.8487, Test Loss: 0.0607, Test Accuracy: 0.8458\n",
      "Epoch 47, Loss: 0.1336, Accuracy: 0.8470, Test Loss: 0.0569, Test Accuracy: 0.8505\n",
      "Epoch 48, Loss: 0.1324, Accuracy: 0.8429, Test Loss: 0.0568, Test Accuracy: 0.8551\n",
      "Epoch 49, Loss: 0.1282, Accuracy: 0.8511, Test Loss: 0.0584, Test Accuracy: 0.8551\n",
      "Epoch 50, Loss: 0.1270, Accuracy: 0.8464, Test Loss: 0.0572, Test Accuracy: 0.8598\n",
      "Epoch 51, Loss: 0.1257, Accuracy: 0.8499, Test Loss: 0.0589, Test Accuracy: 0.8551\n",
      "Epoch 52, Loss: 0.1253, Accuracy: 0.8505, Test Loss: 0.0583, Test Accuracy: 0.8621\n",
      "Epoch 53, Loss: 0.1246, Accuracy: 0.8481, Test Loss: 0.0640, Test Accuracy: 0.8505\n",
      "Epoch 54, Loss: 0.1234, Accuracy: 0.8487, Test Loss: 0.0592, Test Accuracy: 0.8505\n",
      "Epoch 55, Loss: 0.1274, Accuracy: 0.8435, Test Loss: 0.0606, Test Accuracy: 0.8411\n",
      "Epoch 56, Loss: 0.1285, Accuracy: 0.8382, Test Loss: 0.0626, Test Accuracy: 0.8364\n",
      "Epoch 57, Loss: 0.1219, Accuracy: 0.8440, Test Loss: 0.0617, Test Accuracy: 0.8458\n",
      "Epoch 58, Loss: 0.1175, Accuracy: 0.8522, Test Loss: 0.0595, Test Accuracy: 0.8528\n",
      "Epoch 59, Loss: 0.1159, Accuracy: 0.8540, Test Loss: 0.0616, Test Accuracy: 0.8481\n",
      "Epoch 60, Loss: 0.1184, Accuracy: 0.8499, Test Loss: 0.0603, Test Accuracy: 0.8598\n",
      "Epoch 61, Loss: 0.1161, Accuracy: 0.8487, Test Loss: 0.0585, Test Accuracy: 0.8528\n",
      "Epoch 62, Loss: 0.1128, Accuracy: 0.8516, Test Loss: 0.0608, Test Accuracy: 0.8435\n",
      "Epoch 63, Loss: 0.1118, Accuracy: 0.8551, Test Loss: 0.0569, Test Accuracy: 0.8621\n",
      "Epoch 64, Loss: 0.1181, Accuracy: 0.8417, Test Loss: 0.0600, Test Accuracy: 0.8551\n",
      "Epoch 65, Loss: 0.1159, Accuracy: 0.8493, Test Loss: 0.0575, Test Accuracy: 0.8528\n",
      "Epoch 66, Loss: 0.1100, Accuracy: 0.8540, Test Loss: 0.0571, Test Accuracy: 0.8575\n",
      "Epoch 67, Loss: 0.1102, Accuracy: 0.8481, Test Loss: 0.0705, Test Accuracy: 0.8318\n",
      "Epoch 68, Loss: 0.1096, Accuracy: 0.8475, Test Loss: 0.0605, Test Accuracy: 0.8505\n",
      "Epoch 69, Loss: 0.1080, Accuracy: 0.8540, Test Loss: 0.0598, Test Accuracy: 0.8551\n",
      "Epoch 70, Loss: 0.1067, Accuracy: 0.8551, Test Loss: 0.0551, Test Accuracy: 0.8621\n",
      "Epoch 71, Loss: 0.1080, Accuracy: 0.8511, Test Loss: 0.0557, Test Accuracy: 0.8458\n",
      "Epoch 72, Loss: 0.1093, Accuracy: 0.8493, Test Loss: 0.0544, Test Accuracy: 0.8575\n",
      "Epoch 73, Loss: 0.1068, Accuracy: 0.8493, Test Loss: 0.0600, Test Accuracy: 0.8551\n",
      "Epoch 74, Loss: 0.1091, Accuracy: 0.8446, Test Loss: 0.0619, Test Accuracy: 0.8528\n",
      "Epoch 75, Loss: 0.1066, Accuracy: 0.8493, Test Loss: 0.0541, Test Accuracy: 0.8645\n",
      "Epoch 76, Loss: 0.1061, Accuracy: 0.8475, Test Loss: 0.0623, Test Accuracy: 0.8505\n",
      "Epoch 77, Loss: 0.1050, Accuracy: 0.8487, Test Loss: 0.0577, Test Accuracy: 0.8621\n",
      "Epoch 78, Loss: 0.1030, Accuracy: 0.8522, Test Loss: 0.0545, Test Accuracy: 0.8598\n",
      "Epoch 79, Loss: 0.1037, Accuracy: 0.8511, Test Loss: 0.0554, Test Accuracy: 0.8621\n",
      "Epoch 80, Loss: 0.1020, Accuracy: 0.8522, Test Loss: 0.0551, Test Accuracy: 0.8575\n",
      "Epoch 81, Loss: 0.1041, Accuracy: 0.8481, Test Loss: 0.0567, Test Accuracy: 0.8528\n",
      "Epoch 82, Loss: 0.1037, Accuracy: 0.8493, Test Loss: 0.0569, Test Accuracy: 0.8528\n",
      "Epoch 83, Loss: 0.1015, Accuracy: 0.8528, Test Loss: 0.0558, Test Accuracy: 0.8505\n",
      "Epoch 84, Loss: 0.0995, Accuracy: 0.8534, Test Loss: 0.0629, Test Accuracy: 0.8481\n",
      "Epoch 85, Loss: 0.1021, Accuracy: 0.8528, Test Loss: 0.0553, Test Accuracy: 0.8621\n",
      "Epoch 86, Loss: 0.1052, Accuracy: 0.8458, Test Loss: 0.0553, Test Accuracy: 0.8575\n",
      "Epoch 87, Loss: 0.1024, Accuracy: 0.8534, Test Loss: 0.0589, Test Accuracy: 0.8505\n",
      "Epoch 88, Loss: 0.1052, Accuracy: 0.8458, Test Loss: 0.0552, Test Accuracy: 0.8458\n",
      "Epoch 89, Loss: 0.1004, Accuracy: 0.8528, Test Loss: 0.0568, Test Accuracy: 0.8505\n",
      "Epoch 90, Loss: 0.1014, Accuracy: 0.8511, Test Loss: 0.0545, Test Accuracy: 0.8621\n",
      "Epoch 91, Loss: 0.0995, Accuracy: 0.8505, Test Loss: 0.0549, Test Accuracy: 0.8668\n",
      "Epoch 92, Loss: 0.0989, Accuracy: 0.8534, Test Loss: 0.0616, Test Accuracy: 0.8551\n",
      "Epoch 93, Loss: 0.0990, Accuracy: 0.8534, Test Loss: 0.0597, Test Accuracy: 0.8505\n",
      "Epoch 94, Loss: 0.0981, Accuracy: 0.8516, Test Loss: 0.0565, Test Accuracy: 0.8621\n",
      "Epoch 95, Loss: 0.0965, Accuracy: 0.8546, Test Loss: 0.0541, Test Accuracy: 0.8598\n",
      "Epoch 96, Loss: 0.0976, Accuracy: 0.8511, Test Loss: 0.0652, Test Accuracy: 0.8341\n",
      "Epoch 97, Loss: 0.0976, Accuracy: 0.8534, Test Loss: 0.0612, Test Accuracy: 0.8505\n",
      "Epoch 98, Loss: 0.0975, Accuracy: 0.8481, Test Loss: 0.0623, Test Accuracy: 0.8458\n",
      "Epoch 99, Loss: 0.0982, Accuracy: 0.8528, Test Loss: 0.0636, Test Accuracy: 0.8435\n",
      "Epoch 100, Loss: 0.0962, Accuracy: 0.8581, Test Loss: 0.0569, Test Accuracy: 0.8551\n",
      "Epoch 101, Loss: 0.0956, Accuracy: 0.8546, Test Loss: 0.0546, Test Accuracy: 0.8505\n",
      "Epoch 102, Loss: 0.0959, Accuracy: 0.8546, Test Loss: 0.0572, Test Accuracy: 0.8598\n",
      "Epoch 103, Loss: 0.0960, Accuracy: 0.8528, Test Loss: 0.0522, Test Accuracy: 0.8645\n",
      "Epoch 104, Loss: 0.0953, Accuracy: 0.8516, Test Loss: 0.0505, Test Accuracy: 0.8645\n",
      "Epoch 105, Loss: 0.0941, Accuracy: 0.8534, Test Loss: 0.0537, Test Accuracy: 0.8528\n",
      "Epoch 106, Loss: 0.0955, Accuracy: 0.8528, Test Loss: 0.0569, Test Accuracy: 0.8575\n",
      "Epoch 107, Loss: 0.0940, Accuracy: 0.8534, Test Loss: 0.0679, Test Accuracy: 0.8458\n",
      "Epoch 108, Loss: 0.0957, Accuracy: 0.8511, Test Loss: 0.0557, Test Accuracy: 0.8598\n",
      "Epoch 109, Loss: 0.0941, Accuracy: 0.8551, Test Loss: 0.0847, Test Accuracy: 0.8341\n",
      "Epoch 110, Loss: 0.0941, Accuracy: 0.8551, Test Loss: 0.0606, Test Accuracy: 0.8481\n",
      "Epoch 111, Loss: 0.0977, Accuracy: 0.8499, Test Loss: 0.0717, Test Accuracy: 0.8341\n",
      "Epoch 112, Loss: 0.0939, Accuracy: 0.8557, Test Loss: 0.0557, Test Accuracy: 0.8621\n",
      "Epoch 113, Loss: 0.0955, Accuracy: 0.8487, Test Loss: 0.0555, Test Accuracy: 0.8598\n",
      "Epoch 114, Loss: 0.0961, Accuracy: 0.8511, Test Loss: 0.0589, Test Accuracy: 0.8505\n",
      "Epoch 115, Loss: 0.0926, Accuracy: 0.8546, Test Loss: 0.0831, Test Accuracy: 0.8248\n",
      "Epoch 116, Loss: 0.0946, Accuracy: 0.8516, Test Loss: 0.0539, Test Accuracy: 0.8575\n",
      "Epoch 117, Loss: 0.0938, Accuracy: 0.8499, Test Loss: 0.0710, Test Accuracy: 0.8411\n",
      "Epoch 118, Loss: 0.0913, Accuracy: 0.8563, Test Loss: 0.0547, Test Accuracy: 0.8551\n",
      "Epoch 119, Loss: 0.0940, Accuracy: 0.8499, Test Loss: 0.0538, Test Accuracy: 0.8621\n",
      "Epoch 120, Loss: 0.0919, Accuracy: 0.8540, Test Loss: 0.0520, Test Accuracy: 0.8575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:18:15,591] Trial 118 finished with value: 0.866822429906542 and parameters: {'batch_size': 64, 'num_gcn_layers': 2, 'gcn_hidden_dim_0': 85, 'gcn_hidden_dim_1': 32, 'num_fc_layers': 2, 'fc_hidden_dim_0': 156, 'fc_hidden_dim_1': 243, 'learning_rate': 0.0007188522244264614, 'weight_decay': 2.0950265649678512e-05, 'pooling_method': 'max', 'gcn_batch_norm_flag_0': True, 'gcn_batch_norm_flag_1': True, 'gcn_momentum_0': 0.7945722902445773, 'gcn_momentum_1': 0.9615777504925537, 'gcn_eps_0': 0.00724982311428834, 'gcn_eps_1': 0.0016830928819993205, 'gcn_dropout_flag_0': False, 'gcn_dropout_flag_1': False, 'gcn_activation_0': 'softplus', 'gcn_activation_1': 'softplus', 'fc_batch_norm_flag_0': False, 'fc_batch_norm_flag_1': True, 'fc_momentum_1': 0.48073470187498935, 'fc_eps_1': 0.003246050831903892, 'fc_dropout_flag_0': False, 'fc_dropout_flag_1': True, 'fc_dropout_rate_1': 0.1748781935054634, 'fc_activation_0': 'relu', 'fc_activation_1': 'gelu', 'gcn_skip_connections_0': False, 'gcn_skip_connections_1': True, 'l1_lambda': 0.0002188440736890051, 'optimizer': 'Adam', 'beta1': 0.8686506192797756, 'beta2': 0.9876202600676681, 'lr_scheduler': 'OneCycleLR', 'max_lr_1': 0.03624125199616894, 'pct_start': 0.47833776175956555, 'loss_function': 'MultiMargin'}. Best is trial 33 with value: 0.8714953271028038.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121, Loss: 0.0937, Accuracy: 0.8516, Test Loss: 0.0548, Test Accuracy: 0.8551\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:18:18,094] Trial 119 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 3.3671, Accuracy: 0.6390, Test Loss: 4.6575, Test Accuracy: 0.2150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:18:19,705] Trial 120 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.5183, Accuracy: 0.6431, Test Loss: 0.5850, Test Accuracy: 0.2710\n",
      "Epoch 1, Loss: 0.7867, Accuracy: 0.7144, Test Loss: 0.1099, Test Accuracy: 0.7897\n",
      "Epoch 2, Loss: 0.6215, Accuracy: 0.7991, Test Loss: 0.0971, Test Accuracy: 0.8061\n",
      "Epoch 3, Loss: 0.5681, Accuracy: 0.7996, Test Loss: 0.0929, Test Accuracy: 0.8107\n",
      "Epoch 4, Loss: 0.5178, Accuracy: 0.8049, Test Loss: 0.0890, Test Accuracy: 0.8107\n",
      "Epoch 5, Loss: 0.4764, Accuracy: 0.8113, Test Loss: 0.0878, Test Accuracy: 0.8154\n",
      "Epoch 6, Loss: 0.4378, Accuracy: 0.8137, Test Loss: 0.0869, Test Accuracy: 0.8201\n",
      "Epoch 7, Loss: 0.3991, Accuracy: 0.8242, Test Loss: 0.0769, Test Accuracy: 0.8271\n",
      "Epoch 8, Loss: 0.3689, Accuracy: 0.8382, Test Loss: 0.0849, Test Accuracy: 0.8131\n",
      "Epoch 9, Loss: 0.3462, Accuracy: 0.8359, Test Loss: 0.0828, Test Accuracy: 0.8061\n",
      "Epoch 10, Loss: 0.3243, Accuracy: 0.8353, Test Loss: 0.0816, Test Accuracy: 0.8201\n",
      "Epoch 11, Loss: 0.3050, Accuracy: 0.8388, Test Loss: 0.0758, Test Accuracy: 0.8341\n",
      "Epoch 12, Loss: 0.2916, Accuracy: 0.8370, Test Loss: 0.0769, Test Accuracy: 0.8294\n",
      "Epoch 13, Loss: 0.2776, Accuracy: 0.8341, Test Loss: 0.0705, Test Accuracy: 0.8388\n",
      "Epoch 14, Loss: 0.2615, Accuracy: 0.8394, Test Loss: 0.0702, Test Accuracy: 0.8341\n",
      "Epoch 15, Loss: 0.2500, Accuracy: 0.8423, Test Loss: 0.0719, Test Accuracy: 0.8411\n",
      "Epoch 16, Loss: 0.2406, Accuracy: 0.8411, Test Loss: 0.0662, Test Accuracy: 0.8505\n",
      "Epoch 17, Loss: 0.2325, Accuracy: 0.8364, Test Loss: 0.0661, Test Accuracy: 0.8388\n",
      "Epoch 18, Loss: 0.2213, Accuracy: 0.8452, Test Loss: 0.0779, Test Accuracy: 0.8224\n",
      "Epoch 19, Loss: 0.2117, Accuracy: 0.8470, Test Loss: 0.0643, Test Accuracy: 0.8388\n",
      "Epoch 20, Loss: 0.2085, Accuracy: 0.8429, Test Loss: 0.0658, Test Accuracy: 0.8294\n",
      "Epoch 21, Loss: 0.1983, Accuracy: 0.8470, Test Loss: 0.0707, Test Accuracy: 0.8435\n",
      "Epoch 22, Loss: 0.1943, Accuracy: 0.8470, Test Loss: 0.0612, Test Accuracy: 0.8458\n",
      "Epoch 23, Loss: 0.1949, Accuracy: 0.8452, Test Loss: 0.0701, Test Accuracy: 0.8435\n",
      "Epoch 24, Loss: 0.1875, Accuracy: 0.8481, Test Loss: 0.0648, Test Accuracy: 0.8388\n",
      "Epoch 25, Loss: 0.1826, Accuracy: 0.8411, Test Loss: 0.0603, Test Accuracy: 0.8528\n",
      "Epoch 26, Loss: 0.1739, Accuracy: 0.8475, Test Loss: 0.0656, Test Accuracy: 0.8458\n",
      "Epoch 27, Loss: 0.1715, Accuracy: 0.8470, Test Loss: 0.0635, Test Accuracy: 0.8411\n",
      "Epoch 28, Loss: 0.1685, Accuracy: 0.8435, Test Loss: 0.0601, Test Accuracy: 0.8481\n",
      "Epoch 29, Loss: 0.1623, Accuracy: 0.8493, Test Loss: 0.0619, Test Accuracy: 0.8551\n",
      "Epoch 30, Loss: 0.1589, Accuracy: 0.8505, Test Loss: 0.0596, Test Accuracy: 0.8528\n",
      "Epoch 31, Loss: 0.1607, Accuracy: 0.8411, Test Loss: 0.0613, Test Accuracy: 0.8435\n",
      "Epoch 32, Loss: 0.1555, Accuracy: 0.8440, Test Loss: 0.0661, Test Accuracy: 0.8435\n",
      "Epoch 33, Loss: 0.1528, Accuracy: 0.8470, Test Loss: 0.0623, Test Accuracy: 0.8435\n",
      "Epoch 34, Loss: 0.1471, Accuracy: 0.8516, Test Loss: 0.0675, Test Accuracy: 0.8435\n",
      "Epoch 35, Loss: 0.1458, Accuracy: 0.8481, Test Loss: 0.0645, Test Accuracy: 0.8364\n",
      "Epoch 36, Loss: 0.1449, Accuracy: 0.8446, Test Loss: 0.0622, Test Accuracy: 0.8411\n",
      "Epoch 37, Loss: 0.1419, Accuracy: 0.8487, Test Loss: 0.0671, Test Accuracy: 0.8388\n",
      "Epoch 38, Loss: 0.1408, Accuracy: 0.8470, Test Loss: 0.0664, Test Accuracy: 0.8481\n",
      "Epoch 39, Loss: 0.1381, Accuracy: 0.8458, Test Loss: 0.0632, Test Accuracy: 0.8528\n",
      "Epoch 40, Loss: 0.1357, Accuracy: 0.8481, Test Loss: 0.0594, Test Accuracy: 0.8458\n",
      "Epoch 41, Loss: 0.1325, Accuracy: 0.8511, Test Loss: 0.0655, Test Accuracy: 0.8435\n",
      "Epoch 42, Loss: 0.1330, Accuracy: 0.8458, Test Loss: 0.0585, Test Accuracy: 0.8505\n",
      "Epoch 43, Loss: 0.1299, Accuracy: 0.8528, Test Loss: 0.0836, Test Accuracy: 0.8364\n",
      "Epoch 44, Loss: 0.1250, Accuracy: 0.8540, Test Loss: 0.0612, Test Accuracy: 0.8598\n",
      "Epoch 45, Loss: 0.1236, Accuracy: 0.8528, Test Loss: 0.0576, Test Accuracy: 0.8575\n",
      "Epoch 46, Loss: 0.1249, Accuracy: 0.8470, Test Loss: 0.0640, Test Accuracy: 0.8388\n",
      "Epoch 47, Loss: 0.1231, Accuracy: 0.8481, Test Loss: 0.0618, Test Accuracy: 0.8388\n",
      "Epoch 48, Loss: 0.1215, Accuracy: 0.8470, Test Loss: 0.0595, Test Accuracy: 0.8621\n",
      "Epoch 49, Loss: 0.1193, Accuracy: 0.8522, Test Loss: 0.0608, Test Accuracy: 0.8481\n",
      "Epoch 50, Loss: 0.1196, Accuracy: 0.8446, Test Loss: 0.0644, Test Accuracy: 0.8505\n",
      "Epoch 51, Loss: 0.1186, Accuracy: 0.8499, Test Loss: 0.0634, Test Accuracy: 0.8458\n",
      "Epoch 52, Loss: 0.1205, Accuracy: 0.8458, Test Loss: 0.0568, Test Accuracy: 0.8598\n",
      "Epoch 53, Loss: 0.1160, Accuracy: 0.8505, Test Loss: 0.0677, Test Accuracy: 0.8341\n",
      "Epoch 54, Loss: 0.1165, Accuracy: 0.8481, Test Loss: 0.0594, Test Accuracy: 0.8575\n",
      "Epoch 55, Loss: 0.1140, Accuracy: 0.8458, Test Loss: 0.0589, Test Accuracy: 0.8458\n",
      "Epoch 56, Loss: 0.1142, Accuracy: 0.8499, Test Loss: 0.0593, Test Accuracy: 0.8435\n",
      "Epoch 57, Loss: 0.1110, Accuracy: 0.8516, Test Loss: 0.0611, Test Accuracy: 0.8458\n",
      "Epoch 58, Loss: 0.1077, Accuracy: 0.8540, Test Loss: 0.0643, Test Accuracy: 0.8551\n",
      "Epoch 59, Loss: 0.1099, Accuracy: 0.8516, Test Loss: 0.0663, Test Accuracy: 0.8411\n",
      "Epoch 60, Loss: 0.1066, Accuracy: 0.8528, Test Loss: 0.0562, Test Accuracy: 0.8551\n",
      "Epoch 61, Loss: 0.1055, Accuracy: 0.8563, Test Loss: 0.0595, Test Accuracy: 0.8575\n",
      "Epoch 62, Loss: 0.1061, Accuracy: 0.8481, Test Loss: 0.0581, Test Accuracy: 0.8575\n",
      "Epoch 63, Loss: 0.1058, Accuracy: 0.8528, Test Loss: 0.0568, Test Accuracy: 0.8575\n",
      "Epoch 64, Loss: 0.1035, Accuracy: 0.8499, Test Loss: 0.0642, Test Accuracy: 0.8435\n",
      "Epoch 65, Loss: 0.1017, Accuracy: 0.8516, Test Loss: 0.0576, Test Accuracy: 0.8621\n",
      "Epoch 66, Loss: 0.1014, Accuracy: 0.8563, Test Loss: 0.0555, Test Accuracy: 0.8598\n",
      "Epoch 67, Loss: 0.1018, Accuracy: 0.8546, Test Loss: 0.0597, Test Accuracy: 0.8598\n",
      "Epoch 68, Loss: 0.1010, Accuracy: 0.8516, Test Loss: 0.0626, Test Accuracy: 0.8528\n",
      "Epoch 69, Loss: 0.1039, Accuracy: 0.8487, Test Loss: 0.0631, Test Accuracy: 0.8505\n",
      "Epoch 70, Loss: 0.0995, Accuracy: 0.8528, Test Loss: 0.0588, Test Accuracy: 0.8505\n",
      "Epoch 71, Loss: 0.1002, Accuracy: 0.8551, Test Loss: 0.0554, Test Accuracy: 0.8551\n",
      "Epoch 72, Loss: 0.0987, Accuracy: 0.8528, Test Loss: 0.0622, Test Accuracy: 0.8551\n",
      "Epoch 73, Loss: 0.0997, Accuracy: 0.8499, Test Loss: 0.0583, Test Accuracy: 0.8575\n",
      "Epoch 74, Loss: 0.0978, Accuracy: 0.8528, Test Loss: 0.0577, Test Accuracy: 0.8575\n",
      "Epoch 75, Loss: 0.0945, Accuracy: 0.8581, Test Loss: 0.0551, Test Accuracy: 0.8621\n",
      "Epoch 76, Loss: 0.0961, Accuracy: 0.8511, Test Loss: 0.0563, Test Accuracy: 0.8598\n",
      "Epoch 77, Loss: 0.0983, Accuracy: 0.8528, Test Loss: 0.0605, Test Accuracy: 0.8528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:19:55,507] Trial 121 finished with value: 0.8621495327102804 and parameters: {'batch_size': 64, 'num_gcn_layers': 2, 'gcn_hidden_dim_0': 92, 'gcn_hidden_dim_1': 44, 'num_fc_layers': 2, 'fc_hidden_dim_0': 167, 'fc_hidden_dim_1': 226, 'learning_rate': 0.006213225615838132, 'weight_decay': 7.006712542221614e-05, 'pooling_method': 'max', 'gcn_batch_norm_flag_0': True, 'gcn_batch_norm_flag_1': True, 'gcn_momentum_0': 0.7580593581432423, 'gcn_momentum_1': 0.9637282949155371, 'gcn_eps_0': 0.006519231544952091, 'gcn_eps_1': 0.0007020674079565096, 'gcn_dropout_flag_0': False, 'gcn_dropout_flag_1': False, 'gcn_activation_0': 'softplus', 'gcn_activation_1': 'softplus', 'fc_batch_norm_flag_0': False, 'fc_batch_norm_flag_1': True, 'fc_momentum_1': 0.4982149938397964, 'fc_eps_1': 0.0027595806475860787, 'fc_dropout_flag_0': False, 'fc_dropout_flag_1': True, 'fc_dropout_rate_1': 0.19092227624158184, 'fc_activation_0': 'relu', 'fc_activation_1': 'gelu', 'gcn_skip_connections_0': False, 'gcn_skip_connections_1': True, 'l1_lambda': 0.00018789685691052383, 'optimizer': 'Adam', 'beta1': 0.8610558499642443, 'beta2': 0.9883800422526668, 'lr_scheduler': 'OneCycleLR', 'max_lr_1': 0.03595785401769013, 'pct_start': 0.4665821153064396, 'loss_function': 'MultiMargin'}. Best is trial 33 with value: 0.8714953271028038.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78, Loss: 0.0984, Accuracy: 0.8487, Test Loss: 0.0595, Test Accuracy: 0.8411\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:19:57,035] Trial 122 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.8459, Accuracy: 0.7091, Test Loss: 0.1253, Test Accuracy: 0.7640\n",
      "Epoch 1, Loss: 0.8261, Accuracy: 0.7179, Test Loss: 0.1109, Test Accuracy: 0.7804\n",
      "Epoch 2, Loss: 0.6558, Accuracy: 0.7845, Test Loss: 0.1015, Test Accuracy: 0.8014\n",
      "Epoch 3, Loss: 0.5639, Accuracy: 0.8002, Test Loss: 0.1203, Test Accuracy: 0.7710\n",
      "Epoch 4, Loss: 0.4781, Accuracy: 0.8084, Test Loss: 0.0887, Test Accuracy: 0.8107\n",
      "Epoch 5, Loss: 0.4066, Accuracy: 0.8061, Test Loss: 0.0815, Test Accuracy: 0.8178\n",
      "Epoch 6, Loss: 0.3490, Accuracy: 0.8213, Test Loss: 0.0933, Test Accuracy: 0.8248\n",
      "Epoch 7, Loss: 0.3023, Accuracy: 0.8248, Test Loss: 0.0754, Test Accuracy: 0.8248\n",
      "Epoch 8, Loss: 0.2676, Accuracy: 0.8254, Test Loss: 0.0775, Test Accuracy: 0.8107\n",
      "Epoch 9, Loss: 0.2420, Accuracy: 0.8300, Test Loss: 0.0733, Test Accuracy: 0.8388\n",
      "Epoch 10, Loss: 0.2266, Accuracy: 0.8283, Test Loss: 0.0691, Test Accuracy: 0.8411\n",
      "Epoch 11, Loss: 0.2084, Accuracy: 0.8417, Test Loss: 0.0728, Test Accuracy: 0.8364\n",
      "Epoch 12, Loss: 0.1994, Accuracy: 0.8394, Test Loss: 0.0808, Test Accuracy: 0.8364\n",
      "Epoch 13, Loss: 0.1842, Accuracy: 0.8440, Test Loss: 0.0638, Test Accuracy: 0.8435\n",
      "Epoch 14, Loss: 0.1776, Accuracy: 0.8370, Test Loss: 0.0753, Test Accuracy: 0.8248\n",
      "Epoch 15, Loss: 0.1721, Accuracy: 0.8370, Test Loss: 0.0719, Test Accuracy: 0.8201\n",
      "Epoch 16, Loss: 0.1642, Accuracy: 0.8446, Test Loss: 0.0651, Test Accuracy: 0.8435\n",
      "Epoch 17, Loss: 0.1579, Accuracy: 0.8429, Test Loss: 0.0762, Test Accuracy: 0.8341\n",
      "Epoch 18, Loss: 0.1576, Accuracy: 0.8382, Test Loss: 0.0643, Test Accuracy: 0.8411\n",
      "Epoch 19, Loss: 0.1517, Accuracy: 0.8435, Test Loss: 0.0808, Test Accuracy: 0.8224\n",
      "Epoch 20, Loss: 0.1517, Accuracy: 0.8347, Test Loss: 0.0636, Test Accuracy: 0.8388\n",
      "Epoch 21, Loss: 0.1449, Accuracy: 0.8417, Test Loss: 0.0656, Test Accuracy: 0.8528\n",
      "Epoch 22, Loss: 0.1355, Accuracy: 0.8452, Test Loss: 0.0601, Test Accuracy: 0.8505\n",
      "Epoch 23, Loss: 0.1322, Accuracy: 0.8400, Test Loss: 0.0710, Test Accuracy: 0.8341\n",
      "Epoch 24, Loss: 0.1287, Accuracy: 0.8446, Test Loss: 0.0602, Test Accuracy: 0.8458\n",
      "Epoch 25, Loss: 0.1261, Accuracy: 0.8475, Test Loss: 0.0651, Test Accuracy: 0.8388\n",
      "Epoch 26, Loss: 0.1225, Accuracy: 0.8417, Test Loss: 0.0674, Test Accuracy: 0.8458\n",
      "Epoch 27, Loss: 0.1204, Accuracy: 0.8487, Test Loss: 0.0575, Test Accuracy: 0.8481\n",
      "Epoch 28, Loss: 0.1198, Accuracy: 0.8435, Test Loss: 0.0626, Test Accuracy: 0.8435\n",
      "Epoch 29, Loss: 0.1190, Accuracy: 0.8435, Test Loss: 0.0619, Test Accuracy: 0.8528\n",
      "Epoch 30, Loss: 0.1160, Accuracy: 0.8440, Test Loss: 0.0580, Test Accuracy: 0.8505\n",
      "Epoch 31, Loss: 0.1127, Accuracy: 0.8487, Test Loss: 0.0579, Test Accuracy: 0.8458\n",
      "Epoch 32, Loss: 0.1131, Accuracy: 0.8411, Test Loss: 0.0620, Test Accuracy: 0.8551\n",
      "Epoch 33, Loss: 0.1087, Accuracy: 0.8540, Test Loss: 0.0609, Test Accuracy: 0.8388\n",
      "Epoch 34, Loss: 0.1099, Accuracy: 0.8475, Test Loss: 0.0625, Test Accuracy: 0.8528\n",
      "Epoch 35, Loss: 0.1072, Accuracy: 0.8516, Test Loss: 0.0625, Test Accuracy: 0.8435\n",
      "Epoch 36, Loss: 0.1067, Accuracy: 0.8493, Test Loss: 0.0627, Test Accuracy: 0.8528\n",
      "Epoch 37, Loss: 0.1058, Accuracy: 0.8452, Test Loss: 0.0593, Test Accuracy: 0.8458\n",
      "Epoch 38, Loss: 0.1086, Accuracy: 0.8388, Test Loss: 0.0671, Test Accuracy: 0.8364\n",
      "Epoch 39, Loss: 0.1075, Accuracy: 0.8411, Test Loss: 0.0602, Test Accuracy: 0.8505\n",
      "Epoch 40, Loss: 0.1051, Accuracy: 0.8464, Test Loss: 0.0672, Test Accuracy: 0.8364\n",
      "Epoch 41, Loss: 0.1049, Accuracy: 0.8493, Test Loss: 0.0562, Test Accuracy: 0.8551\n",
      "Epoch 42, Loss: 0.1030, Accuracy: 0.8470, Test Loss: 0.0687, Test Accuracy: 0.8388\n",
      "Epoch 43, Loss: 0.1007, Accuracy: 0.8493, Test Loss: 0.0655, Test Accuracy: 0.8364\n",
      "Epoch 44, Loss: 0.1003, Accuracy: 0.8452, Test Loss: 0.0611, Test Accuracy: 0.8481\n",
      "Epoch 45, Loss: 0.0974, Accuracy: 0.8505, Test Loss: 0.0627, Test Accuracy: 0.8435\n",
      "Epoch 46, Loss: 0.0968, Accuracy: 0.8475, Test Loss: 0.0559, Test Accuracy: 0.8598\n",
      "Epoch 47, Loss: 0.0976, Accuracy: 0.8452, Test Loss: 0.0567, Test Accuracy: 0.8528\n",
      "Epoch 48, Loss: 0.0947, Accuracy: 0.8522, Test Loss: 0.0569, Test Accuracy: 0.8505\n",
      "Epoch 49, Loss: 0.0949, Accuracy: 0.8534, Test Loss: 0.0638, Test Accuracy: 0.8411\n",
      "Epoch 50, Loss: 0.0924, Accuracy: 0.8493, Test Loss: 0.0576, Test Accuracy: 0.8598\n",
      "Epoch 51, Loss: 0.0937, Accuracy: 0.8446, Test Loss: 0.0558, Test Accuracy: 0.8575\n",
      "Epoch 52, Loss: 0.0942, Accuracy: 0.8493, Test Loss: 0.0593, Test Accuracy: 0.8551\n",
      "Epoch 53, Loss: 0.0929, Accuracy: 0.8470, Test Loss: 0.0599, Test Accuracy: 0.8435\n",
      "Epoch 54, Loss: 0.0925, Accuracy: 0.8528, Test Loss: 0.0687, Test Accuracy: 0.8341\n",
      "Epoch 55, Loss: 0.0924, Accuracy: 0.8470, Test Loss: 0.0580, Test Accuracy: 0.8621\n",
      "Epoch 56, Loss: 0.0948, Accuracy: 0.8440, Test Loss: 0.0612, Test Accuracy: 0.8364\n",
      "Epoch 57, Loss: 0.0906, Accuracy: 0.8528, Test Loss: 0.0548, Test Accuracy: 0.8528\n",
      "Epoch 58, Loss: 0.0875, Accuracy: 0.8511, Test Loss: 0.0536, Test Accuracy: 0.8575\n",
      "Epoch 59, Loss: 0.0878, Accuracy: 0.8499, Test Loss: 0.0625, Test Accuracy: 0.8435\n",
      "Epoch 60, Loss: 0.0875, Accuracy: 0.8528, Test Loss: 0.0567, Test Accuracy: 0.8575\n",
      "Epoch 61, Loss: 0.0882, Accuracy: 0.8487, Test Loss: 0.0543, Test Accuracy: 0.8575\n",
      "Epoch 62, Loss: 0.0879, Accuracy: 0.8487, Test Loss: 0.0751, Test Accuracy: 0.8248\n",
      "Epoch 63, Loss: 0.0875, Accuracy: 0.8452, Test Loss: 0.0582, Test Accuracy: 0.8481\n",
      "Epoch 64, Loss: 0.0874, Accuracy: 0.8458, Test Loss: 0.0585, Test Accuracy: 0.8481\n",
      "Epoch 65, Loss: 0.0864, Accuracy: 0.8557, Test Loss: 0.0682, Test Accuracy: 0.8341\n",
      "Epoch 66, Loss: 0.0869, Accuracy: 0.8505, Test Loss: 0.0625, Test Accuracy: 0.8458\n",
      "Epoch 67, Loss: 0.0829, Accuracy: 0.8575, Test Loss: 0.0568, Test Accuracy: 0.8575\n",
      "Epoch 68, Loss: 0.0855, Accuracy: 0.8551, Test Loss: 0.0614, Test Accuracy: 0.8388\n",
      "Epoch 69, Loss: 0.0843, Accuracy: 0.8475, Test Loss: 0.0572, Test Accuracy: 0.8551\n",
      "Epoch 70, Loss: 0.0830, Accuracy: 0.8499, Test Loss: 0.0606, Test Accuracy: 0.8481\n",
      "Epoch 71, Loss: 0.0819, Accuracy: 0.8528, Test Loss: 0.0516, Test Accuracy: 0.8598\n",
      "Epoch 72, Loss: 0.0845, Accuracy: 0.8511, Test Loss: 0.0526, Test Accuracy: 0.8645\n",
      "Epoch 73, Loss: 0.0846, Accuracy: 0.8493, Test Loss: 0.0552, Test Accuracy: 0.8621\n",
      "Epoch 74, Loss: 0.0812, Accuracy: 0.8563, Test Loss: 0.0576, Test Accuracy: 0.8575\n",
      "Epoch 75, Loss: 0.0821, Accuracy: 0.8522, Test Loss: 0.0570, Test Accuracy: 0.8551\n",
      "Epoch 76, Loss: 0.0797, Accuracy: 0.8551, Test Loss: 0.0647, Test Accuracy: 0.8388\n",
      "Epoch 77, Loss: 0.0844, Accuracy: 0.8499, Test Loss: 0.0567, Test Accuracy: 0.8458\n",
      "Epoch 78, Loss: 0.0811, Accuracy: 0.8540, Test Loss: 0.0651, Test Accuracy: 0.8435\n",
      "Epoch 79, Loss: 0.0805, Accuracy: 0.8569, Test Loss: 0.0658, Test Accuracy: 0.8458\n",
      "Epoch 80, Loss: 0.0806, Accuracy: 0.8534, Test Loss: 0.0558, Test Accuracy: 0.8551\n",
      "Epoch 81, Loss: 0.0826, Accuracy: 0.8505, Test Loss: 0.0596, Test Accuracy: 0.8481\n",
      "Epoch 82, Loss: 0.0840, Accuracy: 0.8470, Test Loss: 0.0573, Test Accuracy: 0.8551\n",
      "Epoch 83, Loss: 0.0806, Accuracy: 0.8505, Test Loss: 0.0606, Test Accuracy: 0.8458\n",
      "Epoch 84, Loss: 0.0827, Accuracy: 0.8522, Test Loss: 0.0567, Test Accuracy: 0.8505\n",
      "Epoch 85, Loss: 0.0812, Accuracy: 0.8534, Test Loss: 0.0555, Test Accuracy: 0.8551\n",
      "Epoch 86, Loss: 0.0799, Accuracy: 0.8540, Test Loss: 0.0538, Test Accuracy: 0.8551\n",
      "Epoch 87, Loss: 0.0802, Accuracy: 0.8522, Test Loss: 0.0647, Test Accuracy: 0.8388\n",
      "Epoch 88, Loss: 0.0795, Accuracy: 0.8511, Test Loss: 0.0525, Test Accuracy: 0.8551\n",
      "Epoch 89, Loss: 0.0795, Accuracy: 0.8528, Test Loss: 0.0524, Test Accuracy: 0.8575\n",
      "Epoch 90, Loss: 0.0800, Accuracy: 0.8528, Test Loss: 0.0583, Test Accuracy: 0.8505\n",
      "Epoch 91, Loss: 0.0794, Accuracy: 0.8522, Test Loss: 0.0504, Test Accuracy: 0.8575\n",
      "Epoch 92, Loss: 0.0809, Accuracy: 0.8487, Test Loss: 0.0665, Test Accuracy: 0.8458\n",
      "Epoch 93, Loss: 0.0808, Accuracy: 0.8487, Test Loss: 0.0583, Test Accuracy: 0.8575\n",
      "Epoch 94, Loss: 0.0777, Accuracy: 0.8540, Test Loss: 0.0607, Test Accuracy: 0.8575\n",
      "Epoch 95, Loss: 0.0789, Accuracy: 0.8569, Test Loss: 0.0522, Test Accuracy: 0.8551\n",
      "Epoch 96, Loss: 0.0785, Accuracy: 0.8551, Test Loss: 0.0579, Test Accuracy: 0.8528\n",
      "Epoch 97, Loss: 0.0783, Accuracy: 0.8557, Test Loss: 0.0518, Test Accuracy: 0.8598\n",
      "Epoch 98, Loss: 0.0801, Accuracy: 0.8493, Test Loss: 0.0576, Test Accuracy: 0.8481\n",
      "Epoch 99, Loss: 0.0793, Accuracy: 0.8534, Test Loss: 0.0544, Test Accuracy: 0.8621\n",
      "Epoch 100, Loss: 0.0776, Accuracy: 0.8557, Test Loss: 0.0569, Test Accuracy: 0.8505\n",
      "Epoch 101, Loss: 0.0756, Accuracy: 0.8557, Test Loss: 0.0538, Test Accuracy: 0.8481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:23:24,786] Trial 123 finished with value: 0.8644859813084113 and parameters: {'batch_size': 32, 'num_gcn_layers': 2, 'gcn_hidden_dim_0': 87, 'gcn_hidden_dim_1': 200, 'num_fc_layers': 2, 'fc_hidden_dim_0': 181, 'fc_hidden_dim_1': 45, 'learning_rate': 0.00048733106256919204, 'weight_decay': 2.7289082350007722e-05, 'pooling_method': 'max', 'gcn_batch_norm_flag_0': True, 'gcn_batch_norm_flag_1': True, 'gcn_momentum_0': 0.7084373242338702, 'gcn_momentum_1': 0.8948479780203397, 'gcn_eps_0': 0.004556400988235919, 'gcn_eps_1': 0.008898763564050914, 'gcn_dropout_flag_0': False, 'gcn_dropout_flag_1': False, 'gcn_activation_0': 'softplus', 'gcn_activation_1': 'tanh', 'fc_batch_norm_flag_0': False, 'fc_batch_norm_flag_1': True, 'fc_momentum_1': 0.5877202869997439, 'fc_eps_1': 0.0023261980456293504, 'fc_dropout_flag_0': False, 'fc_dropout_flag_1': True, 'fc_dropout_rate_1': 0.1701803463305116, 'fc_activation_0': 'elu', 'fc_activation_1': 'leaky_relu', 'gcn_skip_connections_0': False, 'gcn_skip_connections_1': True, 'l1_lambda': 0.00013761204861579003, 'optimizer': 'Adam', 'beta1': 0.8667601327733384, 'beta2': 0.9910998305132657, 'lr_scheduler': 'OneCycleLR', 'max_lr_1': 0.03036789591413557, 'pct_start': 0.11862363276436778, 'loss_function': 'MultiMargin'}. Best is trial 33 with value: 0.8714953271028038.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102, Loss: 0.0755, Accuracy: 0.8569, Test Loss: 0.0543, Test Accuracy: 0.8551\n",
      "Early stopping triggered\n",
      "Epoch 1, Loss: 0.7823, Accuracy: 0.7126, Test Loss: 0.1359, Test Accuracy: 0.7827\n",
      "Epoch 2, Loss: 0.6418, Accuracy: 0.7979, Test Loss: 0.0988, Test Accuracy: 0.8084\n",
      "Epoch 3, Loss: 0.5500, Accuracy: 0.8061, Test Loss: 0.0950, Test Accuracy: 0.8084\n",
      "Epoch 4, Loss: 0.4682, Accuracy: 0.8049, Test Loss: 0.0909, Test Accuracy: 0.8131\n",
      "Epoch 5, Loss: 0.3939, Accuracy: 0.8055, Test Loss: 0.0858, Test Accuracy: 0.8178\n",
      "Epoch 6, Loss: 0.3406, Accuracy: 0.8148, Test Loss: 0.0921, Test Accuracy: 0.8154\n",
      "Epoch 7, Loss: 0.3004, Accuracy: 0.8166, Test Loss: 0.0753, Test Accuracy: 0.8178\n",
      "Epoch 8, Loss: 0.2601, Accuracy: 0.8242, Test Loss: 0.0908, Test Accuracy: 0.8084\n",
      "Epoch 9, Loss: 0.2413, Accuracy: 0.8341, Test Loss: 0.0880, Test Accuracy: 0.8294\n",
      "Epoch 10, Loss: 0.2228, Accuracy: 0.8318, Test Loss: 0.0827, Test Accuracy: 0.8388\n",
      "Epoch 11, Loss: 0.2080, Accuracy: 0.8347, Test Loss: 0.0886, Test Accuracy: 0.8294\n",
      "Epoch 12, Loss: 0.2023, Accuracy: 0.8324, Test Loss: 0.0781, Test Accuracy: 0.8154\n",
      "Epoch 13, Loss: 0.1977, Accuracy: 0.8341, Test Loss: 0.0697, Test Accuracy: 0.8388\n",
      "Epoch 14, Loss: 0.1879, Accuracy: 0.8376, Test Loss: 0.0616, Test Accuracy: 0.8528\n",
      "Epoch 15, Loss: 0.1798, Accuracy: 0.8423, Test Loss: 0.0664, Test Accuracy: 0.8388\n",
      "Epoch 16, Loss: 0.1722, Accuracy: 0.8370, Test Loss: 0.0739, Test Accuracy: 0.8271\n",
      "Epoch 17, Loss: 0.1657, Accuracy: 0.8382, Test Loss: 0.0621, Test Accuracy: 0.8598\n",
      "Epoch 18, Loss: 0.1594, Accuracy: 0.8364, Test Loss: 0.0670, Test Accuracy: 0.8388\n",
      "Epoch 19, Loss: 0.1512, Accuracy: 0.8423, Test Loss: 0.0604, Test Accuracy: 0.8458\n",
      "Epoch 20, Loss: 0.1481, Accuracy: 0.8411, Test Loss: 0.0703, Test Accuracy: 0.8458\n",
      "Epoch 21, Loss: 0.1416, Accuracy: 0.8470, Test Loss: 0.0821, Test Accuracy: 0.8224\n",
      "Epoch 22, Loss: 0.1411, Accuracy: 0.8394, Test Loss: 0.0726, Test Accuracy: 0.8388\n",
      "Epoch 23, Loss: 0.1372, Accuracy: 0.8382, Test Loss: 0.0753, Test Accuracy: 0.8458\n",
      "Epoch 24, Loss: 0.1294, Accuracy: 0.8435, Test Loss: 0.0635, Test Accuracy: 0.8481\n",
      "Epoch 25, Loss: 0.1252, Accuracy: 0.8429, Test Loss: 0.0699, Test Accuracy: 0.8435\n",
      "Epoch 26, Loss: 0.1204, Accuracy: 0.8464, Test Loss: 0.0575, Test Accuracy: 0.8598\n",
      "Epoch 27, Loss: 0.1140, Accuracy: 0.8493, Test Loss: 0.0655, Test Accuracy: 0.8528\n",
      "Epoch 28, Loss: 0.1112, Accuracy: 0.8464, Test Loss: 0.0585, Test Accuracy: 0.8505\n",
      "Epoch 29, Loss: 0.1096, Accuracy: 0.8446, Test Loss: 0.0671, Test Accuracy: 0.8435\n",
      "Epoch 30, Loss: 0.1085, Accuracy: 0.8499, Test Loss: 0.0600, Test Accuracy: 0.8505\n",
      "Epoch 31, Loss: 0.1072, Accuracy: 0.8475, Test Loss: 0.0594, Test Accuracy: 0.8621\n",
      "Epoch 32, Loss: 0.1053, Accuracy: 0.8440, Test Loss: 0.0613, Test Accuracy: 0.8481\n",
      "Epoch 33, Loss: 0.1039, Accuracy: 0.8505, Test Loss: 0.0661, Test Accuracy: 0.8411\n",
      "Epoch 34, Loss: 0.1051, Accuracy: 0.8435, Test Loss: 0.0573, Test Accuracy: 0.8668\n",
      "Epoch 35, Loss: 0.1025, Accuracy: 0.8499, Test Loss: 0.0623, Test Accuracy: 0.8388\n",
      "Epoch 36, Loss: 0.1019, Accuracy: 0.8493, Test Loss: 0.0578, Test Accuracy: 0.8645\n",
      "Epoch 37, Loss: 0.0980, Accuracy: 0.8522, Test Loss: 0.0591, Test Accuracy: 0.8505\n",
      "Epoch 38, Loss: 0.0961, Accuracy: 0.8528, Test Loss: 0.0618, Test Accuracy: 0.8458\n",
      "Epoch 39, Loss: 0.0955, Accuracy: 0.8516, Test Loss: 0.0657, Test Accuracy: 0.8551\n",
      "Epoch 40, Loss: 0.0978, Accuracy: 0.8481, Test Loss: 0.0542, Test Accuracy: 0.8645\n",
      "Epoch 41, Loss: 0.0934, Accuracy: 0.8493, Test Loss: 0.0526, Test Accuracy: 0.8668\n",
      "Epoch 42, Loss: 0.0952, Accuracy: 0.8470, Test Loss: 0.0560, Test Accuracy: 0.8598\n",
      "Epoch 43, Loss: 0.0960, Accuracy: 0.8475, Test Loss: 0.0542, Test Accuracy: 0.8621\n",
      "Epoch 44, Loss: 0.0949, Accuracy: 0.8470, Test Loss: 0.0529, Test Accuracy: 0.8575\n",
      "Epoch 45, Loss: 0.0930, Accuracy: 0.8481, Test Loss: 0.0542, Test Accuracy: 0.8621\n",
      "Epoch 46, Loss: 0.0928, Accuracy: 0.8511, Test Loss: 0.0565, Test Accuracy: 0.8528\n",
      "Epoch 47, Loss: 0.0889, Accuracy: 0.8540, Test Loss: 0.0544, Test Accuracy: 0.8598\n",
      "Epoch 48, Loss: 0.0871, Accuracy: 0.8546, Test Loss: 0.0557, Test Accuracy: 0.8621\n",
      "Epoch 49, Loss: 0.0864, Accuracy: 0.8563, Test Loss: 0.0627, Test Accuracy: 0.8364\n",
      "Epoch 50, Loss: 0.0877, Accuracy: 0.8458, Test Loss: 0.0556, Test Accuracy: 0.8621\n",
      "Epoch 51, Loss: 0.0876, Accuracy: 0.8540, Test Loss: 0.0552, Test Accuracy: 0.8621\n",
      "Epoch 52, Loss: 0.0867, Accuracy: 0.8505, Test Loss: 0.0537, Test Accuracy: 0.8598\n",
      "Epoch 53, Loss: 0.0877, Accuracy: 0.8511, Test Loss: 0.0526, Test Accuracy: 0.8598\n",
      "Epoch 54, Loss: 0.0900, Accuracy: 0.8481, Test Loss: 0.0560, Test Accuracy: 0.8505\n",
      "Epoch 55, Loss: 0.0902, Accuracy: 0.8505, Test Loss: 0.0562, Test Accuracy: 0.8528\n",
      "Epoch 56, Loss: 0.0939, Accuracy: 0.8475, Test Loss: 0.0559, Test Accuracy: 0.8505\n",
      "Epoch 57, Loss: 0.0930, Accuracy: 0.8528, Test Loss: 0.0569, Test Accuracy: 0.8621\n",
      "Epoch 58, Loss: 0.0895, Accuracy: 0.8511, Test Loss: 0.0573, Test Accuracy: 0.8575\n",
      "Epoch 59, Loss: 0.0866, Accuracy: 0.8557, Test Loss: 0.0567, Test Accuracy: 0.8645\n",
      "Epoch 60, Loss: 0.0855, Accuracy: 0.8546, Test Loss: 0.0577, Test Accuracy: 0.8528\n",
      "Epoch 61, Loss: 0.0869, Accuracy: 0.8516, Test Loss: 0.0665, Test Accuracy: 0.8411\n",
      "Epoch 62, Loss: 0.0891, Accuracy: 0.8452, Test Loss: 0.0576, Test Accuracy: 0.8528\n",
      "Epoch 63, Loss: 0.0847, Accuracy: 0.8522, Test Loss: 0.0543, Test Accuracy: 0.8598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:24:50,201] Trial 124 finished with value: 0.866822429906542 and parameters: {'batch_size': 64, 'num_gcn_layers': 2, 'gcn_hidden_dim_0': 58, 'gcn_hidden_dim_1': 186, 'num_fc_layers': 2, 'fc_hidden_dim_0': 191, 'fc_hidden_dim_1': 240, 'learning_rate': 0.004211068657511489, 'weight_decay': 9.222455871535685e-07, 'pooling_method': 'max', 'gcn_batch_norm_flag_0': True, 'gcn_batch_norm_flag_1': True, 'gcn_momentum_0': 0.984568094082202, 'gcn_momentum_1': 0.39234572835838155, 'gcn_eps_0': 0.007657601611873466, 'gcn_eps_1': 0.00085217829429265, 'gcn_dropout_flag_0': False, 'gcn_dropout_flag_1': False, 'gcn_activation_0': 'elu', 'gcn_activation_1': 'relu', 'fc_batch_norm_flag_0': False, 'fc_batch_norm_flag_1': True, 'fc_momentum_1': 0.4065146818288783, 'fc_eps_1': 0.00030967348681963864, 'fc_dropout_flag_0': False, 'fc_dropout_flag_1': True, 'fc_dropout_rate_1': 0.22530867770375182, 'fc_activation_0': 'relu', 'fc_activation_1': 'leaky_relu', 'gcn_skip_connections_0': False, 'gcn_skip_connections_1': True, 'l1_lambda': 0.00012018044916376318, 'optimizer': 'Adam', 'beta1': 0.9142582285256855, 'beta2': 0.9953324571616635, 'lr_scheduler': 'OneCycleLR', 'max_lr_1': 0.09537724098761717, 'pct_start': 0.1623525569066435, 'loss_function': 'MultiMargin'}. Best is trial 33 with value: 0.8714953271028038.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64, Loss: 0.0881, Accuracy: 0.8470, Test Loss: 0.0526, Test Accuracy: 0.8598\n",
      "Early stopping triggered\n",
      "Epoch 1, Loss: 0.5460, Accuracy: 0.7068, Test Loss: 0.1469, Test Accuracy: 0.7757\n",
      "Epoch 2, Loss: 0.4315, Accuracy: 0.7839, Test Loss: 0.1032, Test Accuracy: 0.8061\n",
      "Epoch 3, Loss: 0.3921, Accuracy: 0.7967, Test Loss: 0.0983, Test Accuracy: 0.8131\n",
      "Epoch 4, Loss: 0.3436, Accuracy: 0.8037, Test Loss: 0.1041, Test Accuracy: 0.8037\n",
      "Epoch 5, Loss: 0.3195, Accuracy: 0.8026, Test Loss: 0.1085, Test Accuracy: 0.7734\n",
      "Epoch 6, Loss: 0.2903, Accuracy: 0.8037, Test Loss: 0.0895, Test Accuracy: 0.8084\n",
      "Epoch 7, Loss: 0.2721, Accuracy: 0.8049, Test Loss: 0.1067, Test Accuracy: 0.8084\n",
      "Epoch 8, Loss: 0.2541, Accuracy: 0.8102, Test Loss: 0.1160, Test Accuracy: 0.8107\n",
      "Epoch 9, Loss: 0.2352, Accuracy: 0.8236, Test Loss: 0.0772, Test Accuracy: 0.8201\n",
      "Epoch 10, Loss: 0.2240, Accuracy: 0.8207, Test Loss: 0.0784, Test Accuracy: 0.8201\n",
      "Epoch 11, Loss: 0.2091, Accuracy: 0.8283, Test Loss: 0.0747, Test Accuracy: 0.8318\n",
      "Epoch 12, Loss: 0.1932, Accuracy: 0.8329, Test Loss: 0.0829, Test Accuracy: 0.8481\n",
      "Epoch 13, Loss: 0.1801, Accuracy: 0.8440, Test Loss: 0.0792, Test Accuracy: 0.8224\n",
      "Epoch 14, Loss: 0.1769, Accuracy: 0.8364, Test Loss: 0.0805, Test Accuracy: 0.8178\n",
      "Epoch 15, Loss: 0.1750, Accuracy: 0.8364, Test Loss: 0.0852, Test Accuracy: 0.8341\n",
      "Epoch 16, Loss: 0.1643, Accuracy: 0.8359, Test Loss: 0.0669, Test Accuracy: 0.8481\n",
      "Epoch 17, Loss: 0.1569, Accuracy: 0.8423, Test Loss: 0.0777, Test Accuracy: 0.8341\n",
      "Epoch 18, Loss: 0.1504, Accuracy: 0.8411, Test Loss: 0.0637, Test Accuracy: 0.8505\n",
      "Epoch 19, Loss: 0.1505, Accuracy: 0.8353, Test Loss: 0.0704, Test Accuracy: 0.8435\n",
      "Epoch 20, Loss: 0.1542, Accuracy: 0.8312, Test Loss: 0.0816, Test Accuracy: 0.8248\n",
      "Epoch 21, Loss: 0.1460, Accuracy: 0.8388, Test Loss: 0.0741, Test Accuracy: 0.8411\n",
      "Epoch 22, Loss: 0.1378, Accuracy: 0.8470, Test Loss: 0.0728, Test Accuracy: 0.8248\n",
      "Epoch 23, Loss: 0.1355, Accuracy: 0.8400, Test Loss: 0.0750, Test Accuracy: 0.8201\n",
      "Epoch 24, Loss: 0.1355, Accuracy: 0.8382, Test Loss: 0.0750, Test Accuracy: 0.8248\n",
      "Epoch 25, Loss: 0.1325, Accuracy: 0.8411, Test Loss: 0.0605, Test Accuracy: 0.8388\n",
      "Epoch 26, Loss: 0.1359, Accuracy: 0.8364, Test Loss: 0.0783, Test Accuracy: 0.8411\n",
      "Epoch 27, Loss: 0.1346, Accuracy: 0.8318, Test Loss: 0.0993, Test Accuracy: 0.8364\n",
      "Epoch 28, Loss: 0.1324, Accuracy: 0.8382, Test Loss: 0.0708, Test Accuracy: 0.8364\n",
      "Epoch 29, Loss: 0.1286, Accuracy: 0.8394, Test Loss: 0.0688, Test Accuracy: 0.8458\n",
      "Epoch 30, Loss: 0.1233, Accuracy: 0.8394, Test Loss: 0.0694, Test Accuracy: 0.8505\n",
      "Epoch 31, Loss: 0.1196, Accuracy: 0.8382, Test Loss: 0.0679, Test Accuracy: 0.8505\n",
      "Epoch 32, Loss: 0.1130, Accuracy: 0.8429, Test Loss: 0.0695, Test Accuracy: 0.8411\n",
      "Epoch 33, Loss: 0.1147, Accuracy: 0.8400, Test Loss: 0.0573, Test Accuracy: 0.8528\n",
      "Epoch 34, Loss: 0.1128, Accuracy: 0.8429, Test Loss: 0.0594, Test Accuracy: 0.8551\n",
      "Epoch 35, Loss: 0.1097, Accuracy: 0.8481, Test Loss: 0.0814, Test Accuracy: 0.8318\n",
      "Epoch 36, Loss: 0.1062, Accuracy: 0.8446, Test Loss: 0.0578, Test Accuracy: 0.8458\n",
      "Epoch 37, Loss: 0.1044, Accuracy: 0.8429, Test Loss: 0.0690, Test Accuracy: 0.8364\n",
      "Epoch 38, Loss: 0.1067, Accuracy: 0.8446, Test Loss: 0.0633, Test Accuracy: 0.8505\n",
      "Epoch 39, Loss: 0.1073, Accuracy: 0.8405, Test Loss: 0.0629, Test Accuracy: 0.8551\n",
      "Epoch 40, Loss: 0.1057, Accuracy: 0.8440, Test Loss: 0.0590, Test Accuracy: 0.8621\n",
      "Epoch 41, Loss: 0.1021, Accuracy: 0.8417, Test Loss: 0.0909, Test Accuracy: 0.8294\n",
      "Epoch 42, Loss: 0.1031, Accuracy: 0.8470, Test Loss: 0.0708, Test Accuracy: 0.8481\n",
      "Epoch 43, Loss: 0.1042, Accuracy: 0.8458, Test Loss: 0.0610, Test Accuracy: 0.8575\n",
      "Epoch 44, Loss: 0.1046, Accuracy: 0.8446, Test Loss: 0.0718, Test Accuracy: 0.8598\n",
      "Epoch 45, Loss: 0.1026, Accuracy: 0.8452, Test Loss: 0.0788, Test Accuracy: 0.8318\n",
      "Epoch 46, Loss: 0.0985, Accuracy: 0.8493, Test Loss: 0.0696, Test Accuracy: 0.8528\n",
      "Epoch 47, Loss: 0.0997, Accuracy: 0.8446, Test Loss: 0.0611, Test Accuracy: 0.8575\n",
      "Epoch 48, Loss: 0.0971, Accuracy: 0.8446, Test Loss: 0.0674, Test Accuracy: 0.8411\n",
      "Epoch 49, Loss: 0.0959, Accuracy: 0.8435, Test Loss: 0.0740, Test Accuracy: 0.8318\n",
      "Epoch 50, Loss: 0.0996, Accuracy: 0.8370, Test Loss: 0.0674, Test Accuracy: 0.8575\n",
      "Epoch 51, Loss: 0.1004, Accuracy: 0.8423, Test Loss: 0.0662, Test Accuracy: 0.8271\n",
      "Epoch 52, Loss: 0.0971, Accuracy: 0.8452, Test Loss: 0.0569, Test Accuracy: 0.8528\n",
      "Epoch 53, Loss: 0.0933, Accuracy: 0.8464, Test Loss: 0.0603, Test Accuracy: 0.8645\n",
      "Epoch 54, Loss: 0.0923, Accuracy: 0.8528, Test Loss: 0.0692, Test Accuracy: 0.8294\n",
      "Epoch 55, Loss: 0.0937, Accuracy: 0.8452, Test Loss: 0.0612, Test Accuracy: 0.8528\n",
      "Epoch 56, Loss: 0.0912, Accuracy: 0.8470, Test Loss: 0.0650, Test Accuracy: 0.8481\n",
      "Epoch 57, Loss: 0.0913, Accuracy: 0.8429, Test Loss: 0.0637, Test Accuracy: 0.8388\n",
      "Epoch 58, Loss: 0.0905, Accuracy: 0.8481, Test Loss: 0.0593, Test Accuracy: 0.8528\n",
      "Epoch 59, Loss: 0.0914, Accuracy: 0.8435, Test Loss: 0.0595, Test Accuracy: 0.8598\n",
      "Epoch 60, Loss: 0.0921, Accuracy: 0.8458, Test Loss: 0.0663, Test Accuracy: 0.8505\n",
      "Epoch 61, Loss: 0.0913, Accuracy: 0.8522, Test Loss: 0.0613, Test Accuracy: 0.8598\n",
      "Epoch 62, Loss: 0.0887, Accuracy: 0.8464, Test Loss: 0.0592, Test Accuracy: 0.8621\n",
      "Epoch 63, Loss: 0.0903, Accuracy: 0.8452, Test Loss: 0.0689, Test Accuracy: 0.8505\n",
      "Epoch 64, Loss: 0.0878, Accuracy: 0.8481, Test Loss: 0.0576, Test Accuracy: 0.8598\n",
      "Epoch 65, Loss: 0.0916, Accuracy: 0.8435, Test Loss: 0.0711, Test Accuracy: 0.8341\n",
      "Epoch 66, Loss: 0.0887, Accuracy: 0.8493, Test Loss: 0.0585, Test Accuracy: 0.8551\n",
      "Epoch 67, Loss: 0.0864, Accuracy: 0.8475, Test Loss: 0.0625, Test Accuracy: 0.8411\n",
      "Epoch 68, Loss: 0.0858, Accuracy: 0.8458, Test Loss: 0.0570, Test Accuracy: 0.8645\n",
      "Epoch 69, Loss: 0.0852, Accuracy: 0.8493, Test Loss: 0.0714, Test Accuracy: 0.8318\n",
      "Epoch 70, Loss: 0.0854, Accuracy: 0.8481, Test Loss: 0.0683, Test Accuracy: 0.8481\n",
      "Epoch 71, Loss: 0.0855, Accuracy: 0.8522, Test Loss: 0.0705, Test Accuracy: 0.8481\n",
      "Epoch 72, Loss: 0.0868, Accuracy: 0.8493, Test Loss: 0.0655, Test Accuracy: 0.8528\n",
      "Epoch 73, Loss: 0.0832, Accuracy: 0.8557, Test Loss: 0.0680, Test Accuracy: 0.8505\n",
      "Epoch 74, Loss: 0.0883, Accuracy: 0.8481, Test Loss: 0.0595, Test Accuracy: 0.8621\n",
      "Epoch 75, Loss: 0.0840, Accuracy: 0.8505, Test Loss: 0.0586, Test Accuracy: 0.8575\n",
      "Epoch 76, Loss: 0.0823, Accuracy: 0.8516, Test Loss: 0.0667, Test Accuracy: 0.8458\n",
      "Epoch 77, Loss: 0.0826, Accuracy: 0.8528, Test Loss: 0.0620, Test Accuracy: 0.8458\n",
      "Epoch 78, Loss: 0.0836, Accuracy: 0.8505, Test Loss: 0.0642, Test Accuracy: 0.8388\n",
      "Epoch 79, Loss: 0.0850, Accuracy: 0.8470, Test Loss: 0.0591, Test Accuracy: 0.8645\n",
      "Epoch 80, Loss: 0.0868, Accuracy: 0.8458, Test Loss: 0.0642, Test Accuracy: 0.8505\n",
      "Epoch 81, Loss: 0.0865, Accuracy: 0.8446, Test Loss: 0.0698, Test Accuracy: 0.8388\n",
      "Epoch 82, Loss: 0.0869, Accuracy: 0.8440, Test Loss: 0.0647, Test Accuracy: 0.8481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:26:25,092] Trial 125 finished with value: 0.8644859813084113 and parameters: {'batch_size': 64, 'num_gcn_layers': 2, 'gcn_hidden_dim_0': 57, 'gcn_hidden_dim_1': 50, 'num_fc_layers': 2, 'fc_hidden_dim_0': 192, 'fc_hidden_dim_1': 250, 'learning_rate': 2.9246820750796242e-05, 'weight_decay': 2.0650653205791303e-06, 'pooling_method': 'max', 'gcn_batch_norm_flag_0': True, 'gcn_batch_norm_flag_1': True, 'gcn_momentum_0': 0.9601169528455782, 'gcn_momentum_1': 0.12193278434840271, 'gcn_eps_0': 0.006057386006423537, 'gcn_eps_1': 0.001026622615236259, 'gcn_dropout_flag_0': False, 'gcn_dropout_flag_1': False, 'gcn_activation_0': 'elu', 'gcn_activation_1': 'relu', 'fc_batch_norm_flag_0': False, 'fc_batch_norm_flag_1': True, 'fc_momentum_1': 0.38793440434419235, 'fc_eps_1': 0.0003680350440416195, 'fc_dropout_flag_0': False, 'fc_dropout_flag_1': True, 'fc_dropout_rate_1': 0.24288853662844917, 'fc_activation_0': 'relu', 'fc_activation_1': 'tanh', 'gcn_skip_connections_0': False, 'gcn_skip_connections_1': True, 'l1_lambda': 0.0001089091770424241, 'optimizer': 'Adam', 'beta1': 0.9220420891356867, 'beta2': 0.996259376919809, 'lr_scheduler': 'OneCycleLR', 'max_lr_1': 0.09989228364715458, 'pct_start': 0.47969083020559566, 'loss_function': 'MultiMargin'}. Best is trial 33 with value: 0.8714953271028038.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83, Loss: 0.0834, Accuracy: 0.8516, Test Loss: 0.0551, Test Accuracy: 0.8621\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:26:26,688] Trial 126 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.9981, Accuracy: 0.6577, Test Loss: 0.7936, Test Accuracy: 0.7547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:26:28,115] Trial 127 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.7405, Accuracy: 0.7290, Test Loss: 0.1626, Test Accuracy: 0.7477\n",
      "Epoch 1, Loss: 1.5625, Accuracy: 0.6840, Test Loss: 0.1325, Test Accuracy: 0.7897\n",
      "Epoch 2, Loss: 1.1585, Accuracy: 0.7798, Test Loss: 0.1121, Test Accuracy: 0.8084\n",
      "Epoch 3, Loss: 0.8936, Accuracy: 0.7944, Test Loss: 0.1135, Test Accuracy: 0.8084\n",
      "Epoch 4, Loss: 0.7038, Accuracy: 0.8032, Test Loss: 0.1710, Test Accuracy: 0.7266\n",
      "Epoch 5, Loss: 0.5660, Accuracy: 0.8143, Test Loss: 0.1786, Test Accuracy: 0.6963\n",
      "Epoch 6, Loss: 0.4836, Accuracy: 0.8026, Test Loss: 0.1120, Test Accuracy: 0.7921\n",
      "Epoch 7, Loss: 0.4059, Accuracy: 0.8172, Test Loss: 0.0870, Test Accuracy: 0.8014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:26:43,219] Trial 128 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 0.3611, Accuracy: 0.8172, Test Loss: 0.1230, Test Accuracy: 0.7944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:26:45,618] Trial 129 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 4.9739, Accuracy: 0.4264, Test Loss: 1.0845, Test Accuracy: 0.6402\n",
      "Epoch 1, Loss: 0.8148, Accuracy: 0.7371, Test Loss: 0.1061, Test Accuracy: 0.8014\n",
      "Epoch 2, Loss: 0.6291, Accuracy: 0.8032, Test Loss: 0.0939, Test Accuracy: 0.8131\n",
      "Epoch 3, Loss: 0.5184, Accuracy: 0.8037, Test Loss: 0.0972, Test Accuracy: 0.8107\n",
      "Epoch 4, Loss: 0.4280, Accuracy: 0.8026, Test Loss: 0.1007, Test Accuracy: 0.8014\n",
      "Epoch 5, Loss: 0.3603, Accuracy: 0.8078, Test Loss: 0.0770, Test Accuracy: 0.8201\n",
      "Epoch 6, Loss: 0.3023, Accuracy: 0.8300, Test Loss: 0.0999, Test Accuracy: 0.8061\n",
      "Epoch 7, Loss: 0.2693, Accuracy: 0.8183, Test Loss: 0.0825, Test Accuracy: 0.8294\n",
      "Epoch 8, Loss: 0.2403, Accuracy: 0.8329, Test Loss: 0.0712, Test Accuracy: 0.8388\n",
      "Epoch 9, Loss: 0.2208, Accuracy: 0.8382, Test Loss: 0.0810, Test Accuracy: 0.8178\n",
      "Epoch 10, Loss: 0.2032, Accuracy: 0.8411, Test Loss: 0.0646, Test Accuracy: 0.8435\n",
      "Epoch 11, Loss: 0.1899, Accuracy: 0.8411, Test Loss: 0.0757, Test Accuracy: 0.8294\n",
      "Epoch 12, Loss: 0.1785, Accuracy: 0.8394, Test Loss: 0.0691, Test Accuracy: 0.8318\n",
      "Epoch 13, Loss: 0.1700, Accuracy: 0.8405, Test Loss: 0.0617, Test Accuracy: 0.8435\n",
      "Epoch 14, Loss: 0.1644, Accuracy: 0.8394, Test Loss: 0.0908, Test Accuracy: 0.7921\n",
      "Epoch 15, Loss: 0.1587, Accuracy: 0.8347, Test Loss: 0.0601, Test Accuracy: 0.8481\n",
      "Epoch 16, Loss: 0.1526, Accuracy: 0.8376, Test Loss: 0.0673, Test Accuracy: 0.8481\n",
      "Epoch 17, Loss: 0.1454, Accuracy: 0.8411, Test Loss: 0.0614, Test Accuracy: 0.8458\n",
      "Epoch 18, Loss: 0.1372, Accuracy: 0.8435, Test Loss: 0.0630, Test Accuracy: 0.8341\n",
      "Epoch 19, Loss: 0.1335, Accuracy: 0.8376, Test Loss: 0.0610, Test Accuracy: 0.8505\n",
      "Epoch 20, Loss: 0.1283, Accuracy: 0.8481, Test Loss: 0.0609, Test Accuracy: 0.8411\n",
      "Epoch 21, Loss: 0.1239, Accuracy: 0.8440, Test Loss: 0.0606, Test Accuracy: 0.8458\n",
      "Epoch 22, Loss: 0.1242, Accuracy: 0.8411, Test Loss: 0.0638, Test Accuracy: 0.8551\n",
      "Epoch 23, Loss: 0.1242, Accuracy: 0.8388, Test Loss: 0.0684, Test Accuracy: 0.8364\n",
      "Epoch 24, Loss: 0.1221, Accuracy: 0.8423, Test Loss: 0.0639, Test Accuracy: 0.8481\n",
      "Epoch 25, Loss: 0.1171, Accuracy: 0.8464, Test Loss: 0.0619, Test Accuracy: 0.8271\n",
      "Epoch 26, Loss: 0.1163, Accuracy: 0.8417, Test Loss: 0.0609, Test Accuracy: 0.8481\n",
      "Epoch 27, Loss: 0.1103, Accuracy: 0.8487, Test Loss: 0.0634, Test Accuracy: 0.8458\n",
      "Epoch 28, Loss: 0.1094, Accuracy: 0.8458, Test Loss: 0.0634, Test Accuracy: 0.8575\n",
      "Epoch 29, Loss: 0.1112, Accuracy: 0.8487, Test Loss: 0.0783, Test Accuracy: 0.8388\n",
      "Epoch 30, Loss: 0.1123, Accuracy: 0.8429, Test Loss: 0.0617, Test Accuracy: 0.8435\n",
      "Epoch 31, Loss: 0.1096, Accuracy: 0.8400, Test Loss: 0.0567, Test Accuracy: 0.8575\n",
      "Epoch 32, Loss: 0.1052, Accuracy: 0.8493, Test Loss: 0.0608, Test Accuracy: 0.8481\n",
      "Epoch 33, Loss: 0.1071, Accuracy: 0.8470, Test Loss: 0.0641, Test Accuracy: 0.8388\n",
      "Epoch 34, Loss: 0.1037, Accuracy: 0.8458, Test Loss: 0.0572, Test Accuracy: 0.8528\n",
      "Epoch 35, Loss: 0.1024, Accuracy: 0.8440, Test Loss: 0.0589, Test Accuracy: 0.8481\n",
      "Epoch 36, Loss: 0.1005, Accuracy: 0.8458, Test Loss: 0.0621, Test Accuracy: 0.8435\n",
      "Epoch 37, Loss: 0.1001, Accuracy: 0.8470, Test Loss: 0.0549, Test Accuracy: 0.8481\n",
      "Epoch 38, Loss: 0.0986, Accuracy: 0.8511, Test Loss: 0.0562, Test Accuracy: 0.8551\n",
      "Epoch 39, Loss: 0.0959, Accuracy: 0.8511, Test Loss: 0.0622, Test Accuracy: 0.8505\n",
      "Epoch 40, Loss: 0.0989, Accuracy: 0.8481, Test Loss: 0.0708, Test Accuracy: 0.8528\n",
      "Epoch 41, Loss: 0.1001, Accuracy: 0.8440, Test Loss: 0.0606, Test Accuracy: 0.8621\n",
      "Epoch 42, Loss: 0.0983, Accuracy: 0.8499, Test Loss: 0.0632, Test Accuracy: 0.8435\n",
      "Epoch 43, Loss: 0.0966, Accuracy: 0.8522, Test Loss: 0.0740, Test Accuracy: 0.8364\n",
      "Epoch 44, Loss: 0.0990, Accuracy: 0.8446, Test Loss: 0.0664, Test Accuracy: 0.8341\n",
      "Epoch 45, Loss: 0.0973, Accuracy: 0.8499, Test Loss: 0.0546, Test Accuracy: 0.8598\n",
      "Epoch 46, Loss: 0.0971, Accuracy: 0.8458, Test Loss: 0.0663, Test Accuracy: 0.8388\n",
      "Epoch 47, Loss: 0.0961, Accuracy: 0.8499, Test Loss: 0.0562, Test Accuracy: 0.8551\n",
      "Epoch 48, Loss: 0.0958, Accuracy: 0.8475, Test Loss: 0.0675, Test Accuracy: 0.8364\n",
      "Epoch 49, Loss: 0.0961, Accuracy: 0.8505, Test Loss: 0.0566, Test Accuracy: 0.8551\n",
      "Epoch 50, Loss: 0.0931, Accuracy: 0.8493, Test Loss: 0.0523, Test Accuracy: 0.8598\n",
      "Epoch 51, Loss: 0.0929, Accuracy: 0.8505, Test Loss: 0.0576, Test Accuracy: 0.8551\n",
      "Epoch 52, Loss: 0.0950, Accuracy: 0.8446, Test Loss: 0.0582, Test Accuracy: 0.8505\n",
      "Epoch 53, Loss: 0.0957, Accuracy: 0.8452, Test Loss: 0.0600, Test Accuracy: 0.8435\n",
      "Epoch 54, Loss: 0.0939, Accuracy: 0.8470, Test Loss: 0.0701, Test Accuracy: 0.8341\n",
      "Epoch 55, Loss: 0.0930, Accuracy: 0.8528, Test Loss: 0.0603, Test Accuracy: 0.8505\n",
      "Epoch 56, Loss: 0.0938, Accuracy: 0.8458, Test Loss: 0.0586, Test Accuracy: 0.8481\n",
      "Epoch 57, Loss: 0.0948, Accuracy: 0.8452, Test Loss: 0.0603, Test Accuracy: 0.8458\n",
      "Epoch 58, Loss: 0.0959, Accuracy: 0.8435, Test Loss: 0.0726, Test Accuracy: 0.8575\n",
      "Epoch 59, Loss: 0.0955, Accuracy: 0.8446, Test Loss: 0.0572, Test Accuracy: 0.8458\n",
      "Epoch 60, Loss: 0.0929, Accuracy: 0.8493, Test Loss: 0.0679, Test Accuracy: 0.8364\n",
      "Epoch 61, Loss: 0.0917, Accuracy: 0.8475, Test Loss: 0.0558, Test Accuracy: 0.8551\n",
      "Epoch 62, Loss: 0.0890, Accuracy: 0.8493, Test Loss: 0.0559, Test Accuracy: 0.8528\n",
      "Epoch 63, Loss: 0.0900, Accuracy: 0.8481, Test Loss: 0.0534, Test Accuracy: 0.8598\n",
      "Epoch 64, Loss: 0.0914, Accuracy: 0.8493, Test Loss: 0.0567, Test Accuracy: 0.8598\n",
      "Epoch 65, Loss: 0.0906, Accuracy: 0.8534, Test Loss: 0.0557, Test Accuracy: 0.8551\n",
      "Epoch 66, Loss: 0.0891, Accuracy: 0.8546, Test Loss: 0.0563, Test Accuracy: 0.8505\n",
      "Epoch 67, Loss: 0.0904, Accuracy: 0.8487, Test Loss: 0.1251, Test Accuracy: 0.8084\n",
      "Epoch 68, Loss: 0.0900, Accuracy: 0.8470, Test Loss: 0.0573, Test Accuracy: 0.8551\n",
      "Epoch 69, Loss: 0.0888, Accuracy: 0.8528, Test Loss: 0.0631, Test Accuracy: 0.8318\n",
      "Epoch 70, Loss: 0.0901, Accuracy: 0.8487, Test Loss: 0.1052, Test Accuracy: 0.7897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:28:07,460] Trial 130 finished with value: 0.8621495327102804 and parameters: {'batch_size': 64, 'num_gcn_layers': 2, 'gcn_hidden_dim_0': 63, 'gcn_hidden_dim_1': 38, 'num_fc_layers': 2, 'fc_hidden_dim_0': 213, 'fc_hidden_dim_1': 227, 'learning_rate': 0.00012088307663746538, 'weight_decay': 2.2467303918309146e-05, 'pooling_method': 'max', 'gcn_batch_norm_flag_0': True, 'gcn_batch_norm_flag_1': True, 'gcn_momentum_0': 0.7900736910465938, 'gcn_momentum_1': 0.3565511315031841, 'gcn_eps_0': 0.007752425640110257, 'gcn_eps_1': 0.0018482694142049048, 'gcn_dropout_flag_0': False, 'gcn_dropout_flag_1': False, 'gcn_activation_0': 'softplus', 'gcn_activation_1': 'gelu', 'fc_batch_norm_flag_0': False, 'fc_batch_norm_flag_1': True, 'fc_momentum_1': 0.4188414279603521, 'fc_eps_1': 0.0018817424310250627, 'fc_dropout_flag_0': False, 'fc_dropout_flag_1': True, 'fc_dropout_rate_1': 0.18610677277461485, 'fc_activation_0': 'relu', 'fc_activation_1': 'gelu', 'gcn_skip_connections_0': False, 'gcn_skip_connections_1': True, 'l1_lambda': 0.000215218588053983, 'optimizer': 'Adam', 'beta1': 0.8808779748676225, 'beta2': 0.9785847976246513, 'lr_scheduler': 'OneCycleLR', 'max_lr_1': 0.0956100275546873, 'pct_start': 0.27991173768776373, 'loss_function': 'MultiMargin'}. Best is trial 33 with value: 0.8714953271028038.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71, Loss: 0.0892, Accuracy: 0.8511, Test Loss: 0.0604, Test Accuracy: 0.8411\n",
      "Early stopping triggered\n",
      "Epoch 1, Loss: 0.8470, Accuracy: 0.7196, Test Loss: 0.1090, Test Accuracy: 0.7850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:28:11,769] Trial 131 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.5473, Accuracy: 0.7880, Test Loss: 0.1724, Test Accuracy: 0.7056\n",
      "Epoch 1, Loss: 0.6689, Accuracy: 0.7155, Test Loss: 0.1103, Test Accuracy: 0.7780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:28:15,652] Trial 132 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.4853, Accuracy: 0.7921, Test Loss: 0.0942, Test Accuracy: 0.7991\n",
      "Epoch 1, Loss: 1.5571, Accuracy: 0.7389, Test Loss: 0.0973, Test Accuracy: 0.7991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:28:20,284] Trial 133 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 1.1433, Accuracy: 0.7967, Test Loss: 0.1063, Test Accuracy: 0.7827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:28:21,092] Trial 134 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.5392, Accuracy: 0.5520, Test Loss: 0.1705, Test Accuracy: 0.6893\n",
      "Epoch 1, Loss: 0.7298, Accuracy: 0.7529, Test Loss: 0.1019, Test Accuracy: 0.8037\n",
      "Epoch 2, Loss: 0.5768, Accuracy: 0.7821, Test Loss: 0.0993, Test Accuracy: 0.7921\n",
      "Epoch 3, Loss: 0.4417, Accuracy: 0.7985, Test Loss: 0.0916, Test Accuracy: 0.8061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:28:29,315] Trial 135 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.3388, Accuracy: 0.8008, Test Loss: 0.1067, Test Accuracy: 0.7991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:28:31,260] Trial 136 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.0291, Accuracy: 0.6945, Test Loss: 0.4358, Test Accuracy: 0.2593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:28:33,530] Trial 137 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.6464, Accuracy: 0.6630, Test Loss: 0.7603, Test Accuracy: 0.7407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:28:37,738] Trial 138 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.2257, Accuracy: 0.6671, Test Loss: 0.1354, Test Accuracy: 0.7383\n",
      "Epoch 1, Loss: 1.9471, Accuracy: 0.7278, Test Loss: 0.5590, Test Accuracy: 0.7944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:28:40,583] Trial 139 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 1.6540, Accuracy: 0.7891, Test Loss: 0.7012, Test Accuracy: 0.7336\n",
      "Epoch 1, Loss: 0.5576, Accuracy: 0.6887, Test Loss: 0.1054, Test Accuracy: 0.7944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:28:44,149] Trial 140 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.4095, Accuracy: 0.7938, Test Loss: 0.1016, Test Accuracy: 0.7967\n",
      "Epoch 1, Loss: 0.9398, Accuracy: 0.7272, Test Loss: 0.1163, Test Accuracy: 0.7921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:28:48,540] Trial 141 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.7082, Accuracy: 0.7932, Test Loss: 0.1204, Test Accuracy: 0.7687\n",
      "Epoch 1, Loss: 0.9776, Accuracy: 0.7056, Test Loss: 0.1236, Test Accuracy: 0.7874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:28:53,181] Trial 142 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.7731, Accuracy: 0.7845, Test Loss: 0.1094, Test Accuracy: 0.7897\n",
      "Epoch 1, Loss: 0.7339, Accuracy: 0.7155, Test Loss: 0.1068, Test Accuracy: 0.7827\n",
      "Epoch 2, Loss: 0.5751, Accuracy: 0.7961, Test Loss: 0.0988, Test Accuracy: 0.8061\n",
      "Epoch 3, Loss: 0.4841, Accuracy: 0.7991, Test Loss: 0.1052, Test Accuracy: 0.8014\n",
      "Epoch 4, Loss: 0.4067, Accuracy: 0.8032, Test Loss: 0.0920, Test Accuracy: 0.8084\n",
      "Epoch 5, Loss: 0.3455, Accuracy: 0.8078, Test Loss: 0.0912, Test Accuracy: 0.7991\n",
      "Epoch 6, Loss: 0.2914, Accuracy: 0.8049, Test Loss: 0.0967, Test Accuracy: 0.7991\n",
      "Epoch 7, Loss: 0.2513, Accuracy: 0.8107, Test Loss: 0.0906, Test Accuracy: 0.8154\n",
      "Epoch 8, Loss: 0.2279, Accuracy: 0.8037, Test Loss: 0.0815, Test Accuracy: 0.8224\n",
      "Epoch 9, Loss: 0.2004, Accuracy: 0.8201, Test Loss: 0.1037, Test Accuracy: 0.7640\n",
      "Epoch 10, Loss: 0.1912, Accuracy: 0.8172, Test Loss: 0.0818, Test Accuracy: 0.8178\n",
      "Epoch 11, Loss: 0.1753, Accuracy: 0.8242, Test Loss: 0.0711, Test Accuracy: 0.8294\n",
      "Epoch 12, Loss: 0.1548, Accuracy: 0.8388, Test Loss: 0.0677, Test Accuracy: 0.8318\n",
      "Epoch 13, Loss: 0.1465, Accuracy: 0.8388, Test Loss: 0.0724, Test Accuracy: 0.8388\n",
      "Epoch 14, Loss: 0.1395, Accuracy: 0.8329, Test Loss: 0.0650, Test Accuracy: 0.8411\n",
      "Epoch 15, Loss: 0.1332, Accuracy: 0.8417, Test Loss: 0.0654, Test Accuracy: 0.8411\n",
      "Epoch 16, Loss: 0.1270, Accuracy: 0.8405, Test Loss: 0.0622, Test Accuracy: 0.8458\n",
      "Epoch 17, Loss: 0.1197, Accuracy: 0.8423, Test Loss: 0.0612, Test Accuracy: 0.8458\n",
      "Epoch 18, Loss: 0.1187, Accuracy: 0.8405, Test Loss: 0.0613, Test Accuracy: 0.8481\n",
      "Epoch 19, Loss: 0.1105, Accuracy: 0.8481, Test Loss: 0.0686, Test Accuracy: 0.8388\n",
      "Epoch 20, Loss: 0.1130, Accuracy: 0.8435, Test Loss: 0.0608, Test Accuracy: 0.8528\n",
      "Epoch 21, Loss: 0.1101, Accuracy: 0.8440, Test Loss: 0.0683, Test Accuracy: 0.8294\n",
      "Epoch 22, Loss: 0.1096, Accuracy: 0.8394, Test Loss: 0.0598, Test Accuracy: 0.8481\n",
      "Epoch 23, Loss: 0.1032, Accuracy: 0.8464, Test Loss: 0.0660, Test Accuracy: 0.8388\n",
      "Epoch 24, Loss: 0.1027, Accuracy: 0.8405, Test Loss: 0.0584, Test Accuracy: 0.8551\n",
      "Epoch 25, Loss: 0.1014, Accuracy: 0.8458, Test Loss: 0.0582, Test Accuracy: 0.8551\n",
      "Epoch 26, Loss: 0.1009, Accuracy: 0.8411, Test Loss: 0.0650, Test Accuracy: 0.8481\n",
      "Epoch 27, Loss: 0.0959, Accuracy: 0.8452, Test Loss: 0.0643, Test Accuracy: 0.8388\n",
      "Epoch 28, Loss: 0.0957, Accuracy: 0.8458, Test Loss: 0.0555, Test Accuracy: 0.8528\n",
      "Epoch 29, Loss: 0.0937, Accuracy: 0.8487, Test Loss: 0.0569, Test Accuracy: 0.8551\n",
      "Epoch 30, Loss: 0.0954, Accuracy: 0.8429, Test Loss: 0.0598, Test Accuracy: 0.8505\n",
      "Epoch 31, Loss: 0.0903, Accuracy: 0.8540, Test Loss: 0.0546, Test Accuracy: 0.8598\n",
      "Epoch 32, Loss: 0.0904, Accuracy: 0.8452, Test Loss: 0.0570, Test Accuracy: 0.8598\n",
      "Epoch 33, Loss: 0.0859, Accuracy: 0.8534, Test Loss: 0.0549, Test Accuracy: 0.8621\n",
      "Epoch 34, Loss: 0.0913, Accuracy: 0.8499, Test Loss: 0.0629, Test Accuracy: 0.8435\n",
      "Epoch 35, Loss: 0.0855, Accuracy: 0.8499, Test Loss: 0.0603, Test Accuracy: 0.8458\n",
      "Epoch 36, Loss: 0.0853, Accuracy: 0.8493, Test Loss: 0.0575, Test Accuracy: 0.8551\n",
      "Epoch 37, Loss: 0.0866, Accuracy: 0.8493, Test Loss: 0.0590, Test Accuracy: 0.8458\n",
      "Epoch 38, Loss: 0.0873, Accuracy: 0.8475, Test Loss: 0.0603, Test Accuracy: 0.8435\n",
      "Epoch 39, Loss: 0.0846, Accuracy: 0.8493, Test Loss: 0.0562, Test Accuracy: 0.8598\n",
      "Epoch 40, Loss: 0.0842, Accuracy: 0.8481, Test Loss: 0.0564, Test Accuracy: 0.8598\n",
      "Epoch 41, Loss: 0.0832, Accuracy: 0.8511, Test Loss: 0.0573, Test Accuracy: 0.8505\n",
      "Epoch 42, Loss: 0.0844, Accuracy: 0.8464, Test Loss: 0.0593, Test Accuracy: 0.8458\n",
      "Epoch 43, Loss: 0.0822, Accuracy: 0.8511, Test Loss: 0.0564, Test Accuracy: 0.8575\n",
      "Epoch 44, Loss: 0.0794, Accuracy: 0.8540, Test Loss: 0.0578, Test Accuracy: 0.8528\n",
      "Epoch 45, Loss: 0.0800, Accuracy: 0.8534, Test Loss: 0.0595, Test Accuracy: 0.8528\n",
      "Epoch 46, Loss: 0.0817, Accuracy: 0.8511, Test Loss: 0.0559, Test Accuracy: 0.8528\n",
      "Epoch 47, Loss: 0.0797, Accuracy: 0.8540, Test Loss: 0.0564, Test Accuracy: 0.8528\n",
      "Epoch 48, Loss: 0.0789, Accuracy: 0.8551, Test Loss: 0.0558, Test Accuracy: 0.8598\n",
      "Epoch 49, Loss: 0.0798, Accuracy: 0.8540, Test Loss: 0.0614, Test Accuracy: 0.8481\n",
      "Epoch 50, Loss: 0.0789, Accuracy: 0.8499, Test Loss: 0.0523, Test Accuracy: 0.8598\n",
      "Epoch 51, Loss: 0.0798, Accuracy: 0.8546, Test Loss: 0.0591, Test Accuracy: 0.8481\n",
      "Epoch 52, Loss: 0.0800, Accuracy: 0.8458, Test Loss: 0.0590, Test Accuracy: 0.8551\n",
      "Epoch 53, Loss: 0.0789, Accuracy: 0.8499, Test Loss: 0.0534, Test Accuracy: 0.8551\n",
      "Epoch 54, Loss: 0.0772, Accuracy: 0.8528, Test Loss: 0.0547, Test Accuracy: 0.8551\n",
      "Epoch 55, Loss: 0.0773, Accuracy: 0.8511, Test Loss: 0.0551, Test Accuracy: 0.8575\n",
      "Epoch 56, Loss: 0.0787, Accuracy: 0.8475, Test Loss: 0.0684, Test Accuracy: 0.8411\n",
      "Epoch 57, Loss: 0.0762, Accuracy: 0.8528, Test Loss: 0.0578, Test Accuracy: 0.8528\n",
      "Epoch 58, Loss: 0.0751, Accuracy: 0.8546, Test Loss: 0.0547, Test Accuracy: 0.8621\n",
      "Epoch 59, Loss: 0.0771, Accuracy: 0.8505, Test Loss: 0.0556, Test Accuracy: 0.8528\n",
      "Epoch 60, Loss: 0.0745, Accuracy: 0.8540, Test Loss: 0.0538, Test Accuracy: 0.8621\n",
      "Epoch 61, Loss: 0.0770, Accuracy: 0.8470, Test Loss: 0.0579, Test Accuracy: 0.8551\n",
      "Epoch 62, Loss: 0.0745, Accuracy: 0.8575, Test Loss: 0.0577, Test Accuracy: 0.8551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:31:10,178] Trial 143 finished with value: 0.8621495327102804 and parameters: {'batch_size': 32, 'num_gcn_layers': 2, 'gcn_hidden_dim_0': 122, 'gcn_hidden_dim_1': 201, 'num_fc_layers': 2, 'fc_hidden_dim_0': 202, 'fc_hidden_dim_1': 67, 'learning_rate': 0.0029312909969911737, 'weight_decay': 6.380264153798182e-05, 'pooling_method': 'max', 'gcn_batch_norm_flag_0': False, 'gcn_batch_norm_flag_1': True, 'gcn_momentum_1': 0.914868972560866, 'gcn_eps_1': 0.009018181820707016, 'gcn_dropout_flag_0': False, 'gcn_dropout_flag_1': False, 'gcn_activation_0': 'leaky_relu', 'gcn_activation_1': 'relu', 'fc_batch_norm_flag_0': False, 'fc_batch_norm_flag_1': True, 'fc_momentum_1': 0.4748589778066091, 'fc_eps_1': 0.0022522984177337623, 'fc_dropout_flag_0': False, 'fc_dropout_flag_1': True, 'fc_dropout_rate_1': 0.157123542485787, 'fc_activation_0': 'elu', 'fc_activation_1': 'leaky_relu', 'gcn_skip_connections_0': False, 'gcn_skip_connections_1': True, 'l1_lambda': 0.00010512918945146141, 'optimizer': 'Adam', 'beta1': 0.8513415539809727, 'beta2': 0.9989314085145246, 'lr_scheduler': 'OneCycleLR', 'max_lr_1': 0.040566792880456407, 'pct_start': 0.13102638943050773, 'loss_function': 'MultiMargin'}. Best is trial 33 with value: 0.8714953271028038.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63, Loss: 0.0731, Accuracy: 0.8557, Test Loss: 0.0576, Test Accuracy: 0.8528\n",
      "Early stopping triggered\n",
      "Epoch 1, Loss: 1.1220, Accuracy: 0.7290, Test Loss: 0.1227, Test Accuracy: 0.7850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:31:16,052] Trial 144 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.7392, Accuracy: 0.7921, Test Loss: 0.0967, Test Accuracy: 0.7967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:31:17,642] Trial 145 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6093, Accuracy: 0.6273, Test Loss: 0.1961, Test Accuracy: 0.6963\n",
      "Epoch 1, Loss: 1.2603, Accuracy: 0.7313, Test Loss: 0.1046, Test Accuracy: 0.7921\n",
      "Epoch 2, Loss: 0.6932, Accuracy: 0.7909, Test Loss: 0.1015, Test Accuracy: 0.8061\n",
      "Epoch 3, Loss: 0.3861, Accuracy: 0.7985, Test Loss: 0.0983, Test Accuracy: 0.8084\n",
      "Epoch 4, Loss: 0.2715, Accuracy: 0.8002, Test Loss: 0.0915, Test Accuracy: 0.7967\n",
      "Epoch 5, Loss: 0.2099, Accuracy: 0.8026, Test Loss: 0.0919, Test Accuracy: 0.8084\n",
      "Epoch 6, Loss: 0.1798, Accuracy: 0.8055, Test Loss: 0.0917, Test Accuracy: 0.8084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:31:31,791] Trial 146 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 0.1646, Accuracy: 0.7979, Test Loss: 0.0898, Test Accuracy: 0.8061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:31:32,910] Trial 147 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 4.9882, Accuracy: 0.4124, Test Loss: 0.4495, Test Accuracy: 0.6051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:31:35,063] Trial 148 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.5410, Accuracy: 0.7284, Test Loss: 0.7466, Test Accuracy: 0.4673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:31:36,683] Trial 149 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.5705, Accuracy: 0.6688, Test Loss: 0.1447, Test Accuracy: 0.7360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:31:38,983] Trial 150 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.9871, Accuracy: 0.7336, Test Loss: 0.1132, Test Accuracy: 0.7734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:31:40,876] Trial 151 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.8173, Accuracy: 0.6898, Test Loss: 0.1239, Test Accuracy: 0.7547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:31:43,096] Trial 152 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.8962, Accuracy: 0.7056, Test Loss: 0.1266, Test Accuracy: 0.7407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:31:45,238] Trial 153 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.8604, Accuracy: 0.7185, Test Loss: 0.1101, Test Accuracy: 0.7710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:31:47,386] Trial 154 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.0967, Accuracy: 0.7383, Test Loss: 0.1054, Test Accuracy: 0.7734\n",
      "Epoch 1, Loss: 0.4246, Accuracy: 0.7366, Test Loss: 0.1125, Test Accuracy: 0.7757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:31:50,985] Trial 155 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.3231, Accuracy: 0.7839, Test Loss: 0.1015, Test Accuracy: 0.7921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:31:53,477] Trial 156 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 3.0906, Accuracy: 0.6980, Test Loss: 0.6355, Test Accuracy: 0.7056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:31:55,728] Trial 157 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.8345, Accuracy: 0.5029, Test Loss: 0.3309, Test Accuracy: 0.6028\n",
      "Epoch 1, Loss: 0.8549, Accuracy: 0.7144, Test Loss: 0.1339, Test Accuracy: 0.7874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:32:00,144] Trial 158 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.6892, Accuracy: 0.7891, Test Loss: 0.1239, Test Accuracy: 0.7991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:32:00,980] Trial 159 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.6962, Accuracy: 0.5298, Test Loss: 0.8192, Test Accuracy: 0.6986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:32:02,563] Trial 160 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.6022, Accuracy: 0.4258, Test Loss: 0.3607, Test Accuracy: 0.6729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:32:05,089] Trial 161 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.8532, Accuracy: 0.6951, Test Loss: 0.1364, Test Accuracy: 0.7664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:32:07,639] Trial 162 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.8408, Accuracy: 0.7255, Test Loss: 0.1224, Test Accuracy: 0.7734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:32:09,808] Trial 163 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.0076, Accuracy: 0.6881, Test Loss: 0.1216, Test Accuracy: 0.7687\n",
      "Epoch 1, Loss: 0.9647, Accuracy: 0.7453, Test Loss: 0.1051, Test Accuracy: 0.8061\n",
      "Epoch 2, Loss: 0.4701, Accuracy: 0.7961, Test Loss: 0.1061, Test Accuracy: 0.8061\n",
      "Epoch 3, Loss: 0.2927, Accuracy: 0.7950, Test Loss: 0.1231, Test Accuracy: 0.8131\n",
      "Epoch 4, Loss: 0.2159, Accuracy: 0.8026, Test Loss: 0.0912, Test Accuracy: 0.8084\n",
      "Epoch 5, Loss: 0.1822, Accuracy: 0.8014, Test Loss: 0.0873, Test Accuracy: 0.8084\n",
      "Epoch 6, Loss: 0.1563, Accuracy: 0.8072, Test Loss: 0.0941, Test Accuracy: 0.8107\n",
      "Epoch 7, Loss: 0.1452, Accuracy: 0.8055, Test Loss: 0.0918, Test Accuracy: 0.8154\n",
      "Epoch 8, Loss: 0.1369, Accuracy: 0.8119, Test Loss: 0.0992, Test Accuracy: 0.8061\n",
      "Epoch 9, Loss: 0.1335, Accuracy: 0.8102, Test Loss: 0.0886, Test Accuracy: 0.8084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:32:33,765] Trial 164 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 0.1292, Accuracy: 0.8096, Test Loss: 0.0854, Test Accuracy: 0.8107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:32:35,884] Trial 165 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.8712, Accuracy: 0.6548, Test Loss: 0.1656, Test Accuracy: 0.7734\n",
      "Epoch 1, Loss: 5.4964, Accuracy: 0.6822, Test Loss: 0.1182, Test Accuracy: 0.7921\n",
      "Epoch 2, Loss: 3.0690, Accuracy: 0.7815, Test Loss: 0.1019, Test Accuracy: 0.8014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:32:48,608] Trial 166 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 1.5372, Accuracy: 0.7862, Test Loss: 0.1178, Test Accuracy: 0.7897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:32:50,221] Trial 167 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.1084, Accuracy: 0.6361, Test Loss: 6.6554, Test Accuracy: 0.2150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:32:52,666] Trial 168 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.8991, Accuracy: 0.7144, Test Loss: 0.1598, Test Accuracy: 0.7523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:32:55,096] Trial 169 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.3883, Accuracy: 0.6151, Test Loss: 0.1653, Test Accuracy: 0.6846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:32:56,915] Trial 170 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6227, Accuracy: 0.6466, Test Loss: 0.2199, Test Accuracy: 0.7173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:32:58,344] Trial 171 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.5609, Accuracy: 0.7033, Test Loss: 0.1564, Test Accuracy: 0.7640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:32:59,644] Trial 172 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.3673, Accuracy: 0.6974, Test Loss: 0.1450, Test Accuracy: 0.7640\n",
      "Epoch 1, Loss: 0.4639, Accuracy: 0.7120, Test Loss: 0.1188, Test Accuracy: 0.7874\n",
      "Epoch 2, Loss: 0.3516, Accuracy: 0.7950, Test Loss: 0.1052, Test Accuracy: 0.8107\n",
      "Epoch 3, Loss: 0.3218, Accuracy: 0.8049, Test Loss: 0.1047, Test Accuracy: 0.7874\n",
      "Epoch 4, Loss: 0.2882, Accuracy: 0.8037, Test Loss: 0.1018, Test Accuracy: 0.8107\n",
      "Epoch 5, Loss: 0.2610, Accuracy: 0.8049, Test Loss: 0.0992, Test Accuracy: 0.7991\n",
      "Epoch 6, Loss: 0.2340, Accuracy: 0.8084, Test Loss: 0.0977, Test Accuracy: 0.8084\n",
      "Epoch 7, Loss: 0.2213, Accuracy: 0.8096, Test Loss: 0.0967, Test Accuracy: 0.8201\n",
      "Epoch 8, Loss: 0.1966, Accuracy: 0.8160, Test Loss: 0.0948, Test Accuracy: 0.8131\n",
      "Epoch 9, Loss: 0.1784, Accuracy: 0.8242, Test Loss: 0.0799, Test Accuracy: 0.8248\n",
      "Epoch 10, Loss: 0.1659, Accuracy: 0.8213, Test Loss: 0.0968, Test Accuracy: 0.8224\n",
      "Epoch 11, Loss: 0.1553, Accuracy: 0.8271, Test Loss: 0.0827, Test Accuracy: 0.8341\n",
      "Epoch 12, Loss: 0.1403, Accuracy: 0.8394, Test Loss: 0.0800, Test Accuracy: 0.8201\n",
      "Epoch 13, Loss: 0.1411, Accuracy: 0.8265, Test Loss: 0.0777, Test Accuracy: 0.8201\n",
      "Epoch 14, Loss: 0.1302, Accuracy: 0.8405, Test Loss: 0.0762, Test Accuracy: 0.8248\n",
      "Epoch 15, Loss: 0.1199, Accuracy: 0.8464, Test Loss: 0.0888, Test Accuracy: 0.8388\n",
      "Epoch 16, Loss: 0.1176, Accuracy: 0.8411, Test Loss: 0.0722, Test Accuracy: 0.8294\n",
      "Epoch 17, Loss: 0.1115, Accuracy: 0.8440, Test Loss: 0.0787, Test Accuracy: 0.8364\n",
      "Epoch 18, Loss: 0.1142, Accuracy: 0.8405, Test Loss: 0.0679, Test Accuracy: 0.8481\n",
      "Epoch 19, Loss: 0.1102, Accuracy: 0.8423, Test Loss: 0.0739, Test Accuracy: 0.8411\n",
      "Epoch 20, Loss: 0.1058, Accuracy: 0.8405, Test Loss: 0.0797, Test Accuracy: 0.8154\n",
      "Epoch 21, Loss: 0.1041, Accuracy: 0.8382, Test Loss: 0.0629, Test Accuracy: 0.8411\n",
      "Epoch 22, Loss: 0.1006, Accuracy: 0.8435, Test Loss: 0.0620, Test Accuracy: 0.8481\n",
      "Epoch 23, Loss: 0.0964, Accuracy: 0.8458, Test Loss: 0.0647, Test Accuracy: 0.8364\n",
      "Epoch 24, Loss: 0.0952, Accuracy: 0.8446, Test Loss: 0.0676, Test Accuracy: 0.8388\n",
      "Epoch 25, Loss: 0.0921, Accuracy: 0.8481, Test Loss: 0.0701, Test Accuracy: 0.8388\n",
      "Epoch 26, Loss: 0.0951, Accuracy: 0.8417, Test Loss: 0.0692, Test Accuracy: 0.8248\n",
      "Epoch 27, Loss: 0.0925, Accuracy: 0.8440, Test Loss: 0.0604, Test Accuracy: 0.8528\n",
      "Epoch 28, Loss: 0.0913, Accuracy: 0.8499, Test Loss: 0.0631, Test Accuracy: 0.8551\n",
      "Epoch 29, Loss: 0.0904, Accuracy: 0.8435, Test Loss: 0.0592, Test Accuracy: 0.8645\n",
      "Epoch 30, Loss: 0.0860, Accuracy: 0.8493, Test Loss: 0.0715, Test Accuracy: 0.8294\n",
      "Epoch 31, Loss: 0.0853, Accuracy: 0.8464, Test Loss: 0.0604, Test Accuracy: 0.8551\n",
      "Epoch 32, Loss: 0.0854, Accuracy: 0.8464, Test Loss: 0.0644, Test Accuracy: 0.8411\n",
      "Epoch 33, Loss: 0.0857, Accuracy: 0.8475, Test Loss: 0.0672, Test Accuracy: 0.8411\n",
      "Epoch 34, Loss: 0.0913, Accuracy: 0.8405, Test Loss: 0.0638, Test Accuracy: 0.8481\n",
      "Epoch 35, Loss: 0.0918, Accuracy: 0.8440, Test Loss: 0.0685, Test Accuracy: 0.8388\n",
      "Epoch 36, Loss: 0.0920, Accuracy: 0.8423, Test Loss: 0.0639, Test Accuracy: 0.8505\n",
      "Epoch 37, Loss: 0.0860, Accuracy: 0.8487, Test Loss: 0.0659, Test Accuracy: 0.8364\n",
      "Epoch 38, Loss: 0.0851, Accuracy: 0.8475, Test Loss: 0.0596, Test Accuracy: 0.8505\n",
      "Epoch 39, Loss: 0.0815, Accuracy: 0.8481, Test Loss: 0.0581, Test Accuracy: 0.8505\n",
      "Epoch 40, Loss: 0.0831, Accuracy: 0.8446, Test Loss: 0.0560, Test Accuracy: 0.8505\n",
      "Epoch 41, Loss: 0.0796, Accuracy: 0.8505, Test Loss: 0.0618, Test Accuracy: 0.8528\n",
      "Epoch 42, Loss: 0.0798, Accuracy: 0.8505, Test Loss: 0.0576, Test Accuracy: 0.8598\n",
      "Epoch 43, Loss: 0.0801, Accuracy: 0.8481, Test Loss: 0.0609, Test Accuracy: 0.8621\n",
      "Epoch 44, Loss: 0.0807, Accuracy: 0.8499, Test Loss: 0.0527, Test Accuracy: 0.8621\n",
      "Epoch 45, Loss: 0.0790, Accuracy: 0.8505, Test Loss: 0.0655, Test Accuracy: 0.8388\n",
      "Epoch 46, Loss: 0.0834, Accuracy: 0.8446, Test Loss: 0.0629, Test Accuracy: 0.8458\n",
      "Epoch 47, Loss: 0.0793, Accuracy: 0.8458, Test Loss: 0.0619, Test Accuracy: 0.8435\n",
      "Epoch 48, Loss: 0.0789, Accuracy: 0.8446, Test Loss: 0.0574, Test Accuracy: 0.8621\n",
      "Epoch 49, Loss: 0.0785, Accuracy: 0.8481, Test Loss: 0.0553, Test Accuracy: 0.8505\n",
      "Epoch 50, Loss: 0.0748, Accuracy: 0.8534, Test Loss: 0.0604, Test Accuracy: 0.8668\n",
      "Epoch 51, Loss: 0.0782, Accuracy: 0.8528, Test Loss: 0.0596, Test Accuracy: 0.8598\n",
      "Epoch 52, Loss: 0.0769, Accuracy: 0.8499, Test Loss: 0.0639, Test Accuracy: 0.8481\n",
      "Epoch 53, Loss: 0.0788, Accuracy: 0.8458, Test Loss: 0.0552, Test Accuracy: 0.8645\n",
      "Epoch 54, Loss: 0.0761, Accuracy: 0.8470, Test Loss: 0.0635, Test Accuracy: 0.8528\n",
      "Epoch 55, Loss: 0.0762, Accuracy: 0.8505, Test Loss: 0.0644, Test Accuracy: 0.8341\n",
      "Epoch 56, Loss: 0.0761, Accuracy: 0.8481, Test Loss: 0.0584, Test Accuracy: 0.8598\n",
      "Epoch 57, Loss: 0.0763, Accuracy: 0.8475, Test Loss: 0.0648, Test Accuracy: 0.8505\n",
      "Epoch 58, Loss: 0.0780, Accuracy: 0.8464, Test Loss: 0.0602, Test Accuracy: 0.8551\n",
      "Epoch 59, Loss: 0.0757, Accuracy: 0.8452, Test Loss: 0.0601, Test Accuracy: 0.8505\n",
      "Epoch 60, Loss: 0.0743, Accuracy: 0.8493, Test Loss: 0.0562, Test Accuracy: 0.8645\n",
      "Epoch 61, Loss: 0.0743, Accuracy: 0.8493, Test Loss: 0.0598, Test Accuracy: 0.8551\n",
      "Epoch 62, Loss: 0.0750, Accuracy: 0.8522, Test Loss: 0.0651, Test Accuracy: 0.8505\n",
      "Epoch 63, Loss: 0.0762, Accuracy: 0.8499, Test Loss: 0.0596, Test Accuracy: 0.8575\n",
      "Epoch 64, Loss: 0.0775, Accuracy: 0.8534, Test Loss: 0.0626, Test Accuracy: 0.8528\n",
      "Epoch 65, Loss: 0.0744, Accuracy: 0.8528, Test Loss: 0.0576, Test Accuracy: 0.8528\n",
      "Epoch 66, Loss: 0.0751, Accuracy: 0.8516, Test Loss: 0.0611, Test Accuracy: 0.8528\n",
      "Epoch 67, Loss: 0.0771, Accuracy: 0.8481, Test Loss: 0.0640, Test Accuracy: 0.8388\n",
      "Epoch 68, Loss: 0.0764, Accuracy: 0.8458, Test Loss: 0.0657, Test Accuracy: 0.8411\n",
      "Epoch 69, Loss: 0.0755, Accuracy: 0.8511, Test Loss: 0.0617, Test Accuracy: 0.8551\n",
      "Epoch 70, Loss: 0.0752, Accuracy: 0.8487, Test Loss: 0.0544, Test Accuracy: 0.8621\n",
      "Epoch 71, Loss: 0.0734, Accuracy: 0.8516, Test Loss: 0.0607, Test Accuracy: 0.8621\n",
      "Epoch 72, Loss: 0.0714, Accuracy: 0.8540, Test Loss: 0.0552, Test Accuracy: 0.8598\n",
      "Epoch 73, Loss: 0.0703, Accuracy: 0.8569, Test Loss: 0.0658, Test Accuracy: 0.8528\n",
      "Epoch 74, Loss: 0.0728, Accuracy: 0.8511, Test Loss: 0.0668, Test Accuracy: 0.8411\n",
      "Epoch 75, Loss: 0.0761, Accuracy: 0.8481, Test Loss: 0.0604, Test Accuracy: 0.8481\n",
      "Epoch 76, Loss: 0.0752, Accuracy: 0.8505, Test Loss: 0.0587, Test Accuracy: 0.8575\n",
      "Epoch 77, Loss: 0.0756, Accuracy: 0.8540, Test Loss: 0.0566, Test Accuracy: 0.8621\n",
      "Epoch 78, Loss: 0.0750, Accuracy: 0.8511, Test Loss: 0.0589, Test Accuracy: 0.8551\n",
      "Epoch 79, Loss: 0.0731, Accuracy: 0.8528, Test Loss: 0.0673, Test Accuracy: 0.8411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:34:32,166] Trial 173 finished with value: 0.866822429906542 and parameters: {'batch_size': 64, 'num_gcn_layers': 2, 'gcn_hidden_dim_0': 59, 'gcn_hidden_dim_1': 53, 'num_fc_layers': 2, 'fc_hidden_dim_0': 200, 'fc_hidden_dim_1': 236, 'learning_rate': 3.1835436981766496e-05, 'weight_decay': 0.0005085776780562061, 'pooling_method': 'max', 'gcn_batch_norm_flag_0': True, 'gcn_batch_norm_flag_1': True, 'gcn_momentum_0': 0.9639820467336527, 'gcn_momentum_1': 0.10617341386073792, 'gcn_eps_0': 0.005454789139434619, 'gcn_eps_1': 0.0011876848633206568, 'gcn_dropout_flag_0': False, 'gcn_dropout_flag_1': False, 'gcn_activation_0': 'elu', 'gcn_activation_1': 'relu', 'fc_batch_norm_flag_0': False, 'fc_batch_norm_flag_1': True, 'fc_momentum_1': 0.3795825450186838, 'fc_eps_1': 0.002843022939763745, 'fc_dropout_flag_0': False, 'fc_dropout_flag_1': True, 'fc_dropout_rate_1': 0.19375606617367455, 'fc_activation_0': 'relu', 'fc_activation_1': 'tanh', 'gcn_skip_connections_0': False, 'gcn_skip_connections_1': True, 'l1_lambda': 8.049965990722567e-05, 'optimizer': 'Adam', 'beta1': 0.9223221539307752, 'beta2': 0.9926542162840238, 'lr_scheduler': 'OneCycleLR', 'max_lr_1': 0.08938207603286379, 'pct_start': 0.4027199399014039, 'loss_function': 'MultiMargin'}. Best is trial 33 with value: 0.8714953271028038.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80, Loss: 0.0745, Accuracy: 0.8470, Test Loss: 0.0610, Test Accuracy: 0.8481\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:34:33,539] Trial 174 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.2266, Accuracy: 0.6904, Test Loss: 0.1479, Test Accuracy: 0.7407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:34:34,897] Trial 175 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.9861, Accuracy: 0.2856, Test Loss: 0.5031, Test Accuracy: 0.4556\n",
      "Epoch 1, Loss: 0.9240, Accuracy: 0.7097, Test Loss: 0.5964, Test Accuracy: 0.7874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:34:38,617] Trial 176 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.7033, Accuracy: 0.7728, Test Loss: 0.5536, Test Accuracy: 0.7944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:34:39,982] Trial 177 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.6641, Accuracy: 0.7097, Test Loss: 0.1206, Test Accuracy: 0.7734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:34:41,295] Trial 178 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.8988, Accuracy: 0.6040, Test Loss: 1.5844, Test Accuracy: 0.2150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:34:43,233] Trial 179 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.1498, Accuracy: 0.7272, Test Loss: 0.6232, Test Accuracy: 0.7523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:34:44,492] Trial 180 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6408, Accuracy: 0.6711, Test Loss: 0.1208, Test Accuracy: 0.7710\n",
      "Epoch 1, Loss: 0.5228, Accuracy: 0.7255, Test Loss: 0.1372, Test Accuracy: 0.7757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:34:47,110] Trial 181 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.4255, Accuracy: 0.7716, Test Loss: 0.1137, Test Accuracy: 0.7897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:34:48,319] Trial 182 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.5709, Accuracy: 0.7085, Test Loss: 0.1472, Test Accuracy: 0.7453\n",
      "Epoch 1, Loss: 0.7319, Accuracy: 0.7138, Test Loss: 0.1249, Test Accuracy: 0.7757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:34:50,840] Trial 183 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.5642, Accuracy: 0.7991, Test Loss: 0.1060, Test Accuracy: 0.7991\n",
      "Epoch 1, Loss: 0.4603, Accuracy: 0.6963, Test Loss: 0.1319, Test Accuracy: 0.7804\n",
      "Epoch 2, Loss: 0.3471, Accuracy: 0.7821, Test Loss: 0.1034, Test Accuracy: 0.8061\n",
      "Epoch 3, Loss: 0.3134, Accuracy: 0.7991, Test Loss: 0.0949, Test Accuracy: 0.8061\n",
      "Epoch 4, Loss: 0.2951, Accuracy: 0.8072, Test Loss: 0.0891, Test Accuracy: 0.8107\n",
      "Epoch 5, Loss: 0.2777, Accuracy: 0.8113, Test Loss: 0.0935, Test Accuracy: 0.8084\n",
      "Epoch 6, Loss: 0.2690, Accuracy: 0.8137, Test Loss: 0.0849, Test Accuracy: 0.8178\n",
      "Epoch 7, Loss: 0.2567, Accuracy: 0.8160, Test Loss: 0.0939, Test Accuracy: 0.8201\n",
      "Epoch 8, Loss: 0.2515, Accuracy: 0.8183, Test Loss: 0.0868, Test Accuracy: 0.8154\n",
      "Epoch 9, Loss: 0.2404, Accuracy: 0.8189, Test Loss: 0.0776, Test Accuracy: 0.8294\n",
      "Epoch 10, Loss: 0.2280, Accuracy: 0.8265, Test Loss: 0.0763, Test Accuracy: 0.8178\n",
      "Epoch 11, Loss: 0.2187, Accuracy: 0.8394, Test Loss: 0.0695, Test Accuracy: 0.8388\n",
      "Epoch 12, Loss: 0.2141, Accuracy: 0.8388, Test Loss: 0.0748, Test Accuracy: 0.8364\n",
      "Epoch 13, Loss: 0.2119, Accuracy: 0.8341, Test Loss: 0.0840, Test Accuracy: 0.8224\n",
      "Epoch 14, Loss: 0.2035, Accuracy: 0.8359, Test Loss: 0.0775, Test Accuracy: 0.8411\n",
      "Epoch 15, Loss: 0.1972, Accuracy: 0.8364, Test Loss: 0.0793, Test Accuracy: 0.8271\n",
      "Epoch 16, Loss: 0.1898, Accuracy: 0.8440, Test Loss: 0.0792, Test Accuracy: 0.8435\n",
      "Epoch 17, Loss: 0.1834, Accuracy: 0.8452, Test Loss: 0.0717, Test Accuracy: 0.8411\n",
      "Epoch 18, Loss: 0.1801, Accuracy: 0.8493, Test Loss: 0.0868, Test Accuracy: 0.8178\n",
      "Epoch 19, Loss: 0.1761, Accuracy: 0.8487, Test Loss: 0.0768, Test Accuracy: 0.8458\n",
      "Epoch 20, Loss: 0.1756, Accuracy: 0.8405, Test Loss: 0.0836, Test Accuracy: 0.8294\n",
      "Epoch 21, Loss: 0.1720, Accuracy: 0.8423, Test Loss: 0.0669, Test Accuracy: 0.8294\n",
      "Epoch 22, Loss: 0.1711, Accuracy: 0.8370, Test Loss: 0.0673, Test Accuracy: 0.8341\n",
      "Epoch 23, Loss: 0.1650, Accuracy: 0.8458, Test Loss: 0.0700, Test Accuracy: 0.8341\n",
      "Epoch 24, Loss: 0.1640, Accuracy: 0.8429, Test Loss: 0.0701, Test Accuracy: 0.8388\n",
      "Epoch 25, Loss: 0.1660, Accuracy: 0.8417, Test Loss: 0.0723, Test Accuracy: 0.8411\n",
      "Epoch 26, Loss: 0.1625, Accuracy: 0.8458, Test Loss: 0.0718, Test Accuracy: 0.8528\n",
      "Epoch 27, Loss: 0.1559, Accuracy: 0.8429, Test Loss: 0.0803, Test Accuracy: 0.8411\n",
      "Epoch 28, Loss: 0.1524, Accuracy: 0.8435, Test Loss: 0.0665, Test Accuracy: 0.8341\n",
      "Epoch 29, Loss: 0.1520, Accuracy: 0.8440, Test Loss: 0.0652, Test Accuracy: 0.8458\n",
      "Epoch 30, Loss: 0.1486, Accuracy: 0.8516, Test Loss: 0.0607, Test Accuracy: 0.8435\n",
      "Epoch 31, Loss: 0.1485, Accuracy: 0.8464, Test Loss: 0.0716, Test Accuracy: 0.8364\n",
      "Epoch 32, Loss: 0.1411, Accuracy: 0.8534, Test Loss: 0.0943, Test Accuracy: 0.8318\n",
      "Epoch 33, Loss: 0.1406, Accuracy: 0.8546, Test Loss: 0.0736, Test Accuracy: 0.8435\n",
      "Epoch 34, Loss: 0.1396, Accuracy: 0.8505, Test Loss: 0.0918, Test Accuracy: 0.8364\n",
      "Epoch 35, Loss: 0.1403, Accuracy: 0.8470, Test Loss: 0.0699, Test Accuracy: 0.8318\n",
      "Epoch 36, Loss: 0.1402, Accuracy: 0.8446, Test Loss: 0.0742, Test Accuracy: 0.8318\n",
      "Epoch 37, Loss: 0.1371, Accuracy: 0.8440, Test Loss: 0.0670, Test Accuracy: 0.8458\n",
      "Epoch 38, Loss: 0.1325, Accuracy: 0.8511, Test Loss: 0.0635, Test Accuracy: 0.8341\n",
      "Epoch 39, Loss: 0.1291, Accuracy: 0.8528, Test Loss: 0.0649, Test Accuracy: 0.8505\n",
      "Epoch 40, Loss: 0.1268, Accuracy: 0.8569, Test Loss: 0.0600, Test Accuracy: 0.8575\n",
      "Epoch 41, Loss: 0.1243, Accuracy: 0.8557, Test Loss: 0.0646, Test Accuracy: 0.8435\n",
      "Epoch 42, Loss: 0.1256, Accuracy: 0.8493, Test Loss: 0.0630, Test Accuracy: 0.8481\n",
      "Epoch 43, Loss: 0.1232, Accuracy: 0.8505, Test Loss: 0.0608, Test Accuracy: 0.8505\n",
      "Epoch 44, Loss: 0.1238, Accuracy: 0.8452, Test Loss: 0.0640, Test Accuracy: 0.8458\n",
      "Epoch 45, Loss: 0.1229, Accuracy: 0.8534, Test Loss: 0.0678, Test Accuracy: 0.8388\n",
      "Epoch 46, Loss: 0.1301, Accuracy: 0.8475, Test Loss: 0.0726, Test Accuracy: 0.8411\n",
      "Epoch 47, Loss: 0.1252, Accuracy: 0.8499, Test Loss: 0.0680, Test Accuracy: 0.8458\n",
      "Epoch 48, Loss: 0.1197, Accuracy: 0.8546, Test Loss: 0.0597, Test Accuracy: 0.8598\n",
      "Epoch 49, Loss: 0.1154, Accuracy: 0.8569, Test Loss: 0.0612, Test Accuracy: 0.8505\n",
      "Epoch 50, Loss: 0.1131, Accuracy: 0.8581, Test Loss: 0.0611, Test Accuracy: 0.8528\n",
      "Epoch 51, Loss: 0.1126, Accuracy: 0.8557, Test Loss: 0.0594, Test Accuracy: 0.8575\n",
      "Epoch 52, Loss: 0.1120, Accuracy: 0.8557, Test Loss: 0.0587, Test Accuracy: 0.8505\n",
      "Epoch 53, Loss: 0.1112, Accuracy: 0.8540, Test Loss: 0.0594, Test Accuracy: 0.8528\n",
      "Epoch 54, Loss: 0.1098, Accuracy: 0.8586, Test Loss: 0.0644, Test Accuracy: 0.8481\n",
      "Epoch 55, Loss: 0.1084, Accuracy: 0.8557, Test Loss: 0.0660, Test Accuracy: 0.8364\n",
      "Epoch 56, Loss: 0.1111, Accuracy: 0.8522, Test Loss: 0.0645, Test Accuracy: 0.8411\n",
      "Epoch 57, Loss: 0.1085, Accuracy: 0.8575, Test Loss: 0.0590, Test Accuracy: 0.8505\n",
      "Epoch 58, Loss: 0.1077, Accuracy: 0.8534, Test Loss: 0.0594, Test Accuracy: 0.8598\n",
      "Epoch 59, Loss: 0.1059, Accuracy: 0.8569, Test Loss: 0.0575, Test Accuracy: 0.8551\n",
      "Epoch 60, Loss: 0.1063, Accuracy: 0.8563, Test Loss: 0.0585, Test Accuracy: 0.8575\n",
      "Epoch 61, Loss: 0.1033, Accuracy: 0.8581, Test Loss: 0.0646, Test Accuracy: 0.8481\n",
      "Epoch 62, Loss: 0.1044, Accuracy: 0.8522, Test Loss: 0.0606, Test Accuracy: 0.8551\n",
      "Epoch 63, Loss: 0.1041, Accuracy: 0.8551, Test Loss: 0.0614, Test Accuracy: 0.8575\n",
      "Epoch 64, Loss: 0.1067, Accuracy: 0.8528, Test Loss: 0.0661, Test Accuracy: 0.8505\n",
      "Epoch 65, Loss: 0.1039, Accuracy: 0.8516, Test Loss: 0.0647, Test Accuracy: 0.8411\n",
      "Epoch 66, Loss: 0.1035, Accuracy: 0.8563, Test Loss: 0.0642, Test Accuracy: 0.8505\n",
      "Epoch 67, Loss: 0.0998, Accuracy: 0.8586, Test Loss: 0.0594, Test Accuracy: 0.8481\n",
      "Epoch 68, Loss: 0.0990, Accuracy: 0.8598, Test Loss: 0.0579, Test Accuracy: 0.8505\n",
      "Epoch 69, Loss: 0.0990, Accuracy: 0.8557, Test Loss: 0.0632, Test Accuracy: 0.8505\n",
      "Epoch 70, Loss: 0.1000, Accuracy: 0.8581, Test Loss: 0.0574, Test Accuracy: 0.8528\n",
      "Epoch 71, Loss: 0.0997, Accuracy: 0.8528, Test Loss: 0.0678, Test Accuracy: 0.8435\n",
      "Epoch 72, Loss: 0.0984, Accuracy: 0.8598, Test Loss: 0.0619, Test Accuracy: 0.8528\n",
      "Epoch 73, Loss: 0.0976, Accuracy: 0.8563, Test Loss: 0.0617, Test Accuracy: 0.8481\n",
      "Epoch 74, Loss: 0.0960, Accuracy: 0.8598, Test Loss: 0.0662, Test Accuracy: 0.8435\n",
      "Epoch 75, Loss: 0.0959, Accuracy: 0.8569, Test Loss: 0.0638, Test Accuracy: 0.8528\n",
      "Epoch 76, Loss: 0.0949, Accuracy: 0.8592, Test Loss: 0.0579, Test Accuracy: 0.8528\n",
      "Epoch 77, Loss: 0.0953, Accuracy: 0.8575, Test Loss: 0.0651, Test Accuracy: 0.8341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:36:16,801] Trial 184 finished with value: 0.8598130841121495 and parameters: {'batch_size': 64, 'num_gcn_layers': 2, 'gcn_hidden_dim_0': 62, 'gcn_hidden_dim_1': 37, 'num_fc_layers': 2, 'fc_hidden_dim_0': 181, 'fc_hidden_dim_1': 250, 'learning_rate': 3.139817585258675e-05, 'weight_decay': 4.349430928318107e-05, 'pooling_method': 'max', 'gcn_batch_norm_flag_0': True, 'gcn_batch_norm_flag_1': True, 'gcn_momentum_0': 0.8532328583088403, 'gcn_momentum_1': 0.1212927962146747, 'gcn_eps_0': 0.006480665805879365, 'gcn_eps_1': 0.0008509567293485106, 'gcn_dropout_flag_0': False, 'gcn_dropout_flag_1': False, 'gcn_activation_0': 'elu', 'gcn_activation_1': 'relu', 'fc_batch_norm_flag_0': False, 'fc_batch_norm_flag_1': True, 'fc_momentum_1': 0.28960218219717304, 'fc_eps_1': 0.00795323914813028, 'fc_dropout_flag_0': False, 'fc_dropout_flag_1': True, 'fc_dropout_rate_1': 0.17008435459777377, 'fc_activation_0': 'relu', 'fc_activation_1': 'tanh', 'gcn_skip_connections_0': False, 'gcn_skip_connections_1': True, 'l1_lambda': 7.722971819384293e-05, 'optimizer': 'Adam', 'beta1': 0.9191428516117851, 'beta2': 0.9937798381649554, 'lr_scheduler': 'OneCycleLR', 'max_lr_1': 0.0310029220513764, 'pct_start': 0.44214799279745515, 'loss_function': 'MultiMargin'}. Best is trial 33 with value: 0.8714953271028038.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78, Loss: 0.0987, Accuracy: 0.8563, Test Loss: 0.0579, Test Accuracy: 0.8575\n",
      "Early stopping triggered\n",
      "Epoch 1, Loss: 0.5681, Accuracy: 0.7325, Test Loss: 0.1008, Test Accuracy: 0.8084\n",
      "Epoch 2, Loss: 0.4403, Accuracy: 0.7973, Test Loss: 0.0961, Test Accuracy: 0.8061\n",
      "Epoch 3, Loss: 0.3707, Accuracy: 0.8020, Test Loss: 0.0983, Test Accuracy: 0.8131\n",
      "Epoch 4, Loss: 0.3238, Accuracy: 0.8020, Test Loss: 0.0962, Test Accuracy: 0.8084\n",
      "Epoch 5, Loss: 0.2836, Accuracy: 0.8072, Test Loss: 0.0959, Test Accuracy: 0.8107\n",
      "Epoch 6, Loss: 0.2520, Accuracy: 0.8166, Test Loss: 0.0829, Test Accuracy: 0.8154\n",
      "Epoch 7, Loss: 0.2291, Accuracy: 0.8283, Test Loss: 0.0932, Test Accuracy: 0.8037\n",
      "Epoch 8, Loss: 0.2070, Accuracy: 0.8289, Test Loss: 0.0716, Test Accuracy: 0.8248\n",
      "Epoch 9, Loss: 0.1936, Accuracy: 0.8259, Test Loss: 0.0854, Test Accuracy: 0.8131\n",
      "Epoch 10, Loss: 0.1868, Accuracy: 0.8289, Test Loss: 0.0740, Test Accuracy: 0.8364\n",
      "Epoch 11, Loss: 0.1701, Accuracy: 0.8341, Test Loss: 0.0746, Test Accuracy: 0.8294\n",
      "Epoch 12, Loss: 0.1591, Accuracy: 0.8400, Test Loss: 0.0658, Test Accuracy: 0.8364\n",
      "Epoch 13, Loss: 0.1493, Accuracy: 0.8364, Test Loss: 0.0627, Test Accuracy: 0.8435\n",
      "Epoch 14, Loss: 0.1488, Accuracy: 0.8318, Test Loss: 0.0694, Test Accuracy: 0.8388\n",
      "Epoch 15, Loss: 0.1392, Accuracy: 0.8405, Test Loss: 0.0648, Test Accuracy: 0.8364\n",
      "Epoch 16, Loss: 0.1336, Accuracy: 0.8394, Test Loss: 0.0644, Test Accuracy: 0.8458\n",
      "Epoch 17, Loss: 0.1372, Accuracy: 0.8335, Test Loss: 0.0630, Test Accuracy: 0.8341\n",
      "Epoch 18, Loss: 0.1266, Accuracy: 0.8435, Test Loss: 0.0697, Test Accuracy: 0.8388\n",
      "Epoch 19, Loss: 0.1236, Accuracy: 0.8376, Test Loss: 0.0676, Test Accuracy: 0.8364\n",
      "Epoch 20, Loss: 0.1219, Accuracy: 0.8452, Test Loss: 0.0568, Test Accuracy: 0.8505\n",
      "Epoch 21, Loss: 0.1157, Accuracy: 0.8452, Test Loss: 0.0625, Test Accuracy: 0.8458\n",
      "Epoch 22, Loss: 0.1127, Accuracy: 0.8417, Test Loss: 0.0601, Test Accuracy: 0.8458\n",
      "Epoch 23, Loss: 0.1084, Accuracy: 0.8446, Test Loss: 0.0586, Test Accuracy: 0.8528\n",
      "Epoch 24, Loss: 0.1066, Accuracy: 0.8423, Test Loss: 0.0617, Test Accuracy: 0.8435\n",
      "Epoch 25, Loss: 0.1054, Accuracy: 0.8423, Test Loss: 0.0619, Test Accuracy: 0.8551\n",
      "Epoch 26, Loss: 0.1048, Accuracy: 0.8423, Test Loss: 0.0607, Test Accuracy: 0.8364\n",
      "Epoch 27, Loss: 0.1070, Accuracy: 0.8423, Test Loss: 0.0600, Test Accuracy: 0.8505\n",
      "Epoch 28, Loss: 0.1038, Accuracy: 0.8481, Test Loss: 0.0603, Test Accuracy: 0.8575\n",
      "Epoch 29, Loss: 0.1010, Accuracy: 0.8458, Test Loss: 0.0557, Test Accuracy: 0.8621\n",
      "Epoch 30, Loss: 0.0975, Accuracy: 0.8458, Test Loss: 0.0635, Test Accuracy: 0.8411\n",
      "Epoch 31, Loss: 0.0981, Accuracy: 0.8475, Test Loss: 0.0628, Test Accuracy: 0.8621\n",
      "Epoch 32, Loss: 0.0933, Accuracy: 0.8499, Test Loss: 0.0597, Test Accuracy: 0.8458\n",
      "Epoch 33, Loss: 0.0920, Accuracy: 0.8493, Test Loss: 0.0537, Test Accuracy: 0.8621\n",
      "Epoch 34, Loss: 0.0953, Accuracy: 0.8464, Test Loss: 0.0610, Test Accuracy: 0.8598\n",
      "Epoch 35, Loss: 0.0946, Accuracy: 0.8446, Test Loss: 0.0570, Test Accuracy: 0.8575\n",
      "Epoch 36, Loss: 0.0920, Accuracy: 0.8475, Test Loss: 0.0671, Test Accuracy: 0.8435\n",
      "Epoch 37, Loss: 0.0944, Accuracy: 0.8464, Test Loss: 0.0586, Test Accuracy: 0.8528\n",
      "Epoch 38, Loss: 0.0893, Accuracy: 0.8505, Test Loss: 0.0618, Test Accuracy: 0.8458\n",
      "Epoch 39, Loss: 0.0925, Accuracy: 0.8458, Test Loss: 0.0610, Test Accuracy: 0.8435\n",
      "Epoch 40, Loss: 0.0925, Accuracy: 0.8464, Test Loss: 0.0609, Test Accuracy: 0.8598\n",
      "Epoch 41, Loss: 0.0904, Accuracy: 0.8446, Test Loss: 0.0614, Test Accuracy: 0.8505\n",
      "Epoch 42, Loss: 0.0971, Accuracy: 0.8388, Test Loss: 0.0608, Test Accuracy: 0.8551\n",
      "Epoch 43, Loss: 0.0893, Accuracy: 0.8511, Test Loss: 0.0540, Test Accuracy: 0.8598\n",
      "Epoch 44, Loss: 0.0881, Accuracy: 0.8481, Test Loss: 0.0556, Test Accuracy: 0.8528\n",
      "Epoch 45, Loss: 0.0881, Accuracy: 0.8499, Test Loss: 0.0534, Test Accuracy: 0.8621\n",
      "Epoch 46, Loss: 0.0885, Accuracy: 0.8475, Test Loss: 0.0625, Test Accuracy: 0.8411\n",
      "Epoch 47, Loss: 0.0880, Accuracy: 0.8505, Test Loss: 0.0541, Test Accuracy: 0.8645\n",
      "Epoch 48, Loss: 0.0848, Accuracy: 0.8522, Test Loss: 0.0512, Test Accuracy: 0.8621\n",
      "Epoch 49, Loss: 0.0860, Accuracy: 0.8505, Test Loss: 0.0517, Test Accuracy: 0.8621\n",
      "Epoch 50, Loss: 0.0849, Accuracy: 0.8516, Test Loss: 0.0558, Test Accuracy: 0.8551\n",
      "Epoch 51, Loss: 0.0866, Accuracy: 0.8470, Test Loss: 0.0657, Test Accuracy: 0.8411\n",
      "Epoch 52, Loss: 0.0872, Accuracy: 0.8475, Test Loss: 0.0563, Test Accuracy: 0.8528\n",
      "Epoch 53, Loss: 0.0859, Accuracy: 0.8487, Test Loss: 0.0566, Test Accuracy: 0.8598\n",
      "Epoch 54, Loss: 0.0886, Accuracy: 0.8435, Test Loss: 0.0614, Test Accuracy: 0.8481\n",
      "Epoch 55, Loss: 0.0827, Accuracy: 0.8522, Test Loss: 0.0529, Test Accuracy: 0.8598\n",
      "Epoch 56, Loss: 0.0860, Accuracy: 0.8464, Test Loss: 0.0569, Test Accuracy: 0.8528\n",
      "Epoch 57, Loss: 0.0844, Accuracy: 0.8505, Test Loss: 0.0536, Test Accuracy: 0.8598\n",
      "Epoch 58, Loss: 0.0867, Accuracy: 0.8458, Test Loss: 0.0557, Test Accuracy: 0.8505\n",
      "Epoch 59, Loss: 0.0839, Accuracy: 0.8540, Test Loss: 0.0701, Test Accuracy: 0.8294\n",
      "Epoch 60, Loss: 0.0865, Accuracy: 0.8481, Test Loss: 0.0549, Test Accuracy: 0.8598\n",
      "Epoch 61, Loss: 0.0850, Accuracy: 0.8511, Test Loss: 0.0568, Test Accuracy: 0.8528\n",
      "Epoch 62, Loss: 0.0802, Accuracy: 0.8551, Test Loss: 0.0608, Test Accuracy: 0.8481\n",
      "Epoch 63, Loss: 0.0817, Accuracy: 0.8493, Test Loss: 0.0555, Test Accuracy: 0.8621\n",
      "Epoch 64, Loss: 0.0828, Accuracy: 0.8475, Test Loss: 0.0543, Test Accuracy: 0.8645\n",
      "Epoch 65, Loss: 0.0857, Accuracy: 0.8470, Test Loss: 0.0550, Test Accuracy: 0.8598\n",
      "Epoch 66, Loss: 0.0833, Accuracy: 0.8493, Test Loss: 0.0584, Test Accuracy: 0.8458\n",
      "Epoch 67, Loss: 0.0829, Accuracy: 0.8475, Test Loss: 0.0630, Test Accuracy: 0.8435\n",
      "Epoch 68, Loss: 0.0819, Accuracy: 0.8481, Test Loss: 0.0537, Test Accuracy: 0.8575\n",
      "Epoch 69, Loss: 0.0836, Accuracy: 0.8487, Test Loss: 0.0567, Test Accuracy: 0.8621\n",
      "Epoch 70, Loss: 0.0800, Accuracy: 0.8522, Test Loss: 0.0518, Test Accuracy: 0.8598\n",
      "Epoch 71, Loss: 0.0798, Accuracy: 0.8516, Test Loss: 0.0514, Test Accuracy: 0.8621\n",
      "Epoch 72, Loss: 0.0810, Accuracy: 0.8522, Test Loss: 0.0577, Test Accuracy: 0.8528\n",
      "Epoch 73, Loss: 0.0815, Accuracy: 0.8511, Test Loss: 0.0589, Test Accuracy: 0.8598\n",
      "Epoch 74, Loss: 0.0807, Accuracy: 0.8516, Test Loss: 0.0578, Test Accuracy: 0.8505\n",
      "Epoch 75, Loss: 0.0828, Accuracy: 0.8511, Test Loss: 0.0560, Test Accuracy: 0.8505\n",
      "Epoch 76, Loss: 0.0806, Accuracy: 0.8522, Test Loss: 0.0586, Test Accuracy: 0.8505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:38:23,423] Trial 185 finished with value: 0.8644859813084113 and parameters: {'batch_size': 32, 'num_gcn_layers': 2, 'gcn_hidden_dim_0': 74, 'gcn_hidden_dim_1': 42, 'num_fc_layers': 2, 'fc_hidden_dim_0': 194, 'fc_hidden_dim_1': 197, 'learning_rate': 2.190666352863033e-05, 'weight_decay': 1.4483095254988024e-05, 'pooling_method': 'max', 'gcn_batch_norm_flag_0': True, 'gcn_batch_norm_flag_1': True, 'gcn_momentum_0': 0.1221263603693408, 'gcn_momentum_1': 0.9454273617214721, 'gcn_eps_0': 0.007247286545220553, 'gcn_eps_1': 0.0015039790974513431, 'gcn_dropout_flag_0': False, 'gcn_dropout_flag_1': False, 'gcn_activation_0': 'elu', 'gcn_activation_1': 'gelu', 'fc_batch_norm_flag_0': False, 'fc_batch_norm_flag_1': True, 'fc_momentum_1': 0.4186642989637622, 'fc_eps_1': 0.0032975681967100452, 'fc_dropout_flag_0': False, 'fc_dropout_flag_1': True, 'fc_dropout_rate_1': 0.21564041401908474, 'fc_activation_0': 'relu', 'fc_activation_1': 'leaky_relu', 'gcn_skip_connections_0': False, 'gcn_skip_connections_1': True, 'l1_lambda': 0.00014181957734242303, 'optimizer': 'Adam', 'beta1': 0.9239010871305628, 'beta2': 0.9954811822161248, 'lr_scheduler': 'OneCycleLR', 'max_lr_1': 0.07440414442010868, 'pct_start': 0.1551927306995748, 'loss_function': 'MultiMargin'}. Best is trial 33 with value: 0.8714953271028038.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77, Loss: 0.0793, Accuracy: 0.8581, Test Loss: 0.0574, Test Accuracy: 0.8621\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:38:25,620] Trial 186 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.9757, Accuracy: 0.6086, Test Loss: 0.2097, Test Accuracy: 0.7313\n",
      "Epoch 1, Loss: 2.0667, Accuracy: 0.7342, Test Loss: 0.1218, Test Accuracy: 0.7944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:38:29,429] Trial 187 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 1.1866, Accuracy: 0.7856, Test Loss: 0.1024, Test Accuracy: 0.7991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:38:30,747] Trial 188 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 3.1807, Accuracy: 0.5754, Test Loss: 0.8305, Test Accuracy: 0.7173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:38:33,608] Trial 189 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.3628, Accuracy: 0.3931, Test Loss: 0.4169, Test Accuracy: 0.5514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:38:35,969] Trial 190 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.3107, Accuracy: 0.5783, Test Loss: 0.8801, Test Accuracy: 0.2150\n",
      "Epoch 1, Loss: 0.5649, Accuracy: 0.7523, Test Loss: 0.1068, Test Accuracy: 0.8061\n",
      "Epoch 2, Loss: 0.4408, Accuracy: 0.8037, Test Loss: 0.0937, Test Accuracy: 0.8084\n",
      "Epoch 3, Loss: 0.3759, Accuracy: 0.7985, Test Loss: 0.0894, Test Accuracy: 0.8107\n",
      "Epoch 4, Loss: 0.3246, Accuracy: 0.8078, Test Loss: 0.0911, Test Accuracy: 0.8131\n",
      "Epoch 5, Loss: 0.2909, Accuracy: 0.8096, Test Loss: 0.0915, Test Accuracy: 0.8061\n",
      "Epoch 6, Loss: 0.2588, Accuracy: 0.8148, Test Loss: 0.0832, Test Accuracy: 0.8201\n",
      "Epoch 7, Loss: 0.2366, Accuracy: 0.8242, Test Loss: 0.0833, Test Accuracy: 0.8154\n",
      "Epoch 8, Loss: 0.2190, Accuracy: 0.8230, Test Loss: 0.0838, Test Accuracy: 0.8294\n",
      "Epoch 9, Loss: 0.2013, Accuracy: 0.8236, Test Loss: 0.0693, Test Accuracy: 0.8364\n",
      "Epoch 10, Loss: 0.1850, Accuracy: 0.8324, Test Loss: 0.0863, Test Accuracy: 0.8154\n",
      "Epoch 11, Loss: 0.1826, Accuracy: 0.8254, Test Loss: 0.0683, Test Accuracy: 0.8364\n",
      "Epoch 12, Loss: 0.1638, Accuracy: 0.8370, Test Loss: 0.0730, Test Accuracy: 0.8248\n",
      "Epoch 13, Loss: 0.1570, Accuracy: 0.8318, Test Loss: 0.0667, Test Accuracy: 0.8294\n",
      "Epoch 14, Loss: 0.1473, Accuracy: 0.8341, Test Loss: 0.0590, Test Accuracy: 0.8481\n",
      "Epoch 15, Loss: 0.1383, Accuracy: 0.8405, Test Loss: 0.0600, Test Accuracy: 0.8505\n",
      "Epoch 16, Loss: 0.1323, Accuracy: 0.8429, Test Loss: 0.0647, Test Accuracy: 0.8411\n",
      "Epoch 17, Loss: 0.1281, Accuracy: 0.8394, Test Loss: 0.0744, Test Accuracy: 0.8364\n",
      "Epoch 18, Loss: 0.1281, Accuracy: 0.8411, Test Loss: 0.0710, Test Accuracy: 0.8364\n",
      "Epoch 19, Loss: 0.1239, Accuracy: 0.8364, Test Loss: 0.0660, Test Accuracy: 0.8341\n",
      "Epoch 20, Loss: 0.1211, Accuracy: 0.8400, Test Loss: 0.0620, Test Accuracy: 0.8481\n",
      "Epoch 21, Loss: 0.1171, Accuracy: 0.8417, Test Loss: 0.0634, Test Accuracy: 0.8411\n",
      "Epoch 22, Loss: 0.1114, Accuracy: 0.8475, Test Loss: 0.0613, Test Accuracy: 0.8435\n",
      "Epoch 23, Loss: 0.1075, Accuracy: 0.8435, Test Loss: 0.0688, Test Accuracy: 0.8435\n",
      "Epoch 24, Loss: 0.1137, Accuracy: 0.8329, Test Loss: 0.0604, Test Accuracy: 0.8551\n",
      "Epoch 25, Loss: 0.1050, Accuracy: 0.8452, Test Loss: 0.0549, Test Accuracy: 0.8551\n",
      "Epoch 26, Loss: 0.1029, Accuracy: 0.8487, Test Loss: 0.0602, Test Accuracy: 0.8411\n",
      "Epoch 27, Loss: 0.0993, Accuracy: 0.8493, Test Loss: 0.0598, Test Accuracy: 0.8364\n",
      "Epoch 28, Loss: 0.0984, Accuracy: 0.8505, Test Loss: 0.0568, Test Accuracy: 0.8528\n",
      "Epoch 29, Loss: 0.1016, Accuracy: 0.8388, Test Loss: 0.0549, Test Accuracy: 0.8458\n",
      "Epoch 30, Loss: 0.0968, Accuracy: 0.8452, Test Loss: 0.0529, Test Accuracy: 0.8505\n",
      "Epoch 31, Loss: 0.0974, Accuracy: 0.8487, Test Loss: 0.0566, Test Accuracy: 0.8551\n",
      "Epoch 32, Loss: 0.0987, Accuracy: 0.8470, Test Loss: 0.0563, Test Accuracy: 0.8645\n",
      "Epoch 33, Loss: 0.0968, Accuracy: 0.8470, Test Loss: 0.0556, Test Accuracy: 0.8598\n",
      "Epoch 34, Loss: 0.0921, Accuracy: 0.8475, Test Loss: 0.0572, Test Accuracy: 0.8528\n",
      "Epoch 35, Loss: 0.0904, Accuracy: 0.8487, Test Loss: 0.0534, Test Accuracy: 0.8598\n",
      "Epoch 36, Loss: 0.0887, Accuracy: 0.8516, Test Loss: 0.0547, Test Accuracy: 0.8528\n",
      "Epoch 37, Loss: 0.0889, Accuracy: 0.8505, Test Loss: 0.0558, Test Accuracy: 0.8598\n",
      "Epoch 38, Loss: 0.0897, Accuracy: 0.8458, Test Loss: 0.0563, Test Accuracy: 0.8435\n",
      "Epoch 39, Loss: 0.0896, Accuracy: 0.8475, Test Loss: 0.0582, Test Accuracy: 0.8598\n",
      "Epoch 40, Loss: 0.0892, Accuracy: 0.8470, Test Loss: 0.0593, Test Accuracy: 0.8481\n",
      "Epoch 41, Loss: 0.0914, Accuracy: 0.8475, Test Loss: 0.0776, Test Accuracy: 0.8224\n",
      "Epoch 42, Loss: 0.0896, Accuracy: 0.8481, Test Loss: 0.0525, Test Accuracy: 0.8598\n",
      "Epoch 43, Loss: 0.0857, Accuracy: 0.8499, Test Loss: 0.0536, Test Accuracy: 0.8575\n",
      "Epoch 44, Loss: 0.0871, Accuracy: 0.8446, Test Loss: 0.0536, Test Accuracy: 0.8598\n",
      "Epoch 45, Loss: 0.0856, Accuracy: 0.8528, Test Loss: 0.0527, Test Accuracy: 0.8645\n",
      "Epoch 46, Loss: 0.0816, Accuracy: 0.8551, Test Loss: 0.0546, Test Accuracy: 0.8598\n",
      "Epoch 47, Loss: 0.0843, Accuracy: 0.8511, Test Loss: 0.0579, Test Accuracy: 0.8551\n",
      "Epoch 48, Loss: 0.0855, Accuracy: 0.8499, Test Loss: 0.0535, Test Accuracy: 0.8621\n",
      "Epoch 49, Loss: 0.0835, Accuracy: 0.8522, Test Loss: 0.0535, Test Accuracy: 0.8621\n",
      "Epoch 50, Loss: 0.0840, Accuracy: 0.8493, Test Loss: 0.0553, Test Accuracy: 0.8621\n",
      "Epoch 51, Loss: 0.0846, Accuracy: 0.8458, Test Loss: 0.0589, Test Accuracy: 0.8505\n",
      "Epoch 52, Loss: 0.0868, Accuracy: 0.8470, Test Loss: 0.0544, Test Accuracy: 0.8528\n",
      "Epoch 53, Loss: 0.0819, Accuracy: 0.8511, Test Loss: 0.0563, Test Accuracy: 0.8575\n",
      "Epoch 54, Loss: 0.0835, Accuracy: 0.8499, Test Loss: 0.0529, Test Accuracy: 0.8575\n",
      "Epoch 55, Loss: 0.0810, Accuracy: 0.8528, Test Loss: 0.0617, Test Accuracy: 0.8388\n",
      "Epoch 56, Loss: 0.0841, Accuracy: 0.8464, Test Loss: 0.0599, Test Accuracy: 0.8505\n",
      "Epoch 57, Loss: 0.0846, Accuracy: 0.8458, Test Loss: 0.0577, Test Accuracy: 0.8551\n",
      "Epoch 58, Loss: 0.0795, Accuracy: 0.8546, Test Loss: 0.0751, Test Accuracy: 0.8294\n",
      "Epoch 59, Loss: 0.0835, Accuracy: 0.8475, Test Loss: 0.0552, Test Accuracy: 0.8551\n",
      "Epoch 60, Loss: 0.0814, Accuracy: 0.8528, Test Loss: 0.0579, Test Accuracy: 0.8528\n",
      "Epoch 61, Loss: 0.0782, Accuracy: 0.8551, Test Loss: 0.0550, Test Accuracy: 0.8551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:40:19,770] Trial 191 finished with value: 0.8644859813084113 and parameters: {'batch_size': 32, 'num_gcn_layers': 2, 'gcn_hidden_dim_0': 75, 'gcn_hidden_dim_1': 43, 'num_fc_layers': 2, 'fc_hidden_dim_0': 195, 'fc_hidden_dim_1': 216, 'learning_rate': 1.840856623849249e-05, 'weight_decay': 2.0793184775919587e-05, 'pooling_method': 'max', 'gcn_batch_norm_flag_0': True, 'gcn_batch_norm_flag_1': True, 'gcn_momentum_0': 0.14208478124372928, 'gcn_momentum_1': 0.9424315845735832, 'gcn_eps_0': 0.007318523019420907, 'gcn_eps_1': 0.0014313977688323802, 'gcn_dropout_flag_0': False, 'gcn_dropout_flag_1': False, 'gcn_activation_0': 'elu', 'gcn_activation_1': 'gelu', 'fc_batch_norm_flag_0': False, 'fc_batch_norm_flag_1': True, 'fc_momentum_1': 0.4112830488612893, 'fc_eps_1': 0.0034405025404344773, 'fc_dropout_flag_0': False, 'fc_dropout_flag_1': True, 'fc_dropout_rate_1': 0.2163937986573987, 'fc_activation_0': 'relu', 'fc_activation_1': 'leaky_relu', 'gcn_skip_connections_0': False, 'gcn_skip_connections_1': True, 'l1_lambda': 0.00013702001241539452, 'optimizer': 'Adam', 'beta1': 0.9273933819957462, 'beta2': 0.9960466038343844, 'lr_scheduler': 'OneCycleLR', 'max_lr_1': 0.06927998841500806, 'pct_start': 0.15579780739176863, 'loss_function': 'MultiMargin'}. Best is trial 33 with value: 0.8714953271028038.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62, Loss: 0.0804, Accuracy: 0.8493, Test Loss: 0.0532, Test Accuracy: 0.8575\n",
      "Early stopping triggered\n",
      "Epoch 1, Loss: 0.5383, Accuracy: 0.7465, Test Loss: 0.1042, Test Accuracy: 0.7967\n",
      "Epoch 2, Loss: 0.4054, Accuracy: 0.7961, Test Loss: 0.1056, Test Accuracy: 0.8061\n",
      "Epoch 3, Loss: 0.3382, Accuracy: 0.8008, Test Loss: 0.0958, Test Accuracy: 0.8084\n",
      "Epoch 4, Loss: 0.2824, Accuracy: 0.8078, Test Loss: 0.1023, Test Accuracy: 0.8084\n",
      "Epoch 5, Loss: 0.2543, Accuracy: 0.7956, Test Loss: 0.0932, Test Accuracy: 0.8037\n",
      "Epoch 6, Loss: 0.2321, Accuracy: 0.8055, Test Loss: 0.0994, Test Accuracy: 0.8154\n",
      "Epoch 7, Loss: 0.2034, Accuracy: 0.8148, Test Loss: 0.0831, Test Accuracy: 0.8318\n",
      "Epoch 8, Loss: 0.1878, Accuracy: 0.8242, Test Loss: 0.1131, Test Accuracy: 0.7827\n",
      "Epoch 9, Loss: 0.1720, Accuracy: 0.8254, Test Loss: 0.0674, Test Accuracy: 0.8364\n",
      "Epoch 10, Loss: 0.1576, Accuracy: 0.8353, Test Loss: 0.0699, Test Accuracy: 0.8364\n",
      "Epoch 11, Loss: 0.1493, Accuracy: 0.8341, Test Loss: 0.0973, Test Accuracy: 0.8294\n",
      "Epoch 12, Loss: 0.1402, Accuracy: 0.8376, Test Loss: 0.0715, Test Accuracy: 0.8364\n",
      "Epoch 13, Loss: 0.1341, Accuracy: 0.8400, Test Loss: 0.0764, Test Accuracy: 0.8318\n",
      "Epoch 14, Loss: 0.1270, Accuracy: 0.8353, Test Loss: 0.0650, Test Accuracy: 0.8481\n",
      "Epoch 15, Loss: 0.1235, Accuracy: 0.8417, Test Loss: 0.0715, Test Accuracy: 0.8364\n",
      "Epoch 16, Loss: 0.1178, Accuracy: 0.8411, Test Loss: 0.0654, Test Accuracy: 0.8528\n",
      "Epoch 17, Loss: 0.1160, Accuracy: 0.8382, Test Loss: 0.0611, Test Accuracy: 0.8575\n",
      "Epoch 18, Loss: 0.1085, Accuracy: 0.8505, Test Loss: 0.0568, Test Accuracy: 0.8528\n",
      "Epoch 19, Loss: 0.1050, Accuracy: 0.8440, Test Loss: 0.0563, Test Accuracy: 0.8621\n",
      "Epoch 20, Loss: 0.1039, Accuracy: 0.8411, Test Loss: 0.0586, Test Accuracy: 0.8528\n",
      "Epoch 21, Loss: 0.1055, Accuracy: 0.8417, Test Loss: 0.0624, Test Accuracy: 0.8411\n",
      "Epoch 22, Loss: 0.0992, Accuracy: 0.8446, Test Loss: 0.0634, Test Accuracy: 0.8458\n",
      "Epoch 23, Loss: 0.0964, Accuracy: 0.8470, Test Loss: 0.0642, Test Accuracy: 0.8341\n",
      "Epoch 24, Loss: 0.0963, Accuracy: 0.8464, Test Loss: 0.0667, Test Accuracy: 0.8388\n",
      "Epoch 25, Loss: 0.0957, Accuracy: 0.8417, Test Loss: 0.0591, Test Accuracy: 0.8528\n",
      "Epoch 26, Loss: 0.0956, Accuracy: 0.8417, Test Loss: 0.0567, Test Accuracy: 0.8505\n",
      "Epoch 27, Loss: 0.0931, Accuracy: 0.8458, Test Loss: 0.0684, Test Accuracy: 0.8435\n",
      "Epoch 28, Loss: 0.0882, Accuracy: 0.8516, Test Loss: 0.0539, Test Accuracy: 0.8598\n",
      "Epoch 29, Loss: 0.0891, Accuracy: 0.8505, Test Loss: 0.0533, Test Accuracy: 0.8575\n",
      "Epoch 30, Loss: 0.0862, Accuracy: 0.8475, Test Loss: 0.0611, Test Accuracy: 0.8528\n",
      "Epoch 31, Loss: 0.0870, Accuracy: 0.8481, Test Loss: 0.0599, Test Accuracy: 0.8481\n",
      "Epoch 32, Loss: 0.0910, Accuracy: 0.8481, Test Loss: 0.0636, Test Accuracy: 0.8411\n",
      "Epoch 33, Loss: 0.0904, Accuracy: 0.8458, Test Loss: 0.0550, Test Accuracy: 0.8598\n",
      "Epoch 34, Loss: 0.0877, Accuracy: 0.8487, Test Loss: 0.0545, Test Accuracy: 0.8598\n",
      "Epoch 35, Loss: 0.0874, Accuracy: 0.8475, Test Loss: 0.0653, Test Accuracy: 0.8505\n",
      "Epoch 36, Loss: 0.0950, Accuracy: 0.8347, Test Loss: 0.0603, Test Accuracy: 0.8551\n",
      "Epoch 37, Loss: 0.0874, Accuracy: 0.8522, Test Loss: 0.0539, Test Accuracy: 0.8575\n",
      "Epoch 38, Loss: 0.0882, Accuracy: 0.8452, Test Loss: 0.0613, Test Accuracy: 0.8505\n",
      "Epoch 39, Loss: 0.0848, Accuracy: 0.8499, Test Loss: 0.0514, Test Accuracy: 0.8598\n",
      "Epoch 40, Loss: 0.0855, Accuracy: 0.8475, Test Loss: 0.0542, Test Accuracy: 0.8528\n",
      "Epoch 41, Loss: 0.0829, Accuracy: 0.8493, Test Loss: 0.0523, Test Accuracy: 0.8645\n",
      "Epoch 42, Loss: 0.0810, Accuracy: 0.8551, Test Loss: 0.0533, Test Accuracy: 0.8575\n",
      "Epoch 43, Loss: 0.0829, Accuracy: 0.8470, Test Loss: 0.0607, Test Accuracy: 0.8528\n",
      "Epoch 44, Loss: 0.0844, Accuracy: 0.8493, Test Loss: 0.0694, Test Accuracy: 0.8341\n",
      "Epoch 45, Loss: 0.0835, Accuracy: 0.8464, Test Loss: 0.0543, Test Accuracy: 0.8551\n",
      "Epoch 46, Loss: 0.0841, Accuracy: 0.8516, Test Loss: 0.0560, Test Accuracy: 0.8575\n",
      "Epoch 47, Loss: 0.0823, Accuracy: 0.8464, Test Loss: 0.0768, Test Accuracy: 0.8154\n",
      "Epoch 48, Loss: 0.0851, Accuracy: 0.8446, Test Loss: 0.0526, Test Accuracy: 0.8551\n",
      "Epoch 49, Loss: 0.0827, Accuracy: 0.8546, Test Loss: 0.0699, Test Accuracy: 0.8294\n",
      "Epoch 50, Loss: 0.0842, Accuracy: 0.8440, Test Loss: 0.0582, Test Accuracy: 0.8551\n",
      "Epoch 51, Loss: 0.0816, Accuracy: 0.8493, Test Loss: 0.0592, Test Accuracy: 0.8481\n",
      "Epoch 52, Loss: 0.0832, Accuracy: 0.8499, Test Loss: 0.0651, Test Accuracy: 0.8481\n",
      "Epoch 53, Loss: 0.0831, Accuracy: 0.8493, Test Loss: 0.0565, Test Accuracy: 0.8621\n",
      "Epoch 54, Loss: 0.0824, Accuracy: 0.8499, Test Loss: 0.0610, Test Accuracy: 0.8411\n",
      "Epoch 55, Loss: 0.0797, Accuracy: 0.8516, Test Loss: 0.0542, Test Accuracy: 0.8645\n",
      "Epoch 56, Loss: 0.0804, Accuracy: 0.8534, Test Loss: 0.0539, Test Accuracy: 0.8598\n",
      "Epoch 57, Loss: 0.0823, Accuracy: 0.8493, Test Loss: 0.0583, Test Accuracy: 0.8505\n",
      "Epoch 58, Loss: 0.0798, Accuracy: 0.8481, Test Loss: 0.0507, Test Accuracy: 0.8645\n",
      "Epoch 59, Loss: 0.0813, Accuracy: 0.8499, Test Loss: 0.0554, Test Accuracy: 0.8575\n",
      "Epoch 60, Loss: 0.0783, Accuracy: 0.8546, Test Loss: 0.0560, Test Accuracy: 0.8575\n",
      "Epoch 61, Loss: 0.0799, Accuracy: 0.8516, Test Loss: 0.0691, Test Accuracy: 0.8224\n",
      "Epoch 62, Loss: 0.0808, Accuracy: 0.8493, Test Loss: 0.0509, Test Accuracy: 0.8575\n",
      "Epoch 63, Loss: 0.0784, Accuracy: 0.8528, Test Loss: 0.0512, Test Accuracy: 0.8645\n",
      "Epoch 64, Loss: 0.0799, Accuracy: 0.8528, Test Loss: 0.0576, Test Accuracy: 0.8551\n",
      "Epoch 65, Loss: 0.0824, Accuracy: 0.8470, Test Loss: 0.0530, Test Accuracy: 0.8575\n",
      "Epoch 66, Loss: 0.0850, Accuracy: 0.8470, Test Loss: 0.0635, Test Accuracy: 0.8435\n",
      "Epoch 67, Loss: 0.0807, Accuracy: 0.8516, Test Loss: 0.0522, Test Accuracy: 0.8598\n",
      "Epoch 68, Loss: 0.0795, Accuracy: 0.8563, Test Loss: 0.0564, Test Accuracy: 0.8551\n",
      "Epoch 69, Loss: 0.0788, Accuracy: 0.8511, Test Loss: 0.0674, Test Accuracy: 0.8435\n",
      "Epoch 70, Loss: 0.0808, Accuracy: 0.8487, Test Loss: 0.0551, Test Accuracy: 0.8528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:42:15,075] Trial 192 finished with value: 0.8644859813084113 and parameters: {'batch_size': 32, 'num_gcn_layers': 2, 'gcn_hidden_dim_0': 69, 'gcn_hidden_dim_1': 51, 'num_fc_layers': 2, 'fc_hidden_dim_0': 192, 'fc_hidden_dim_1': 230, 'learning_rate': 2.067691546807003e-05, 'weight_decay': 3.786267349084264e-05, 'pooling_method': 'max', 'gcn_batch_norm_flag_0': True, 'gcn_batch_norm_flag_1': True, 'gcn_momentum_0': 0.8904463507108535, 'gcn_momentum_1': 0.9491465536262057, 'gcn_eps_0': 0.0071893221574177504, 'gcn_eps_1': 0.0017755844220910463, 'gcn_dropout_flag_0': False, 'gcn_dropout_flag_1': False, 'gcn_activation_0': 'elu', 'gcn_activation_1': 'gelu', 'fc_batch_norm_flag_0': False, 'fc_batch_norm_flag_1': True, 'fc_momentum_1': 0.5272014328831897, 'fc_eps_1': 0.003238507072926458, 'fc_dropout_flag_0': False, 'fc_dropout_flag_1': True, 'fc_dropout_rate_1': 0.20953500564154048, 'fc_activation_0': 'relu', 'fc_activation_1': 'leaky_relu', 'gcn_skip_connections_0': False, 'gcn_skip_connections_1': True, 'l1_lambda': 0.00011869216129445926, 'optimizer': 'Adam', 'beta1': 0.9223075613356208, 'beta2': 0.9932324051189989, 'lr_scheduler': 'OneCycleLR', 'max_lr_1': 0.08972997199378199, 'pct_start': 0.16641560519056586, 'loss_function': 'MultiMargin'}. Best is trial 33 with value: 0.8714953271028038.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71, Loss: 0.0779, Accuracy: 0.8505, Test Loss: 0.0569, Test Accuracy: 0.8598\n",
      "Early stopping triggered\n",
      "Epoch 1, Loss: 0.4535, Accuracy: 0.7360, Test Loss: 0.1017, Test Accuracy: 0.7921\n",
      "Epoch 2, Loss: 0.3538, Accuracy: 0.7921, Test Loss: 0.1027, Test Accuracy: 0.8061\n",
      "Epoch 3, Loss: 0.3055, Accuracy: 0.8037, Test Loss: 0.1000, Test Accuracy: 0.8061\n",
      "Epoch 4, Loss: 0.2683, Accuracy: 0.8061, Test Loss: 0.0968, Test Accuracy: 0.8084\n",
      "Epoch 5, Loss: 0.2434, Accuracy: 0.8032, Test Loss: 0.0894, Test Accuracy: 0.8061\n",
      "Epoch 6, Loss: 0.2120, Accuracy: 0.8096, Test Loss: 0.0960, Test Accuracy: 0.8131\n",
      "Epoch 7, Loss: 0.1996, Accuracy: 0.8055, Test Loss: 0.1070, Test Accuracy: 0.7967\n",
      "Epoch 8, Loss: 0.1842, Accuracy: 0.8137, Test Loss: 0.0824, Test Accuracy: 0.8037\n",
      "Epoch 9, Loss: 0.1808, Accuracy: 0.8125, Test Loss: 0.0801, Test Accuracy: 0.8154\n",
      "Epoch 10, Loss: 0.1686, Accuracy: 0.8154, Test Loss: 0.0711, Test Accuracy: 0.8178\n",
      "Epoch 11, Loss: 0.1611, Accuracy: 0.8207, Test Loss: 0.0675, Test Accuracy: 0.8505\n",
      "Epoch 12, Loss: 0.1510, Accuracy: 0.8289, Test Loss: 0.0735, Test Accuracy: 0.8364\n",
      "Epoch 13, Loss: 0.1459, Accuracy: 0.8329, Test Loss: 0.0610, Test Accuracy: 0.8528\n",
      "Epoch 14, Loss: 0.1334, Accuracy: 0.8347, Test Loss: 0.0682, Test Accuracy: 0.8458\n",
      "Epoch 15, Loss: 0.1289, Accuracy: 0.8347, Test Loss: 0.0697, Test Accuracy: 0.8318\n",
      "Epoch 16, Loss: 0.1231, Accuracy: 0.8364, Test Loss: 0.0622, Test Accuracy: 0.8481\n",
      "Epoch 17, Loss: 0.1206, Accuracy: 0.8359, Test Loss: 0.0604, Test Accuracy: 0.8575\n",
      "Epoch 18, Loss: 0.1189, Accuracy: 0.8429, Test Loss: 0.0602, Test Accuracy: 0.8575\n",
      "Epoch 19, Loss: 0.1132, Accuracy: 0.8417, Test Loss: 0.0573, Test Accuracy: 0.8621\n",
      "Epoch 20, Loss: 0.1118, Accuracy: 0.8376, Test Loss: 0.0620, Test Accuracy: 0.8458\n",
      "Epoch 21, Loss: 0.1071, Accuracy: 0.8440, Test Loss: 0.0655, Test Accuracy: 0.8411\n",
      "Epoch 22, Loss: 0.1095, Accuracy: 0.8417, Test Loss: 0.0646, Test Accuracy: 0.8294\n",
      "Epoch 23, Loss: 0.1079, Accuracy: 0.8435, Test Loss: 0.0596, Test Accuracy: 0.8458\n",
      "Epoch 24, Loss: 0.1075, Accuracy: 0.8394, Test Loss: 0.0565, Test Accuracy: 0.8551\n",
      "Epoch 25, Loss: 0.1002, Accuracy: 0.8487, Test Loss: 0.0578, Test Accuracy: 0.8505\n",
      "Epoch 26, Loss: 0.1031, Accuracy: 0.8429, Test Loss: 0.0586, Test Accuracy: 0.8528\n",
      "Epoch 27, Loss: 0.0953, Accuracy: 0.8528, Test Loss: 0.0669, Test Accuracy: 0.8435\n",
      "Epoch 28, Loss: 0.0969, Accuracy: 0.8446, Test Loss: 0.0724, Test Accuracy: 0.8271\n",
      "Epoch 29, Loss: 0.0975, Accuracy: 0.8429, Test Loss: 0.0609, Test Accuracy: 0.8528\n",
      "Epoch 30, Loss: 0.0956, Accuracy: 0.8429, Test Loss: 0.0606, Test Accuracy: 0.8481\n",
      "Epoch 31, Loss: 0.0961, Accuracy: 0.8446, Test Loss: 0.0594, Test Accuracy: 0.8505\n",
      "Epoch 32, Loss: 0.0957, Accuracy: 0.8394, Test Loss: 0.0591, Test Accuracy: 0.8458\n",
      "Epoch 33, Loss: 0.0898, Accuracy: 0.8522, Test Loss: 0.0702, Test Accuracy: 0.8294\n",
      "Epoch 34, Loss: 0.0932, Accuracy: 0.8429, Test Loss: 0.0548, Test Accuracy: 0.8551\n",
      "Epoch 35, Loss: 0.0936, Accuracy: 0.8435, Test Loss: 0.0581, Test Accuracy: 0.8481\n",
      "Epoch 36, Loss: 0.0921, Accuracy: 0.8440, Test Loss: 0.0619, Test Accuracy: 0.8388\n",
      "Epoch 37, Loss: 0.0906, Accuracy: 0.8481, Test Loss: 0.0511, Test Accuracy: 0.8645\n",
      "Epoch 38, Loss: 0.0866, Accuracy: 0.8505, Test Loss: 0.0555, Test Accuracy: 0.8575\n",
      "Epoch 39, Loss: 0.0887, Accuracy: 0.8440, Test Loss: 0.0632, Test Accuracy: 0.8435\n",
      "Epoch 40, Loss: 0.0885, Accuracy: 0.8487, Test Loss: 0.0589, Test Accuracy: 0.8551\n",
      "Epoch 41, Loss: 0.0869, Accuracy: 0.8452, Test Loss: 0.0602, Test Accuracy: 0.8458\n",
      "Epoch 42, Loss: 0.0857, Accuracy: 0.8475, Test Loss: 0.0538, Test Accuracy: 0.8598\n",
      "Epoch 43, Loss: 0.0889, Accuracy: 0.8382, Test Loss: 0.0560, Test Accuracy: 0.8551\n",
      "Epoch 44, Loss: 0.0846, Accuracy: 0.8528, Test Loss: 0.0553, Test Accuracy: 0.8621\n",
      "Epoch 45, Loss: 0.0857, Accuracy: 0.8417, Test Loss: 0.0515, Test Accuracy: 0.8575\n",
      "Epoch 46, Loss: 0.0842, Accuracy: 0.8435, Test Loss: 0.0595, Test Accuracy: 0.8388\n",
      "Epoch 47, Loss: 0.0848, Accuracy: 0.8481, Test Loss: 0.0546, Test Accuracy: 0.8598\n",
      "Epoch 48, Loss: 0.0810, Accuracy: 0.8528, Test Loss: 0.0597, Test Accuracy: 0.8551\n",
      "Epoch 49, Loss: 0.0836, Accuracy: 0.8516, Test Loss: 0.0558, Test Accuracy: 0.8598\n",
      "Epoch 50, Loss: 0.0862, Accuracy: 0.8475, Test Loss: 0.0519, Test Accuracy: 0.8598\n",
      "Epoch 51, Loss: 0.0849, Accuracy: 0.8452, Test Loss: 0.0588, Test Accuracy: 0.8551\n",
      "Epoch 52, Loss: 0.0846, Accuracy: 0.8481, Test Loss: 0.0606, Test Accuracy: 0.8481\n",
      "Epoch 53, Loss: 0.0846, Accuracy: 0.8452, Test Loss: 0.0547, Test Accuracy: 0.8528\n",
      "Epoch 54, Loss: 0.0808, Accuracy: 0.8557, Test Loss: 0.0548, Test Accuracy: 0.8458\n",
      "Epoch 55, Loss: 0.0837, Accuracy: 0.8464, Test Loss: 0.0561, Test Accuracy: 0.8598\n",
      "Epoch 56, Loss: 0.0820, Accuracy: 0.8528, Test Loss: 0.0565, Test Accuracy: 0.8551\n",
      "Epoch 57, Loss: 0.0831, Accuracy: 0.8481, Test Loss: 0.0571, Test Accuracy: 0.8598\n",
      "Epoch 58, Loss: 0.0827, Accuracy: 0.8499, Test Loss: 0.0556, Test Accuracy: 0.8551\n",
      "Epoch 59, Loss: 0.0870, Accuracy: 0.8446, Test Loss: 0.0573, Test Accuracy: 0.8551\n",
      "Epoch 60, Loss: 0.0838, Accuracy: 0.8493, Test Loss: 0.0625, Test Accuracy: 0.8551\n",
      "Epoch 61, Loss: 0.0799, Accuracy: 0.8546, Test Loss: 0.0541, Test Accuracy: 0.8575\n",
      "Epoch 62, Loss: 0.0803, Accuracy: 0.8511, Test Loss: 0.0542, Test Accuracy: 0.8551\n",
      "Epoch 63, Loss: 0.0801, Accuracy: 0.8505, Test Loss: 0.0523, Test Accuracy: 0.8621\n",
      "Epoch 64, Loss: 0.0789, Accuracy: 0.8534, Test Loss: 0.0497, Test Accuracy: 0.8621\n",
      "Epoch 65, Loss: 0.0800, Accuracy: 0.8493, Test Loss: 0.0526, Test Accuracy: 0.8621\n",
      "Epoch 66, Loss: 0.0790, Accuracy: 0.8522, Test Loss: 0.0532, Test Accuracy: 0.8551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:44:00,737] Trial 193 finished with value: 0.8644859813084113 and parameters: {'batch_size': 32, 'num_gcn_layers': 2, 'gcn_hidden_dim_0': 82, 'gcn_hidden_dim_1': 39, 'num_fc_layers': 2, 'fc_hidden_dim_0': 182, 'fc_hidden_dim_1': 58, 'learning_rate': 2.8327822062804715e-05, 'weight_decay': 1.786260748096182e-05, 'pooling_method': 'max', 'gcn_batch_norm_flag_0': True, 'gcn_batch_norm_flag_1': True, 'gcn_momentum_0': 0.1483045950375736, 'gcn_momentum_1': 0.9169908447900608, 'gcn_eps_0': 0.005792129640340792, 'gcn_eps_1': 0.0005985209768550378, 'gcn_dropout_flag_0': False, 'gcn_dropout_flag_1': False, 'gcn_activation_0': 'elu', 'gcn_activation_1': 'gelu', 'fc_batch_norm_flag_0': False, 'fc_batch_norm_flag_1': True, 'fc_momentum_1': 0.42620587070263527, 'fc_eps_1': 0.002959709787228699, 'fc_dropout_flag_0': False, 'fc_dropout_flag_1': True, 'fc_dropout_rate_1': 0.23350578734031988, 'fc_activation_0': 'relu', 'fc_activation_1': 'leaky_relu', 'gcn_skip_connections_0': False, 'gcn_skip_connections_1': True, 'l1_lambda': 0.00014865877312727083, 'optimizer': 'Adam', 'beta1': 0.92939511393381, 'beta2': 0.9989176798234944, 'lr_scheduler': 'OneCycleLR', 'max_lr_1': 0.0964527397607292, 'pct_start': 0.4999581595194821, 'loss_function': 'MultiMargin'}. Best is trial 33 with value: 0.8714953271028038.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67, Loss: 0.0797, Accuracy: 0.8534, Test Loss: 0.0609, Test Accuracy: 0.8528\n",
      "Early stopping triggered\n",
      "Epoch 1, Loss: 0.7269, Accuracy: 0.7255, Test Loss: 0.1038, Test Accuracy: 0.8061\n",
      "Epoch 2, Loss: 0.5331, Accuracy: 0.7903, Test Loss: 0.1031, Test Accuracy: 0.7804\n",
      "Epoch 3, Loss: 0.4269, Accuracy: 0.7991, Test Loss: 0.0943, Test Accuracy: 0.8084\n",
      "Epoch 4, Loss: 0.3534, Accuracy: 0.8002, Test Loss: 0.0977, Test Accuracy: 0.8061\n",
      "Epoch 5, Loss: 0.3070, Accuracy: 0.8014, Test Loss: 0.0881, Test Accuracy: 0.8084\n",
      "Epoch 6, Loss: 0.2689, Accuracy: 0.8014, Test Loss: 0.0872, Test Accuracy: 0.8131\n",
      "Epoch 7, Loss: 0.2410, Accuracy: 0.8072, Test Loss: 0.0909, Test Accuracy: 0.8131\n",
      "Epoch 8, Loss: 0.2171, Accuracy: 0.8084, Test Loss: 0.0806, Test Accuracy: 0.8154\n",
      "Epoch 9, Loss: 0.1986, Accuracy: 0.8119, Test Loss: 0.0779, Test Accuracy: 0.8178\n",
      "Epoch 10, Loss: 0.1848, Accuracy: 0.8178, Test Loss: 0.0734, Test Accuracy: 0.8178\n",
      "Epoch 11, Loss: 0.1733, Accuracy: 0.8242, Test Loss: 0.0666, Test Accuracy: 0.8248\n",
      "Epoch 12, Loss: 0.1609, Accuracy: 0.8341, Test Loss: 0.0797, Test Accuracy: 0.8364\n",
      "Epoch 13, Loss: 0.1601, Accuracy: 0.8242, Test Loss: 0.0728, Test Accuracy: 0.8201\n",
      "Epoch 14, Loss: 0.1522, Accuracy: 0.8294, Test Loss: 0.0722, Test Accuracy: 0.8271\n",
      "Epoch 15, Loss: 0.1396, Accuracy: 0.8394, Test Loss: 0.0595, Test Accuracy: 0.8528\n",
      "Epoch 16, Loss: 0.1437, Accuracy: 0.8294, Test Loss: 0.0652, Test Accuracy: 0.8341\n",
      "Epoch 17, Loss: 0.1395, Accuracy: 0.8318, Test Loss: 0.0573, Test Accuracy: 0.8505\n",
      "Epoch 18, Loss: 0.1291, Accuracy: 0.8370, Test Loss: 0.0584, Test Accuracy: 0.8575\n",
      "Epoch 19, Loss: 0.1229, Accuracy: 0.8429, Test Loss: 0.0590, Test Accuracy: 0.8528\n",
      "Epoch 20, Loss: 0.1172, Accuracy: 0.8452, Test Loss: 0.0655, Test Accuracy: 0.8411\n",
      "Epoch 21, Loss: 0.1166, Accuracy: 0.8423, Test Loss: 0.0599, Test Accuracy: 0.8621\n",
      "Epoch 22, Loss: 0.1118, Accuracy: 0.8470, Test Loss: 0.0597, Test Accuracy: 0.8435\n",
      "Epoch 23, Loss: 0.1087, Accuracy: 0.8499, Test Loss: 0.0669, Test Accuracy: 0.8411\n",
      "Epoch 24, Loss: 0.1094, Accuracy: 0.8458, Test Loss: 0.0572, Test Accuracy: 0.8621\n",
      "Epoch 25, Loss: 0.1072, Accuracy: 0.8435, Test Loss: 0.0568, Test Accuracy: 0.8575\n",
      "Epoch 26, Loss: 0.1036, Accuracy: 0.8458, Test Loss: 0.0600, Test Accuracy: 0.8621\n",
      "Epoch 27, Loss: 0.1022, Accuracy: 0.8481, Test Loss: 0.0531, Test Accuracy: 0.8621\n",
      "Epoch 28, Loss: 0.1037, Accuracy: 0.8417, Test Loss: 0.0572, Test Accuracy: 0.8505\n",
      "Epoch 29, Loss: 0.0980, Accuracy: 0.8487, Test Loss: 0.0628, Test Accuracy: 0.8575\n",
      "Epoch 30, Loss: 0.0973, Accuracy: 0.8505, Test Loss: 0.0623, Test Accuracy: 0.8505\n",
      "Epoch 31, Loss: 0.0952, Accuracy: 0.8452, Test Loss: 0.0570, Test Accuracy: 0.8505\n",
      "Epoch 32, Loss: 0.0978, Accuracy: 0.8470, Test Loss: 0.0548, Test Accuracy: 0.8598\n",
      "Epoch 33, Loss: 0.0964, Accuracy: 0.8493, Test Loss: 0.0616, Test Accuracy: 0.8458\n",
      "Epoch 34, Loss: 0.0949, Accuracy: 0.8481, Test Loss: 0.0567, Test Accuracy: 0.8575\n",
      "Epoch 35, Loss: 0.0924, Accuracy: 0.8452, Test Loss: 0.0543, Test Accuracy: 0.8598\n",
      "Epoch 36, Loss: 0.0965, Accuracy: 0.8458, Test Loss: 0.0521, Test Accuracy: 0.8621\n",
      "Epoch 37, Loss: 0.0909, Accuracy: 0.8470, Test Loss: 0.0590, Test Accuracy: 0.8528\n",
      "Epoch 38, Loss: 0.0893, Accuracy: 0.8493, Test Loss: 0.0555, Test Accuracy: 0.8645\n",
      "Epoch 39, Loss: 0.0928, Accuracy: 0.8481, Test Loss: 0.0572, Test Accuracy: 0.8575\n",
      "Epoch 40, Loss: 0.0927, Accuracy: 0.8487, Test Loss: 0.0552, Test Accuracy: 0.8528\n",
      "Epoch 41, Loss: 0.0909, Accuracy: 0.8470, Test Loss: 0.0578, Test Accuracy: 0.8575\n",
      "Epoch 42, Loss: 0.0900, Accuracy: 0.8505, Test Loss: 0.0609, Test Accuracy: 0.8481\n",
      "Epoch 43, Loss: 0.0935, Accuracy: 0.8446, Test Loss: 0.0594, Test Accuracy: 0.8505\n",
      "Epoch 44, Loss: 0.0911, Accuracy: 0.8452, Test Loss: 0.0624, Test Accuracy: 0.8645\n",
      "Epoch 45, Loss: 0.0893, Accuracy: 0.8481, Test Loss: 0.0538, Test Accuracy: 0.8575\n",
      "Epoch 46, Loss: 0.0863, Accuracy: 0.8534, Test Loss: 0.0535, Test Accuracy: 0.8551\n",
      "Epoch 47, Loss: 0.0893, Accuracy: 0.8440, Test Loss: 0.0610, Test Accuracy: 0.8481\n",
      "Epoch 48, Loss: 0.0910, Accuracy: 0.8400, Test Loss: 0.0597, Test Accuracy: 0.8481\n",
      "Epoch 49, Loss: 0.0863, Accuracy: 0.8487, Test Loss: 0.0502, Test Accuracy: 0.8645\n",
      "Epoch 50, Loss: 0.0846, Accuracy: 0.8505, Test Loss: 0.0572, Test Accuracy: 0.8551\n",
      "Epoch 51, Loss: 0.0897, Accuracy: 0.8499, Test Loss: 0.0674, Test Accuracy: 0.8388\n",
      "Epoch 52, Loss: 0.0889, Accuracy: 0.8522, Test Loss: 0.0514, Test Accuracy: 0.8621\n",
      "Epoch 53, Loss: 0.0871, Accuracy: 0.8475, Test Loss: 0.0515, Test Accuracy: 0.8598\n",
      "Epoch 54, Loss: 0.0885, Accuracy: 0.8487, Test Loss: 0.0513, Test Accuracy: 0.8621\n",
      "Epoch 55, Loss: 0.0868, Accuracy: 0.8505, Test Loss: 0.0539, Test Accuracy: 0.8621\n",
      "Epoch 56, Loss: 0.0885, Accuracy: 0.8505, Test Loss: 0.0633, Test Accuracy: 0.8435\n",
      "Epoch 57, Loss: 0.0871, Accuracy: 0.8516, Test Loss: 0.0531, Test Accuracy: 0.8598\n",
      "Epoch 58, Loss: 0.0875, Accuracy: 0.8499, Test Loss: 0.0523, Test Accuracy: 0.8551\n",
      "Epoch 59, Loss: 0.0887, Accuracy: 0.8475, Test Loss: 0.0552, Test Accuracy: 0.8621\n",
      "Epoch 60, Loss: 0.0873, Accuracy: 0.8493, Test Loss: 0.0681, Test Accuracy: 0.8388\n",
      "Epoch 61, Loss: 0.0849, Accuracy: 0.8528, Test Loss: 0.0555, Test Accuracy: 0.8645\n",
      "Epoch 62, Loss: 0.0830, Accuracy: 0.8557, Test Loss: 0.0561, Test Accuracy: 0.8575\n",
      "Epoch 63, Loss: 0.0858, Accuracy: 0.8540, Test Loss: 0.0697, Test Accuracy: 0.8388\n",
      "Epoch 64, Loss: 0.0879, Accuracy: 0.8470, Test Loss: 0.0550, Test Accuracy: 0.8505\n",
      "Epoch 65, Loss: 0.0892, Accuracy: 0.8435, Test Loss: 0.0558, Test Accuracy: 0.8575\n",
      "Epoch 66, Loss: 0.0847, Accuracy: 0.8516, Test Loss: 0.0566, Test Accuracy: 0.8528\n",
      "Epoch 67, Loss: 0.0870, Accuracy: 0.8446, Test Loss: 0.0513, Test Accuracy: 0.8551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:45:49,839] Trial 194 finished with value: 0.8644859813084113 and parameters: {'batch_size': 32, 'num_gcn_layers': 2, 'gcn_hidden_dim_0': 74, 'gcn_hidden_dim_1': 43, 'num_fc_layers': 2, 'fc_hidden_dim_0': 186, 'fc_hidden_dim_1': 205, 'learning_rate': 2.3047261472486506e-05, 'weight_decay': 6.486016138106549e-05, 'pooling_method': 'max', 'gcn_batch_norm_flag_0': True, 'gcn_batch_norm_flag_1': True, 'gcn_momentum_0': 0.0668908645431269, 'gcn_momentum_1': 0.263932440756391, 'gcn_eps_0': 0.007541616918143126, 'gcn_eps_1': 0.004816884944376266, 'gcn_dropout_flag_0': False, 'gcn_dropout_flag_1': False, 'gcn_activation_0': 'elu', 'gcn_activation_1': 'gelu', 'fc_batch_norm_flag_0': False, 'fc_batch_norm_flag_1': True, 'fc_momentum_1': 0.55831395138558, 'fc_eps_1': 0.0036193953339518584, 'fc_dropout_flag_0': False, 'fc_dropout_flag_1': True, 'fc_dropout_rate_1': 0.22000370393786753, 'fc_activation_0': 'relu', 'fc_activation_1': 'leaky_relu', 'gcn_skip_connections_0': False, 'gcn_skip_connections_1': True, 'l1_lambda': 0.00019085817812093748, 'optimizer': 'Adam', 'beta1': 0.9233772426735686, 'beta2': 0.9951632721987024, 'lr_scheduler': 'OneCycleLR', 'max_lr_1': 0.07546683638736826, 'pct_start': 0.1540597133772649, 'loss_function': 'MultiMargin'}. Best is trial 33 with value: 0.8714953271028038.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68, Loss: 0.0845, Accuracy: 0.8493, Test Loss: 0.0540, Test Accuracy: 0.8621\n",
      "Early stopping triggered\n",
      "Epoch 1, Loss: 0.8030, Accuracy: 0.7424, Test Loss: 0.1123, Test Accuracy: 0.8037\n",
      "Epoch 2, Loss: 0.6349, Accuracy: 0.7956, Test Loss: 0.0963, Test Accuracy: 0.8084\n",
      "Epoch 3, Loss: 0.5401, Accuracy: 0.8026, Test Loss: 0.1026, Test Accuracy: 0.7967\n",
      "Epoch 4, Loss: 0.4756, Accuracy: 0.7973, Test Loss: 0.0905, Test Accuracy: 0.8201\n",
      "Epoch 5, Loss: 0.4123, Accuracy: 0.8113, Test Loss: 0.0810, Test Accuracy: 0.8084\n",
      "Epoch 6, Loss: 0.3658, Accuracy: 0.8248, Test Loss: 0.0773, Test Accuracy: 0.8271\n",
      "Epoch 7, Loss: 0.3332, Accuracy: 0.8265, Test Loss: 0.0710, Test Accuracy: 0.8388\n",
      "Epoch 8, Loss: 0.2973, Accuracy: 0.8324, Test Loss: 0.0755, Test Accuracy: 0.8271\n",
      "Epoch 9, Loss: 0.2672, Accuracy: 0.8364, Test Loss: 0.1195, Test Accuracy: 0.7804\n",
      "Epoch 10, Loss: 0.2564, Accuracy: 0.8265, Test Loss: 0.0742, Test Accuracy: 0.8364\n",
      "Epoch 11, Loss: 0.2312, Accuracy: 0.8400, Test Loss: 0.0840, Test Accuracy: 0.8294\n",
      "Epoch 12, Loss: 0.2199, Accuracy: 0.8329, Test Loss: 0.0770, Test Accuracy: 0.8248\n",
      "Epoch 13, Loss: 0.2063, Accuracy: 0.8364, Test Loss: 0.0711, Test Accuracy: 0.8294\n",
      "Epoch 14, Loss: 0.1980, Accuracy: 0.8353, Test Loss: 0.0689, Test Accuracy: 0.8481\n",
      "Epoch 15, Loss: 0.1837, Accuracy: 0.8440, Test Loss: 0.0598, Test Accuracy: 0.8528\n",
      "Epoch 16, Loss: 0.1786, Accuracy: 0.8417, Test Loss: 0.0650, Test Accuracy: 0.8481\n",
      "Epoch 17, Loss: 0.1764, Accuracy: 0.8318, Test Loss: 0.0622, Test Accuracy: 0.8341\n",
      "Epoch 18, Loss: 0.1695, Accuracy: 0.8411, Test Loss: 0.0683, Test Accuracy: 0.8318\n",
      "Epoch 19, Loss: 0.1615, Accuracy: 0.8417, Test Loss: 0.0630, Test Accuracy: 0.8364\n",
      "Epoch 20, Loss: 0.1569, Accuracy: 0.8405, Test Loss: 0.0677, Test Accuracy: 0.8248\n",
      "Epoch 21, Loss: 0.1503, Accuracy: 0.8405, Test Loss: 0.0655, Test Accuracy: 0.8248\n",
      "Epoch 22, Loss: 0.1504, Accuracy: 0.8306, Test Loss: 0.0635, Test Accuracy: 0.8505\n",
      "Epoch 23, Loss: 0.1395, Accuracy: 0.8458, Test Loss: 0.0683, Test Accuracy: 0.8388\n",
      "Epoch 24, Loss: 0.1359, Accuracy: 0.8382, Test Loss: 0.0644, Test Accuracy: 0.8505\n",
      "Epoch 25, Loss: 0.1320, Accuracy: 0.8417, Test Loss: 0.0687, Test Accuracy: 0.8318\n",
      "Epoch 26, Loss: 0.1298, Accuracy: 0.8440, Test Loss: 0.0660, Test Accuracy: 0.8435\n",
      "Epoch 27, Loss: 0.1276, Accuracy: 0.8411, Test Loss: 0.0617, Test Accuracy: 0.8435\n",
      "Epoch 28, Loss: 0.1198, Accuracy: 0.8505, Test Loss: 0.0601, Test Accuracy: 0.8505\n",
      "Epoch 29, Loss: 0.1183, Accuracy: 0.8470, Test Loss: 0.0619, Test Accuracy: 0.8435\n",
      "Epoch 30, Loss: 0.1203, Accuracy: 0.8429, Test Loss: 0.0620, Test Accuracy: 0.8575\n",
      "Epoch 31, Loss: 0.1151, Accuracy: 0.8511, Test Loss: 0.0580, Test Accuracy: 0.8575\n",
      "Epoch 32, Loss: 0.1108, Accuracy: 0.8487, Test Loss: 0.0638, Test Accuracy: 0.8411\n",
      "Epoch 33, Loss: 0.1144, Accuracy: 0.8458, Test Loss: 0.0615, Test Accuracy: 0.8528\n",
      "Epoch 34, Loss: 0.1103, Accuracy: 0.8452, Test Loss: 0.0608, Test Accuracy: 0.8435\n",
      "Epoch 35, Loss: 0.1112, Accuracy: 0.8452, Test Loss: 0.0594, Test Accuracy: 0.8528\n",
      "Epoch 36, Loss: 0.1086, Accuracy: 0.8487, Test Loss: 0.0560, Test Accuracy: 0.8621\n",
      "Epoch 37, Loss: 0.1067, Accuracy: 0.8516, Test Loss: 0.0624, Test Accuracy: 0.8435\n",
      "Epoch 38, Loss: 0.1054, Accuracy: 0.8452, Test Loss: 0.0653, Test Accuracy: 0.8411\n",
      "Epoch 39, Loss: 0.1029, Accuracy: 0.8511, Test Loss: 0.0594, Test Accuracy: 0.8505\n",
      "Epoch 40, Loss: 0.1024, Accuracy: 0.8493, Test Loss: 0.0619, Test Accuracy: 0.8388\n",
      "Epoch 41, Loss: 0.1032, Accuracy: 0.8458, Test Loss: 0.0572, Test Accuracy: 0.8598\n",
      "Epoch 42, Loss: 0.1010, Accuracy: 0.8452, Test Loss: 0.0551, Test Accuracy: 0.8575\n",
      "Epoch 43, Loss: 0.0981, Accuracy: 0.8493, Test Loss: 0.0593, Test Accuracy: 0.8528\n",
      "Epoch 44, Loss: 0.0997, Accuracy: 0.8481, Test Loss: 0.0571, Test Accuracy: 0.8598\n",
      "Epoch 45, Loss: 0.0967, Accuracy: 0.8505, Test Loss: 0.0547, Test Accuracy: 0.8621\n",
      "Epoch 46, Loss: 0.0958, Accuracy: 0.8551, Test Loss: 0.0584, Test Accuracy: 0.8621\n",
      "Epoch 47, Loss: 0.0979, Accuracy: 0.8470, Test Loss: 0.0666, Test Accuracy: 0.8411\n",
      "Epoch 48, Loss: 0.0976, Accuracy: 0.8464, Test Loss: 0.0547, Test Accuracy: 0.8598\n",
      "Epoch 49, Loss: 0.0946, Accuracy: 0.8505, Test Loss: 0.0565, Test Accuracy: 0.8598\n",
      "Epoch 50, Loss: 0.0962, Accuracy: 0.8481, Test Loss: 0.0619, Test Accuracy: 0.8435\n",
      "Epoch 51, Loss: 0.0936, Accuracy: 0.8534, Test Loss: 0.0585, Test Accuracy: 0.8621\n",
      "Epoch 52, Loss: 0.0944, Accuracy: 0.8499, Test Loss: 0.0675, Test Accuracy: 0.8341\n",
      "Epoch 53, Loss: 0.0937, Accuracy: 0.8499, Test Loss: 0.0560, Test Accuracy: 0.8621\n",
      "Epoch 54, Loss: 0.0929, Accuracy: 0.8511, Test Loss: 0.0568, Test Accuracy: 0.8645\n",
      "Epoch 55, Loss: 0.0921, Accuracy: 0.8505, Test Loss: 0.0655, Test Accuracy: 0.8575\n",
      "Epoch 56, Loss: 0.0902, Accuracy: 0.8534, Test Loss: 0.0570, Test Accuracy: 0.8551\n",
      "Epoch 57, Loss: 0.0893, Accuracy: 0.8551, Test Loss: 0.0624, Test Accuracy: 0.8411\n",
      "Epoch 58, Loss: 0.0897, Accuracy: 0.8546, Test Loss: 0.0608, Test Accuracy: 0.8505\n",
      "Epoch 59, Loss: 0.0918, Accuracy: 0.8487, Test Loss: 0.0588, Test Accuracy: 0.8575\n",
      "Epoch 60, Loss: 0.0926, Accuracy: 0.8475, Test Loss: 0.0562, Test Accuracy: 0.8528\n",
      "Epoch 61, Loss: 0.0911, Accuracy: 0.8470, Test Loss: 0.0562, Test Accuracy: 0.8621\n",
      "Epoch 62, Loss: 0.0917, Accuracy: 0.8452, Test Loss: 0.0640, Test Accuracy: 0.8435\n",
      "Epoch 63, Loss: 0.0888, Accuracy: 0.8534, Test Loss: 0.0592, Test Accuracy: 0.8551\n",
      "Epoch 64, Loss: 0.0871, Accuracy: 0.8546, Test Loss: 0.0663, Test Accuracy: 0.8388\n",
      "Epoch 65, Loss: 0.0881, Accuracy: 0.8540, Test Loss: 0.0554, Test Accuracy: 0.8598\n",
      "Epoch 66, Loss: 0.0871, Accuracy: 0.8534, Test Loss: 0.0593, Test Accuracy: 0.8645\n",
      "Epoch 67, Loss: 0.0879, Accuracy: 0.8540, Test Loss: 0.0572, Test Accuracy: 0.8668\n",
      "Epoch 68, Loss: 0.0862, Accuracy: 0.8557, Test Loss: 0.0594, Test Accuracy: 0.8575\n",
      "Epoch 69, Loss: 0.0856, Accuracy: 0.8528, Test Loss: 0.0556, Test Accuracy: 0.8598\n",
      "Epoch 70, Loss: 0.0850, Accuracy: 0.8551, Test Loss: 0.0579, Test Accuracy: 0.8621\n",
      "Epoch 71, Loss: 0.0854, Accuracy: 0.8522, Test Loss: 0.0548, Test Accuracy: 0.8645\n",
      "Epoch 72, Loss: 0.0855, Accuracy: 0.8534, Test Loss: 0.0628, Test Accuracy: 0.8551\n",
      "Epoch 73, Loss: 0.0888, Accuracy: 0.8499, Test Loss: 0.0666, Test Accuracy: 0.8411\n",
      "Epoch 74, Loss: 0.0881, Accuracy: 0.8481, Test Loss: 0.0591, Test Accuracy: 0.8528\n",
      "Epoch 75, Loss: 0.0849, Accuracy: 0.8551, Test Loss: 0.0585, Test Accuracy: 0.8645\n",
      "Epoch 76, Loss: 0.0846, Accuracy: 0.8516, Test Loss: 0.0582, Test Accuracy: 0.8645\n",
      "Epoch 77, Loss: 0.0842, Accuracy: 0.8528, Test Loss: 0.0542, Test Accuracy: 0.8621\n",
      "Epoch 78, Loss: 0.0846, Accuracy: 0.8528, Test Loss: 0.0590, Test Accuracy: 0.8551\n",
      "Epoch 79, Loss: 0.0844, Accuracy: 0.8551, Test Loss: 0.0586, Test Accuracy: 0.8575\n",
      "Epoch 80, Loss: 0.0845, Accuracy: 0.8505, Test Loss: 0.0578, Test Accuracy: 0.8551\n",
      "Epoch 81, Loss: 0.0849, Accuracy: 0.8511, Test Loss: 0.0616, Test Accuracy: 0.8551\n",
      "Epoch 82, Loss: 0.0853, Accuracy: 0.8499, Test Loss: 0.0543, Test Accuracy: 0.8575\n",
      "Epoch 83, Loss: 0.0835, Accuracy: 0.8528, Test Loss: 0.0555, Test Accuracy: 0.8528\n",
      "Epoch 84, Loss: 0.0861, Accuracy: 0.8470, Test Loss: 0.0624, Test Accuracy: 0.8575\n",
      "Epoch 85, Loss: 0.0831, Accuracy: 0.8528, Test Loss: 0.0549, Test Accuracy: 0.8528\n",
      "Epoch 86, Loss: 0.0852, Accuracy: 0.8516, Test Loss: 0.0625, Test Accuracy: 0.8621\n",
      "Epoch 87, Loss: 0.0816, Accuracy: 0.8546, Test Loss: 0.0600, Test Accuracy: 0.8551\n",
      "Epoch 88, Loss: 0.0835, Accuracy: 0.8546, Test Loss: 0.0560, Test Accuracy: 0.8621\n",
      "Epoch 89, Loss: 0.0829, Accuracy: 0.8546, Test Loss: 0.0610, Test Accuracy: 0.8575\n",
      "Epoch 90, Loss: 0.0841, Accuracy: 0.8528, Test Loss: 0.0570, Test Accuracy: 0.8645\n",
      "Epoch 91, Loss: 0.0833, Accuracy: 0.8551, Test Loss: 0.0542, Test Accuracy: 0.8621\n",
      "Epoch 92, Loss: 0.0810, Accuracy: 0.8546, Test Loss: 0.0563, Test Accuracy: 0.8668\n",
      "Epoch 93, Loss: 0.0821, Accuracy: 0.8546, Test Loss: 0.0532, Test Accuracy: 0.8668\n",
      "Epoch 94, Loss: 0.0841, Accuracy: 0.8540, Test Loss: 0.0548, Test Accuracy: 0.8645\n",
      "Epoch 95, Loss: 0.0817, Accuracy: 0.8540, Test Loss: 0.0724, Test Accuracy: 0.8364\n",
      "Epoch 96, Loss: 0.0844, Accuracy: 0.8516, Test Loss: 0.0627, Test Accuracy: 0.8364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:48:39,654] Trial 195 finished with value: 0.866822429906542 and parameters: {'batch_size': 32, 'num_gcn_layers': 2, 'gcn_hidden_dim_0': 117, 'gcn_hidden_dim_1': 48, 'num_fc_layers': 2, 'fc_hidden_dim_0': 195, 'fc_hidden_dim_1': 243, 'learning_rate': 3.7779787400192844e-05, 'weight_decay': 7.953551162301608e-05, 'pooling_method': 'max', 'gcn_batch_norm_flag_0': True, 'gcn_batch_norm_flag_1': True, 'gcn_momentum_0': 0.2424124731127509, 'gcn_momentum_1': 0.06689571926156047, 'gcn_eps_0': 0.00673471991082727, 'gcn_eps_1': 0.009245149348804159, 'gcn_dropout_flag_0': False, 'gcn_dropout_flag_1': False, 'gcn_activation_0': 'elu', 'gcn_activation_1': 'relu', 'fc_batch_norm_flag_0': False, 'fc_batch_norm_flag_1': True, 'fc_momentum_1': 0.46552124659656896, 'fc_eps_1': 0.0030269351389893245, 'fc_dropout_flag_0': False, 'fc_dropout_flag_1': True, 'fc_dropout_rate_1': 0.19127545035905127, 'fc_activation_0': 'relu', 'fc_activation_1': 'gelu', 'gcn_skip_connections_0': False, 'gcn_skip_connections_1': True, 'l1_lambda': 0.00017642562761661392, 'optimizer': 'Adam', 'beta1': 0.925270758239455, 'beta2': 0.9909393126319149, 'lr_scheduler': 'OneCycleLR', 'max_lr_1': 0.03637394015010417, 'pct_start': 0.1787859334889304, 'loss_function': 'MultiMargin'}. Best is trial 33 with value: 0.8714953271028038.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97, Loss: 0.0821, Accuracy: 0.8534, Test Loss: 0.0532, Test Accuracy: 0.8575\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:48:41,870] Trial 196 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.3536, Accuracy: 0.7161, Test Loss: 0.1241, Test Accuracy: 0.7734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:48:43,119] Trial 197 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.4811, Accuracy: 0.7167, Test Loss: 6.0010, Test Accuracy: 0.2150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:48:43,803] Trial 198 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.4143, Accuracy: 0.5619, Test Loss: 0.3322, Test Accuracy: 0.6355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-08 14:48:45,992] Trial 199 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.9340, Accuracy: 0.3201, Test Loss: 0.4551, Test Accuracy: 0.5818\n",
      "Best Hyperparameters: {'batch_size': 64, 'num_gcn_layers': 4, 'gcn_hidden_dim_0': 75, 'gcn_hidden_dim_1': 38, 'gcn_hidden_dim_2': 203, 'gcn_hidden_dim_3': 216, 'num_fc_layers': 2, 'fc_hidden_dim_0': 195, 'fc_hidden_dim_1': 211, 'learning_rate': 3.906092533355772e-05, 'weight_decay': 0.0008383274514321103, 'pooling_method': 'max', 'gcn_batch_norm_flag_0': True, 'gcn_batch_norm_flag_1': True, 'gcn_batch_norm_flag_2': False, 'gcn_batch_norm_flag_3': True, 'gcn_momentum_0': 0.8217968152253406, 'gcn_momentum_1': 0.8370398653730386, 'gcn_momentum_3': 0.7815973993240434, 'gcn_eps_0': 0.0056463681340145795, 'gcn_eps_1': 0.001529708689395466, 'gcn_eps_3': 0.007629669710253976, 'gcn_dropout_flag_0': True, 'gcn_dropout_flag_1': False, 'gcn_dropout_flag_2': False, 'gcn_dropout_flag_3': False, 'gcn_dropout_rate_0': 0.1958699153219181, 'gcn_activation_0': 'softplus', 'gcn_activation_1': 'gelu', 'gcn_activation_2': 'gelu', 'gcn_activation_3': 'elu', 'fc_batch_norm_flag_0': False, 'fc_batch_norm_flag_1': True, 'fc_momentum_1': 0.7312571225456058, 'fc_eps_1': 0.002633219222852208, 'fc_dropout_flag_0': False, 'fc_dropout_flag_1': True, 'fc_dropout_rate_1': 0.22646533440385175, 'fc_activation_0': 'relu', 'fc_activation_1': 'tanh', 'gcn_skip_connections_0': True, 'gcn_skip_connections_1': True, 'gcn_skip_connections_2': False, 'gcn_skip_connections_3': True, 'l1_lambda': 0.00014847614815074084, 'optimizer': 'Adam', 'beta1': 0.8847832072232581, 'beta2': 0.9765193026440564, 'lr_scheduler': 'OneCycleLR', 'max_lr_1': 0.07913189464182088, 'pct_start': 0.35947256384374804, 'loss_function': 'CrossEntropy'}\n",
      "Best test accuracy:  0.8714953271028038\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "#study.optimize(objective, n_trials=80)\n",
    "study.optimize(lambda trial: objective(trial, model_save_folder, \n",
    "                                       train_dataset, test_dataset, \n",
    "                                       num_comb_features,\n",
    "                                       output_dim, \n",
    "                                       patience, epochs, device), n_trials=200)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", study.best_params)\n",
    "print(\"Best test accuracy: \", study.best_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb61dc0e-7ce4-4f5f-bea9-b61085700cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = best_trial_path(study, model_save_folder)\n",
    "\n",
    "best_model_save_path =  f\"{model_save_path[:model_save_path.rfind('/')]}/best_model_{model_save_path[model_save_path.rfind('/')+1:]}\"\n",
    "# Copy the file and \n",
    "shutil.copy(model_save_path, best_model_save_path)\n",
    "\n",
    "best_model, optimizer, criterion, batch_size, l1_lambda, start_epoch, best_accuracy, best_loss, best_std_dev = load_model(GCNModel, model_save_path, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70913d86-6dbb-4a35-b643-01482b572b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch from best model:116\n",
      "Epoch 1, Train Loss: 0.4555, Train Accuracy: 0.8423, Test Loss: 0.3502, Test Accuracy: 0.8575\n",
      "Epoch 2, Train Loss: 0.4590, Train Accuracy: 0.8440, Test Loss: 0.3565, Test Accuracy: 0.8621\n",
      "Epoch 3, Train Loss: 0.4564, Train Accuracy: 0.8440, Test Loss: 0.3542, Test Accuracy: 0.8621\n",
      "Epoch 4, Train Loss: 0.4624, Train Accuracy: 0.8423, Test Loss: 0.3482, Test Accuracy: 0.8575\n",
      "Epoch 5, Train Loss: 0.4579, Train Accuracy: 0.8511, Test Loss: 0.3636, Test Accuracy: 0.8598\n",
      "Epoch 6, Train Loss: 0.4573, Train Accuracy: 0.8511, Test Loss: 0.3631, Test Accuracy: 0.8505\n",
      "Epoch 7, Train Loss: 0.4559, Train Accuracy: 0.8417, Test Loss: 0.3434, Test Accuracy: 0.8598\n",
      "Epoch 8, Train Loss: 0.4432, Train Accuracy: 0.8511, Test Loss: 0.3374, Test Accuracy: 0.8715\n",
      "Epoch 9, Train Loss: 0.4389, Train Accuracy: 0.8522, Test Loss: 0.3431, Test Accuracy: 0.8645\n",
      "Epoch 10, Train Loss: 0.4477, Train Accuracy: 0.8528, Test Loss: 0.3546, Test Accuracy: 0.8621\n",
      "Epoch 11, Train Loss: 0.4600, Train Accuracy: 0.8440, Test Loss: 0.3476, Test Accuracy: 0.8621\n",
      "Epoch 12, Train Loss: 0.4420, Train Accuracy: 0.8458, Test Loss: 0.3552, Test Accuracy: 0.8621\n",
      "Epoch 13, Train Loss: 0.4400, Train Accuracy: 0.8563, Test Loss: 0.3517, Test Accuracy: 0.8598\n",
      "Epoch 14, Train Loss: 0.4615, Train Accuracy: 0.8400, Test Loss: 0.3629, Test Accuracy: 0.8528\n",
      "Epoch 15, Train Loss: 0.4558, Train Accuracy: 0.8452, Test Loss: 0.3530, Test Accuracy: 0.8598\n",
      "Epoch 16, Train Loss: 0.4518, Train Accuracy: 0.8475, Test Loss: 0.3355, Test Accuracy: 0.8645\n",
      "Epoch 17, Train Loss: 0.4671, Train Accuracy: 0.8440, Test Loss: 0.3542, Test Accuracy: 0.8645\n",
      "Epoch 18, Train Loss: 0.4463, Train Accuracy: 0.8493, Test Loss: 0.3730, Test Accuracy: 0.8435\n",
      "Epoch 19, Train Loss: 0.4515, Train Accuracy: 0.8493, Test Loss: 0.3308, Test Accuracy: 0.8598\n",
      "Epoch 20, Train Loss: 0.4512, Train Accuracy: 0.8464, Test Loss: 0.3585, Test Accuracy: 0.8551\n",
      "Epoch 21, Train Loss: 0.4546, Train Accuracy: 0.8475, Test Loss: 0.3638, Test Accuracy: 0.8551\n",
      "Epoch 22, Train Loss: 0.4643, Train Accuracy: 0.8458, Test Loss: 0.3480, Test Accuracy: 0.8575\n",
      "Epoch 23, Train Loss: 0.4627, Train Accuracy: 0.8435, Test Loss: 0.3773, Test Accuracy: 0.8505\n",
      "Epoch 24, Train Loss: 0.4586, Train Accuracy: 0.8493, Test Loss: 0.3332, Test Accuracy: 0.8692\n",
      "Epoch 25, Train Loss: 0.4490, Train Accuracy: 0.8505, Test Loss: 0.3506, Test Accuracy: 0.8645\n",
      "Epoch 26, Train Loss: 0.4517, Train Accuracy: 0.8481, Test Loss: 0.3394, Test Accuracy: 0.8668\n",
      "Epoch 27, Train Loss: 0.4465, Train Accuracy: 0.8481, Test Loss: 0.3418, Test Accuracy: 0.8551\n",
      "Epoch 28, Train Loss: 0.4422, Train Accuracy: 0.8534, Test Loss: 0.3356, Test Accuracy: 0.8715\n",
      "Epoch 29, Train Loss: 0.4473, Train Accuracy: 0.8493, Test Loss: 0.4273, Test Accuracy: 0.8318\n",
      "Epoch 30, Train Loss: 0.4472, Train Accuracy: 0.8546, Test Loss: 0.3311, Test Accuracy: 0.8645\n",
      "Epoch 31, Train Loss: 0.4440, Train Accuracy: 0.8499, Test Loss: 0.3443, Test Accuracy: 0.8668\n",
      "Epoch 32, Train Loss: 0.4449, Train Accuracy: 0.8446, Test Loss: 0.3632, Test Accuracy: 0.8551\n",
      "Epoch 33, Train Loss: 0.4477, Train Accuracy: 0.8481, Test Loss: 0.3518, Test Accuracy: 0.8621\n",
      "Epoch 34, Train Loss: 0.4394, Train Accuracy: 0.8575, Test Loss: 0.3275, Test Accuracy: 0.8668\n",
      "Epoch 35, Train Loss: 0.4329, Train Accuracy: 0.8493, Test Loss: 0.3309, Test Accuracy: 0.8621\n",
      "Epoch 36, Train Loss: 0.4480, Train Accuracy: 0.8522, Test Loss: 0.4271, Test Accuracy: 0.8388\n",
      "Epoch 37, Train Loss: 0.4375, Train Accuracy: 0.8569, Test Loss: 0.3493, Test Accuracy: 0.8668\n",
      "Epoch 38, Train Loss: 0.4428, Train Accuracy: 0.8475, Test Loss: 0.3529, Test Accuracy: 0.8575\n",
      "Epoch 39, Train Loss: 0.4500, Train Accuracy: 0.8464, Test Loss: 0.3534, Test Accuracy: 0.8621\n",
      "Epoch 40, Train Loss: 0.4509, Train Accuracy: 0.8452, Test Loss: 0.3822, Test Accuracy: 0.8621\n",
      "Epoch 41, Train Loss: 0.4434, Train Accuracy: 0.8522, Test Loss: 0.3714, Test Accuracy: 0.8505\n",
      "Epoch 42, Train Loss: 0.4414, Train Accuracy: 0.8446, Test Loss: 0.3667, Test Accuracy: 0.8668\n",
      "Epoch 43, Train Loss: 0.4502, Train Accuracy: 0.8493, Test Loss: 0.3360, Test Accuracy: 0.8551\n",
      "Epoch 44, Train Loss: 0.4550, Train Accuracy: 0.8440, Test Loss: 0.3422, Test Accuracy: 0.8692\n",
      "Epoch 45, Train Loss: 0.4534, Train Accuracy: 0.8452, Test Loss: 0.3541, Test Accuracy: 0.8621\n",
      "Epoch 46, Train Loss: 0.4478, Train Accuracy: 0.8505, Test Loss: 0.3351, Test Accuracy: 0.8645\n",
      "Epoch 47, Train Loss: 0.4523, Train Accuracy: 0.8511, Test Loss: 0.3741, Test Accuracy: 0.8551\n",
      "Epoch 48, Train Loss: 0.4400, Train Accuracy: 0.8487, Test Loss: 0.3382, Test Accuracy: 0.8645\n",
      "Epoch 49, Train Loss: 0.4409, Train Accuracy: 0.8540, Test Loss: 0.3449, Test Accuracy: 0.8621\n",
      "Epoch 50, Train Loss: 0.4391, Train Accuracy: 0.8511, Test Loss: 0.3425, Test Accuracy: 0.8621\n",
      "Epoch 51, Train Loss: 0.4346, Train Accuracy: 0.8546, Test Loss: 0.3582, Test Accuracy: 0.8598\n",
      "Epoch 52, Train Loss: 0.4309, Train Accuracy: 0.8499, Test Loss: 0.3266, Test Accuracy: 0.8668\n",
      "Epoch 53, Train Loss: 0.4314, Train Accuracy: 0.8557, Test Loss: 0.3864, Test Accuracy: 0.8528\n",
      "Epoch 54, Train Loss: 0.4343, Train Accuracy: 0.8464, Test Loss: 0.4297, Test Accuracy: 0.8201\n",
      "Epoch 55, Train Loss: 0.4388, Train Accuracy: 0.8569, Test Loss: 0.3568, Test Accuracy: 0.8598\n",
      "Epoch 56, Train Loss: 0.4405, Train Accuracy: 0.8528, Test Loss: 0.3535, Test Accuracy: 0.8645\n",
      "Epoch 57, Train Loss: 0.4512, Train Accuracy: 0.8487, Test Loss: 0.3446, Test Accuracy: 0.8645\n",
      "Epoch 58, Train Loss: 0.4388, Train Accuracy: 0.8522, Test Loss: 0.3671, Test Accuracy: 0.8528\n",
      "Epoch 59, Train Loss: 0.4412, Train Accuracy: 0.8487, Test Loss: 0.3290, Test Accuracy: 0.8692\n",
      "Epoch 60, Train Loss: 0.4411, Train Accuracy: 0.8511, Test Loss: 0.3499, Test Accuracy: 0.8551\n",
      "Epoch 61, Train Loss: 0.4363, Train Accuracy: 0.8522, Test Loss: 0.3638, Test Accuracy: 0.8551\n",
      "Epoch 62, Train Loss: 0.4448, Train Accuracy: 0.8464, Test Loss: 0.3352, Test Accuracy: 0.8692\n",
      "Epoch 63, Train Loss: 0.4331, Train Accuracy: 0.8481, Test Loss: 0.3527, Test Accuracy: 0.8598\n",
      "Epoch 64, Train Loss: 0.4348, Train Accuracy: 0.8493, Test Loss: 0.3459, Test Accuracy: 0.8598\n",
      "Epoch 65, Train Loss: 0.4331, Train Accuracy: 0.8546, Test Loss: 0.3344, Test Accuracy: 0.8668\n",
      "Epoch 66, Train Loss: 0.4434, Train Accuracy: 0.8493, Test Loss: 0.3840, Test Accuracy: 0.8481\n",
      "Epoch 67, Train Loss: 0.4534, Train Accuracy: 0.8499, Test Loss: 0.3675, Test Accuracy: 0.8505\n",
      "Epoch 68, Train Loss: 0.4412, Train Accuracy: 0.8475, Test Loss: 0.3948, Test Accuracy: 0.8435\n",
      "Epoch 69, Train Loss: 0.4407, Train Accuracy: 0.8505, Test Loss: 0.3432, Test Accuracy: 0.8621\n",
      "Epoch 70, Train Loss: 0.4457, Train Accuracy: 0.8475, Test Loss: 0.3496, Test Accuracy: 0.8598\n",
      "Epoch 71, Train Loss: 0.4418, Train Accuracy: 0.8475, Test Loss: 0.3435, Test Accuracy: 0.8551\n",
      "Epoch 72, Train Loss: 0.4361, Train Accuracy: 0.8534, Test Loss: 0.3713, Test Accuracy: 0.8505\n",
      "Epoch 73, Train Loss: 0.4411, Train Accuracy: 0.8569, Test Loss: 0.3447, Test Accuracy: 0.8598\n",
      "Epoch 74, Train Loss: 0.4278, Train Accuracy: 0.8551, Test Loss: 0.3279, Test Accuracy: 0.8645\n",
      "Epoch 75, Train Loss: 0.4241, Train Accuracy: 0.8487, Test Loss: 0.3423, Test Accuracy: 0.8551\n",
      "Epoch 76, Train Loss: 0.4337, Train Accuracy: 0.8534, Test Loss: 0.4035, Test Accuracy: 0.8458\n",
      "Epoch 77, Train Loss: 0.4391, Train Accuracy: 0.8475, Test Loss: 0.3748, Test Accuracy: 0.8411\n",
      "Epoch 78, Train Loss: 0.4394, Train Accuracy: 0.8475, Test Loss: 0.3426, Test Accuracy: 0.8645\n",
      "Epoch 79, Train Loss: 0.4371, Train Accuracy: 0.8505, Test Loss: 0.3354, Test Accuracy: 0.8575\n",
      "Epoch 80, Train Loss: 0.4456, Train Accuracy: 0.8516, Test Loss: 0.3985, Test Accuracy: 0.8458\n",
      "Epoch 81, Train Loss: 0.4649, Train Accuracy: 0.8481, Test Loss: 0.3956, Test Accuracy: 0.8435\n",
      "Epoch 82, Train Loss: 0.4545, Train Accuracy: 0.8499, Test Loss: 0.3682, Test Accuracy: 0.8505\n",
      "Epoch 83, Train Loss: 0.4393, Train Accuracy: 0.8499, Test Loss: 0.3642, Test Accuracy: 0.8551\n",
      "Epoch 84, Train Loss: 0.4363, Train Accuracy: 0.8516, Test Loss: 0.3920, Test Accuracy: 0.8458\n",
      "Epoch 85, Train Loss: 0.4311, Train Accuracy: 0.8528, Test Loss: 0.3428, Test Accuracy: 0.8621\n",
      "Epoch 86, Train Loss: 0.4406, Train Accuracy: 0.8511, Test Loss: 0.3573, Test Accuracy: 0.8551\n",
      "Epoch 87, Train Loss: 0.4373, Train Accuracy: 0.8452, Test Loss: 0.4549, Test Accuracy: 0.8388\n",
      "Epoch 88, Train Loss: 0.4396, Train Accuracy: 0.8563, Test Loss: 0.3560, Test Accuracy: 0.8598\n",
      "Epoch 89, Train Loss: 0.4423, Train Accuracy: 0.8522, Test Loss: 0.3768, Test Accuracy: 0.8435\n",
      "Epoch 90, Train Loss: 0.4335, Train Accuracy: 0.8534, Test Loss: 0.3726, Test Accuracy: 0.8528\n",
      "Epoch 91, Train Loss: 0.4379, Train Accuracy: 0.8487, Test Loss: 0.3755, Test Accuracy: 0.8575\n",
      "Epoch 92, Train Loss: 0.4411, Train Accuracy: 0.8499, Test Loss: 0.3368, Test Accuracy: 0.8668\n",
      "Epoch 93, Train Loss: 0.4321, Train Accuracy: 0.8505, Test Loss: 0.3722, Test Accuracy: 0.8528\n",
      "Epoch 94, Train Loss: 0.4266, Train Accuracy: 0.8546, Test Loss: 0.3729, Test Accuracy: 0.8528\n",
      "Epoch 95, Train Loss: 0.4368, Train Accuracy: 0.8546, Test Loss: 0.3887, Test Accuracy: 0.8458\n",
      "Epoch 96, Train Loss: 0.4261, Train Accuracy: 0.8592, Test Loss: 0.3692, Test Accuracy: 0.8551\n",
      "Epoch 97, Train Loss: 0.4192, Train Accuracy: 0.8487, Test Loss: 0.3316, Test Accuracy: 0.8668\n",
      "Epoch 98, Train Loss: 0.4230, Train Accuracy: 0.8522, Test Loss: 0.3492, Test Accuracy: 0.8528\n",
      "Epoch 99, Train Loss: 0.4258, Train Accuracy: 0.8540, Test Loss: 0.3566, Test Accuracy: 0.8575\n",
      "Epoch 100, Train Loss: 0.4232, Train Accuracy: 0.8511, Test Loss: 0.3344, Test Accuracy: 0.8621\n",
      "Epoch 101, Train Loss: 0.4272, Train Accuracy: 0.8522, Test Loss: 0.3318, Test Accuracy: 0.8621\n",
      "Epoch 102, Train Loss: 0.4216, Train Accuracy: 0.8546, Test Loss: 0.3584, Test Accuracy: 0.8621\n",
      "Epoch 103, Train Loss: 0.4357, Train Accuracy: 0.8475, Test Loss: 0.3712, Test Accuracy: 0.8271\n",
      "Epoch 104, Train Loss: 0.4475, Train Accuracy: 0.8464, Test Loss: 0.4163, Test Accuracy: 0.8388\n",
      "Epoch 105, Train Loss: 0.4300, Train Accuracy: 0.8563, Test Loss: 0.3890, Test Accuracy: 0.8435\n",
      "Epoch 106, Train Loss: 0.4406, Train Accuracy: 0.8540, Test Loss: 0.3339, Test Accuracy: 0.8645\n",
      "Epoch 107, Train Loss: 0.4226, Train Accuracy: 0.8528, Test Loss: 0.3400, Test Accuracy: 0.8668\n",
      "Epoch 108, Train Loss: 0.4115, Train Accuracy: 0.8516, Test Loss: 0.3500, Test Accuracy: 0.8621\n",
      "Epoch 109, Train Loss: 0.4259, Train Accuracy: 0.8592, Test Loss: 0.3446, Test Accuracy: 0.8621\n",
      "Epoch 110, Train Loss: 0.4280, Train Accuracy: 0.8499, Test Loss: 0.3405, Test Accuracy: 0.8598\n",
      "Epoch 111, Train Loss: 0.4257, Train Accuracy: 0.8551, Test Loss: 0.3318, Test Accuracy: 0.8598\n",
      "Epoch 112, Train Loss: 0.4147, Train Accuracy: 0.8598, Test Loss: 0.3738, Test Accuracy: 0.8435\n",
      "Epoch 113, Train Loss: 0.4237, Train Accuracy: 0.8546, Test Loss: 0.3854, Test Accuracy: 0.8575\n",
      "Epoch 114, Train Loss: 0.4287, Train Accuracy: 0.8522, Test Loss: 0.3457, Test Accuracy: 0.8598\n",
      "Epoch 115, Train Loss: 0.4326, Train Accuracy: 0.8470, Test Loss: 0.3521, Test Accuracy: 0.8551\n",
      "Epoch 116, Train Loss: 0.4538, Train Accuracy: 0.8429, Test Loss: 0.4102, Test Accuracy: 0.8388\n",
      "Epoch 117, Train Loss: 0.4415, Train Accuracy: 0.8511, Test Loss: 0.3406, Test Accuracy: 0.8575\n",
      "Epoch 118, Train Loss: 0.4316, Train Accuracy: 0.8581, Test Loss: 0.3640, Test Accuracy: 0.8551\n",
      "Epoch 119, Train Loss: 0.4217, Train Accuracy: 0.8569, Test Loss: 0.3375, Test Accuracy: 0.8715\n",
      "Epoch 120, Train Loss: 0.4271, Train Accuracy: 0.8540, Test Loss: 0.3436, Test Accuracy: 0.8645\n",
      "Epoch 121, Train Loss: 0.4176, Train Accuracy: 0.8522, Test Loss: 0.3809, Test Accuracy: 0.8481\n",
      "Epoch 122, Train Loss: 0.4270, Train Accuracy: 0.8522, Test Loss: 0.3660, Test Accuracy: 0.8551\n",
      "Epoch 123, Train Loss: 0.4317, Train Accuracy: 0.8505, Test Loss: 0.3587, Test Accuracy: 0.8575\n",
      "Epoch 124, Train Loss: 0.4410, Train Accuracy: 0.8516, Test Loss: 0.4224, Test Accuracy: 0.8411\n",
      "Epoch 125, Train Loss: 0.4472, Train Accuracy: 0.8493, Test Loss: 0.3486, Test Accuracy: 0.8481\n",
      "Epoch 126, Train Loss: 0.4450, Train Accuracy: 0.8475, Test Loss: 0.3694, Test Accuracy: 0.8435\n",
      "Epoch 127, Train Loss: 0.4343, Train Accuracy: 0.8569, Test Loss: 0.3992, Test Accuracy: 0.8505\n",
      "Epoch 128, Train Loss: 0.4251, Train Accuracy: 0.8522, Test Loss: 0.3908, Test Accuracy: 0.8435\n",
      "Epoch 129, Train Loss: 0.4381, Train Accuracy: 0.8452, Test Loss: 0.3687, Test Accuracy: 0.8481\n",
      "Epoch 130, Train Loss: 0.4222, Train Accuracy: 0.8505, Test Loss: 0.3454, Test Accuracy: 0.8645\n",
      "Epoch 131, Train Loss: 0.4311, Train Accuracy: 0.8516, Test Loss: 0.3701, Test Accuracy: 0.8505\n",
      "Epoch 132, Train Loss: 0.4334, Train Accuracy: 0.8569, Test Loss: 0.4094, Test Accuracy: 0.8458\n",
      "Epoch 133, Train Loss: 0.4327, Train Accuracy: 0.8464, Test Loss: 0.3506, Test Accuracy: 0.8575\n",
      "Epoch 134, Train Loss: 0.4309, Train Accuracy: 0.8511, Test Loss: 0.3502, Test Accuracy: 0.8598\n",
      "Epoch 135, Train Loss: 0.4280, Train Accuracy: 0.8592, Test Loss: 0.3779, Test Accuracy: 0.8505\n",
      "Epoch 136, Train Loss: 0.4166, Train Accuracy: 0.8592, Test Loss: 0.3784, Test Accuracy: 0.8551\n",
      "Epoch 137, Train Loss: 0.4189, Train Accuracy: 0.8528, Test Loss: 0.4056, Test Accuracy: 0.8411\n",
      "Epoch 138, Train Loss: 0.4267, Train Accuracy: 0.8534, Test Loss: 0.3386, Test Accuracy: 0.8575\n",
      "Epoch 139, Train Loss: 0.4438, Train Accuracy: 0.8470, Test Loss: 0.3460, Test Accuracy: 0.8598\n",
      "Epoch 140, Train Loss: 0.4198, Train Accuracy: 0.8581, Test Loss: 0.3850, Test Accuracy: 0.8505\n",
      "Epoch 141, Train Loss: 0.4312, Train Accuracy: 0.8540, Test Loss: 0.4449, Test Accuracy: 0.8341\n",
      "Epoch 142, Train Loss: 0.4409, Train Accuracy: 0.8493, Test Loss: 0.3787, Test Accuracy: 0.8505\n",
      "Epoch 143, Train Loss: 0.4306, Train Accuracy: 0.8528, Test Loss: 0.3616, Test Accuracy: 0.8505\n",
      "Epoch 144, Train Loss: 0.4343, Train Accuracy: 0.8499, Test Loss: 0.4029, Test Accuracy: 0.8481\n",
      "Epoch 145, Train Loss: 0.4504, Train Accuracy: 0.8452, Test Loss: 0.3349, Test Accuracy: 0.8645\n",
      "Epoch 146, Train Loss: 0.4622, Train Accuracy: 0.8440, Test Loss: 0.3535, Test Accuracy: 0.8505\n",
      "Epoch 147, Train Loss: 0.4460, Train Accuracy: 0.8499, Test Loss: 0.4121, Test Accuracy: 0.8341\n",
      "Epoch 148, Train Loss: 0.4456, Train Accuracy: 0.8557, Test Loss: 0.4168, Test Accuracy: 0.8458\n",
      "Epoch 149, Train Loss: 0.4359, Train Accuracy: 0.8452, Test Loss: 0.3350, Test Accuracy: 0.8621\n",
      "Epoch 150, Train Loss: 0.4385, Train Accuracy: 0.8575, Test Loss: 0.3486, Test Accuracy: 0.8621\n",
      "Epoch 151, Train Loss: 0.4351, Train Accuracy: 0.8487, Test Loss: 0.3875, Test Accuracy: 0.8505\n",
      "Epoch 152, Train Loss: 0.4158, Train Accuracy: 0.8551, Test Loss: 0.3533, Test Accuracy: 0.8528\n",
      "Epoch 153, Train Loss: 0.4279, Train Accuracy: 0.8546, Test Loss: 0.3363, Test Accuracy: 0.8645\n",
      "Epoch 154, Train Loss: 0.4284, Train Accuracy: 0.8528, Test Loss: 0.4208, Test Accuracy: 0.8411\n",
      "Epoch 155, Train Loss: 0.4475, Train Accuracy: 0.8440, Test Loss: 0.3985, Test Accuracy: 0.8435\n",
      "Epoch 156, Train Loss: 0.4489, Train Accuracy: 0.8499, Test Loss: 0.3621, Test Accuracy: 0.8575\n",
      "Epoch 157, Train Loss: 0.4481, Train Accuracy: 0.8516, Test Loss: 0.3713, Test Accuracy: 0.8505\n",
      "Epoch 158, Train Loss: 0.4360, Train Accuracy: 0.8604, Test Loss: 0.3812, Test Accuracy: 0.8528\n",
      "Epoch 159, Train Loss: 0.4319, Train Accuracy: 0.8511, Test Loss: 0.3364, Test Accuracy: 0.8621\n",
      "Epoch 160, Train Loss: 0.4259, Train Accuracy: 0.8499, Test Loss: 0.3603, Test Accuracy: 0.8528\n",
      "Epoch 161, Train Loss: 0.4335, Train Accuracy: 0.8493, Test Loss: 0.3851, Test Accuracy: 0.8528\n",
      "Epoch 162, Train Loss: 0.4231, Train Accuracy: 0.8516, Test Loss: 0.4218, Test Accuracy: 0.8435\n",
      "Epoch 163, Train Loss: 0.4154, Train Accuracy: 0.8581, Test Loss: 0.3491, Test Accuracy: 0.8575\n",
      "Epoch 164, Train Loss: 0.4360, Train Accuracy: 0.8470, Test Loss: 0.3463, Test Accuracy: 0.8598\n",
      "Epoch 165, Train Loss: 0.4222, Train Accuracy: 0.8551, Test Loss: 0.3472, Test Accuracy: 0.8575\n",
      "Epoch 166, Train Loss: 0.4173, Train Accuracy: 0.8546, Test Loss: 0.3683, Test Accuracy: 0.8528\n",
      "Epoch 167, Train Loss: 0.4235, Train Accuracy: 0.8528, Test Loss: 0.3387, Test Accuracy: 0.8621\n",
      "Epoch 168, Train Loss: 0.4070, Train Accuracy: 0.8592, Test Loss: 0.3521, Test Accuracy: 0.8575\n",
      "Epoch 169, Train Loss: 0.4327, Train Accuracy: 0.8569, Test Loss: 0.3966, Test Accuracy: 0.8481\n",
      "Epoch 170, Train Loss: 0.4335, Train Accuracy: 0.8470, Test Loss: 0.3691, Test Accuracy: 0.8598\n",
      "Epoch 171, Train Loss: 0.4473, Train Accuracy: 0.8464, Test Loss: 0.3422, Test Accuracy: 0.8598\n",
      "Epoch 172, Train Loss: 0.4205, Train Accuracy: 0.8522, Test Loss: 0.3465, Test Accuracy: 0.8621\n",
      "Epoch 173, Train Loss: 0.4267, Train Accuracy: 0.8528, Test Loss: 0.4047, Test Accuracy: 0.8435\n",
      "Epoch 174, Train Loss: 0.4226, Train Accuracy: 0.8516, Test Loss: 0.3697, Test Accuracy: 0.8551\n",
      "Epoch 175, Train Loss: 0.4123, Train Accuracy: 0.8546, Test Loss: 0.3242, Test Accuracy: 0.8668\n",
      "Epoch 176, Train Loss: 0.4158, Train Accuracy: 0.8511, Test Loss: 0.3377, Test Accuracy: 0.8645\n",
      "Epoch 177, Train Loss: 0.4336, Train Accuracy: 0.8516, Test Loss: 0.3304, Test Accuracy: 0.8668\n",
      "Epoch 178, Train Loss: 0.4409, Train Accuracy: 0.8446, Test Loss: 0.3912, Test Accuracy: 0.8411\n",
      "Epoch 179, Train Loss: 0.4261, Train Accuracy: 0.8563, Test Loss: 0.3422, Test Accuracy: 0.8528\n",
      "Epoch 180, Train Loss: 0.4284, Train Accuracy: 0.8511, Test Loss: 0.3840, Test Accuracy: 0.8481\n",
      "Epoch 181, Train Loss: 0.4311, Train Accuracy: 0.8487, Test Loss: 0.3412, Test Accuracy: 0.8645\n",
      "Epoch 182, Train Loss: 0.4195, Train Accuracy: 0.8540, Test Loss: 0.3478, Test Accuracy: 0.8575\n",
      "Epoch 183, Train Loss: 0.4223, Train Accuracy: 0.8505, Test Loss: 0.3313, Test Accuracy: 0.8645\n",
      "Epoch 184, Train Loss: 0.4337, Train Accuracy: 0.8487, Test Loss: 0.3573, Test Accuracy: 0.8598\n",
      "Epoch 185, Train Loss: 0.4263, Train Accuracy: 0.8540, Test Loss: 0.3511, Test Accuracy: 0.8645\n",
      "Epoch 186, Train Loss: 0.4309, Train Accuracy: 0.8528, Test Loss: 0.3592, Test Accuracy: 0.8505\n",
      "Epoch 187, Train Loss: 0.4250, Train Accuracy: 0.8505, Test Loss: 0.3357, Test Accuracy: 0.8692\n",
      "Epoch 188, Train Loss: 0.4309, Train Accuracy: 0.8446, Test Loss: 0.3777, Test Accuracy: 0.8481\n",
      "Epoch 189, Train Loss: 0.4238, Train Accuracy: 0.8458, Test Loss: 0.3371, Test Accuracy: 0.8621\n",
      "Epoch 190, Train Loss: 0.4119, Train Accuracy: 0.8569, Test Loss: 0.3279, Test Accuracy: 0.8668\n",
      "Epoch 191, Train Loss: 0.4202, Train Accuracy: 0.8481, Test Loss: 0.3673, Test Accuracy: 0.8575\n",
      "Epoch 192, Train Loss: 0.4381, Train Accuracy: 0.8446, Test Loss: 0.3610, Test Accuracy: 0.8575\n",
      "Epoch 193, Train Loss: 0.4111, Train Accuracy: 0.8569, Test Loss: 0.3617, Test Accuracy: 0.8528\n",
      "Epoch 194, Train Loss: 0.4406, Train Accuracy: 0.8487, Test Loss: 0.3792, Test Accuracy: 0.8528\n",
      "Epoch 195, Train Loss: 0.4302, Train Accuracy: 0.8516, Test Loss: 0.4029, Test Accuracy: 0.8458\n",
      "Epoch 196, Train Loss: 0.4461, Train Accuracy: 0.8440, Test Loss: 0.3355, Test Accuracy: 0.8621\n",
      "Epoch 197, Train Loss: 0.4332, Train Accuracy: 0.8511, Test Loss: 0.3507, Test Accuracy: 0.8575\n",
      "Epoch 198, Train Loss: 0.4264, Train Accuracy: 0.8487, Test Loss: 0.3774, Test Accuracy: 0.8551\n",
      "Epoch 199, Train Loss: 0.4191, Train Accuracy: 0.8575, Test Loss: 0.3648, Test Accuracy: 0.8551\n",
      "Epoch 200, Train Loss: 0.4191, Train Accuracy: 0.8569, Test Loss: 0.3377, Test Accuracy: 0.8575\n",
      "Epoch 201, Train Loss: 0.4216, Train Accuracy: 0.8499, Test Loss: 0.3722, Test Accuracy: 0.8551\n",
      "Epoch 202, Train Loss: 0.4298, Train Accuracy: 0.8546, Test Loss: 0.3869, Test Accuracy: 0.8551\n",
      "Epoch 203, Train Loss: 0.4128, Train Accuracy: 0.8557, Test Loss: 0.3258, Test Accuracy: 0.8692\n",
      "Epoch 204, Train Loss: 0.4145, Train Accuracy: 0.8569, Test Loss: 0.3492, Test Accuracy: 0.8598\n",
      "Epoch 205, Train Loss: 0.4171, Train Accuracy: 0.8551, Test Loss: 0.3805, Test Accuracy: 0.8505\n",
      "Epoch 206, Train Loss: 0.4124, Train Accuracy: 0.8569, Test Loss: 0.3685, Test Accuracy: 0.8481\n",
      "Epoch 207, Train Loss: 0.4180, Train Accuracy: 0.8528, Test Loss: 0.3900, Test Accuracy: 0.8481\n",
      "Epoch 208, Train Loss: 0.4349, Train Accuracy: 0.8475, Test Loss: 0.3896, Test Accuracy: 0.8435\n",
      "Epoch 209, Train Loss: 0.4180, Train Accuracy: 0.8505, Test Loss: 0.3331, Test Accuracy: 0.8645\n",
      "Epoch 210, Train Loss: 0.4282, Train Accuracy: 0.8435, Test Loss: 0.3749, Test Accuracy: 0.8598\n",
      "Epoch 211, Train Loss: 0.4395, Train Accuracy: 0.8481, Test Loss: 0.3675, Test Accuracy: 0.8411\n",
      "Epoch 212, Train Loss: 0.4379, Train Accuracy: 0.8487, Test Loss: 0.3296, Test Accuracy: 0.8692\n",
      "Epoch 213, Train Loss: 0.4187, Train Accuracy: 0.8516, Test Loss: 0.3331, Test Accuracy: 0.8692\n",
      "Epoch 214, Train Loss: 0.4261, Train Accuracy: 0.8475, Test Loss: 0.3341, Test Accuracy: 0.8738\n",
      "New best accuracy with continue training: 0.8738\n",
      "New best epoch with continue training: 214\n",
      "Epoch 215, Train Loss: 0.4217, Train Accuracy: 0.8499, Test Loss: 0.3528, Test Accuracy: 0.8598\n",
      "Epoch 216, Train Loss: 0.4135, Train Accuracy: 0.8534, Test Loss: 0.3362, Test Accuracy: 0.8598\n",
      "Epoch 217, Train Loss: 0.4117, Train Accuracy: 0.8563, Test Loss: 0.3958, Test Accuracy: 0.8551\n",
      "Epoch 218, Train Loss: 0.4075, Train Accuracy: 0.8581, Test Loss: 0.3596, Test Accuracy: 0.8505\n",
      "Epoch 219, Train Loss: 0.4271, Train Accuracy: 0.8475, Test Loss: 0.4230, Test Accuracy: 0.8411\n",
      "Epoch 220, Train Loss: 0.4232, Train Accuracy: 0.8546, Test Loss: 0.3715, Test Accuracy: 0.8528\n",
      "Epoch 221, Train Loss: 0.4143, Train Accuracy: 0.8534, Test Loss: 0.3484, Test Accuracy: 0.8598\n",
      "Epoch 222, Train Loss: 0.4298, Train Accuracy: 0.8522, Test Loss: 0.3483, Test Accuracy: 0.8621\n",
      "Epoch 223, Train Loss: 0.4425, Train Accuracy: 0.8487, Test Loss: 0.4002, Test Accuracy: 0.8481\n",
      "Epoch 224, Train Loss: 0.4296, Train Accuracy: 0.8557, Test Loss: 0.4239, Test Accuracy: 0.8341\n",
      "Epoch 225, Train Loss: 0.4274, Train Accuracy: 0.8516, Test Loss: 0.3520, Test Accuracy: 0.8575\n",
      "Epoch 226, Train Loss: 0.4252, Train Accuracy: 0.8540, Test Loss: 0.3374, Test Accuracy: 0.8621\n",
      "Epoch 227, Train Loss: 0.4241, Train Accuracy: 0.8534, Test Loss: 0.4196, Test Accuracy: 0.8458\n",
      "Epoch 228, Train Loss: 0.4209, Train Accuracy: 0.8557, Test Loss: 0.3525, Test Accuracy: 0.8621\n",
      "Epoch 229, Train Loss: 0.4099, Train Accuracy: 0.8563, Test Loss: 0.3690, Test Accuracy: 0.8551\n",
      "Epoch 230, Train Loss: 0.4187, Train Accuracy: 0.8528, Test Loss: 0.3743, Test Accuracy: 0.8481\n",
      "Epoch 231, Train Loss: 0.4268, Train Accuracy: 0.8505, Test Loss: 0.3650, Test Accuracy: 0.8528\n",
      "Epoch 232, Train Loss: 0.4426, Train Accuracy: 0.8487, Test Loss: 0.3450, Test Accuracy: 0.8645\n",
      "Epoch 233, Train Loss: 0.4361, Train Accuracy: 0.8505, Test Loss: 0.3348, Test Accuracy: 0.8692\n",
      "Epoch 234, Train Loss: 0.4306, Train Accuracy: 0.8475, Test Loss: 0.3711, Test Accuracy: 0.8551\n",
      "Epoch 235, Train Loss: 0.4191, Train Accuracy: 0.8592, Test Loss: 0.3949, Test Accuracy: 0.8435\n",
      "Epoch 236, Train Loss: 0.4108, Train Accuracy: 0.8516, Test Loss: 0.3559, Test Accuracy: 0.8575\n",
      "Epoch 237, Train Loss: 0.4165, Train Accuracy: 0.8551, Test Loss: 0.4370, Test Accuracy: 0.8364\n",
      "Epoch 238, Train Loss: 0.4062, Train Accuracy: 0.8627, Test Loss: 0.3823, Test Accuracy: 0.8528\n",
      "Epoch 239, Train Loss: 0.4030, Train Accuracy: 0.8645, Test Loss: 0.3323, Test Accuracy: 0.8645\n",
      "Epoch 240, Train Loss: 0.4032, Train Accuracy: 0.8633, Test Loss: 0.4224, Test Accuracy: 0.8458\n",
      "Epoch 241, Train Loss: 0.4274, Train Accuracy: 0.8534, Test Loss: 0.3820, Test Accuracy: 0.8528\n",
      "Epoch 242, Train Loss: 0.4152, Train Accuracy: 0.8557, Test Loss: 0.3466, Test Accuracy: 0.8621\n",
      "Epoch 243, Train Loss: 0.4193, Train Accuracy: 0.8551, Test Loss: 0.3665, Test Accuracy: 0.8411\n",
      "Epoch 244, Train Loss: 0.4119, Train Accuracy: 0.8511, Test Loss: 0.4043, Test Accuracy: 0.8411\n",
      "Epoch 245, Train Loss: 0.4095, Train Accuracy: 0.8551, Test Loss: 0.3566, Test Accuracy: 0.8621\n",
      "Epoch 246, Train Loss: 0.4085, Train Accuracy: 0.8516, Test Loss: 0.3951, Test Accuracy: 0.8528\n",
      "Epoch 247, Train Loss: 0.4242, Train Accuracy: 0.8505, Test Loss: 0.3469, Test Accuracy: 0.8645\n",
      "Epoch 248, Train Loss: 0.4110, Train Accuracy: 0.8581, Test Loss: 0.3649, Test Accuracy: 0.8528\n",
      "Epoch 249, Train Loss: 0.4108, Train Accuracy: 0.8616, Test Loss: 0.3679, Test Accuracy: 0.8551\n",
      "Epoch 250, Train Loss: 0.4207, Train Accuracy: 0.8516, Test Loss: 0.3487, Test Accuracy: 0.8598\n",
      "Epoch 251, Train Loss: 0.4125, Train Accuracy: 0.8581, Test Loss: 0.4020, Test Accuracy: 0.8458\n",
      "Epoch 252, Train Loss: 0.4171, Train Accuracy: 0.8563, Test Loss: 0.3597, Test Accuracy: 0.8621\n",
      "Epoch 253, Train Loss: 0.4258, Train Accuracy: 0.8551, Test Loss: 0.3340, Test Accuracy: 0.8668\n",
      "Epoch 254, Train Loss: 0.4249, Train Accuracy: 0.8493, Test Loss: 0.3297, Test Accuracy: 0.8668\n",
      "Epoch 255, Train Loss: 0.4243, Train Accuracy: 0.8534, Test Loss: 0.3365, Test Accuracy: 0.8715\n",
      "Epoch 256, Train Loss: 0.4127, Train Accuracy: 0.8569, Test Loss: 0.3387, Test Accuracy: 0.8692\n",
      "Epoch 257, Train Loss: 0.4129, Train Accuracy: 0.8522, Test Loss: 0.3361, Test Accuracy: 0.8621\n",
      "Epoch 258, Train Loss: 0.4112, Train Accuracy: 0.8586, Test Loss: 0.3700, Test Accuracy: 0.8598\n",
      "Epoch 259, Train Loss: 0.4171, Train Accuracy: 0.8592, Test Loss: 0.3786, Test Accuracy: 0.8598\n",
      "Epoch 260, Train Loss: 0.4316, Train Accuracy: 0.8481, Test Loss: 0.3668, Test Accuracy: 0.8551\n",
      "Epoch 261, Train Loss: 0.4345, Train Accuracy: 0.8499, Test Loss: 0.4467, Test Accuracy: 0.8411\n",
      "Epoch 262, Train Loss: 0.4277, Train Accuracy: 0.8557, Test Loss: 0.3453, Test Accuracy: 0.8645\n",
      "Epoch 263, Train Loss: 0.4222, Train Accuracy: 0.8522, Test Loss: 0.3491, Test Accuracy: 0.8621\n",
      "Epoch 264, Train Loss: 0.4202, Train Accuracy: 0.8481, Test Loss: 0.3534, Test Accuracy: 0.8528\n",
      "Epoch 265, Train Loss: 0.4118, Train Accuracy: 0.8551, Test Loss: 0.3843, Test Accuracy: 0.8528\n",
      "Epoch 266, Train Loss: 0.4075, Train Accuracy: 0.8557, Test Loss: 0.3230, Test Accuracy: 0.8738\n",
      "Epoch 267, Train Loss: 0.4202, Train Accuracy: 0.8551, Test Loss: 0.3434, Test Accuracy: 0.8668\n",
      "Epoch 268, Train Loss: 0.4245, Train Accuracy: 0.8464, Test Loss: 0.4077, Test Accuracy: 0.8481\n",
      "Epoch 269, Train Loss: 0.4316, Train Accuracy: 0.8534, Test Loss: 0.3957, Test Accuracy: 0.8458\n",
      "Epoch 270, Train Loss: 0.4307, Train Accuracy: 0.8528, Test Loss: 0.4066, Test Accuracy: 0.8458\n",
      "Epoch 271, Train Loss: 0.4275, Train Accuracy: 0.8505, Test Loss: 0.4499, Test Accuracy: 0.8411\n",
      "Epoch 272, Train Loss: 0.4257, Train Accuracy: 0.8481, Test Loss: 0.3488, Test Accuracy: 0.8575\n",
      "Epoch 273, Train Loss: 0.4252, Train Accuracy: 0.8528, Test Loss: 0.4440, Test Accuracy: 0.8248\n",
      "Epoch 274, Train Loss: 0.4218, Train Accuracy: 0.8505, Test Loss: 0.3278, Test Accuracy: 0.8645\n",
      "Epoch 275, Train Loss: 0.4244, Train Accuracy: 0.8540, Test Loss: 0.3881, Test Accuracy: 0.8528\n",
      "Epoch 276, Train Loss: 0.4327, Train Accuracy: 0.8546, Test Loss: 0.3483, Test Accuracy: 0.8598\n",
      "Epoch 277, Train Loss: 0.4253, Train Accuracy: 0.8540, Test Loss: 0.3632, Test Accuracy: 0.8458\n",
      "Epoch 278, Train Loss: 0.4178, Train Accuracy: 0.8581, Test Loss: 0.3606, Test Accuracy: 0.8598\n",
      "Epoch 279, Train Loss: 0.4105, Train Accuracy: 0.8534, Test Loss: 0.3300, Test Accuracy: 0.8668\n",
      "Epoch 280, Train Loss: 0.4195, Train Accuracy: 0.8551, Test Loss: 0.3595, Test Accuracy: 0.8528\n",
      "Epoch 281, Train Loss: 0.4115, Train Accuracy: 0.8575, Test Loss: 0.3544, Test Accuracy: 0.8551\n",
      "Epoch 282, Train Loss: 0.4054, Train Accuracy: 0.8557, Test Loss: 0.3438, Test Accuracy: 0.8621\n",
      "Epoch 283, Train Loss: 0.4098, Train Accuracy: 0.8540, Test Loss: 0.4118, Test Accuracy: 0.8411\n",
      "Epoch 284, Train Loss: 0.4150, Train Accuracy: 0.8505, Test Loss: 0.3818, Test Accuracy: 0.8575\n",
      "Epoch 285, Train Loss: 0.4218, Train Accuracy: 0.8551, Test Loss: 0.3770, Test Accuracy: 0.8505\n",
      "Epoch 286, Train Loss: 0.4189, Train Accuracy: 0.8487, Test Loss: 0.3914, Test Accuracy: 0.8528\n",
      "Epoch 287, Train Loss: 0.4274, Train Accuracy: 0.8528, Test Loss: 0.3493, Test Accuracy: 0.8598\n",
      "Epoch 288, Train Loss: 0.4221, Train Accuracy: 0.8563, Test Loss: 0.3562, Test Accuracy: 0.8621\n",
      "Epoch 289, Train Loss: 0.4141, Train Accuracy: 0.8540, Test Loss: 0.4479, Test Accuracy: 0.8318\n",
      "Epoch 290, Train Loss: 0.4177, Train Accuracy: 0.8516, Test Loss: 0.3991, Test Accuracy: 0.8458\n",
      "Epoch 291, Train Loss: 0.4066, Train Accuracy: 0.8581, Test Loss: 0.3252, Test Accuracy: 0.8692\n",
      "Epoch 292, Train Loss: 0.4163, Train Accuracy: 0.8522, Test Loss: 0.3508, Test Accuracy: 0.8551\n",
      "Epoch 293, Train Loss: 0.4087, Train Accuracy: 0.8551, Test Loss: 0.3921, Test Accuracy: 0.8458\n",
      "Epoch 294, Train Loss: 0.4223, Train Accuracy: 0.8540, Test Loss: 0.3802, Test Accuracy: 0.8575\n",
      "Epoch 295, Train Loss: 0.4152, Train Accuracy: 0.8592, Test Loss: 0.3732, Test Accuracy: 0.8575\n",
      "Epoch 296, Train Loss: 0.4147, Train Accuracy: 0.8522, Test Loss: 0.3565, Test Accuracy: 0.8575\n",
      "Epoch 297, Train Loss: 0.4140, Train Accuracy: 0.8522, Test Loss: 0.3577, Test Accuracy: 0.8575\n",
      "Epoch 298, Train Loss: 0.4079, Train Accuracy: 0.8546, Test Loss: 0.3497, Test Accuracy: 0.8645\n",
      "Epoch 299, Train Loss: 0.4095, Train Accuracy: 0.8586, Test Loss: 0.3684, Test Accuracy: 0.8621\n",
      "Epoch 300, Train Loss: 0.4053, Train Accuracy: 0.8557, Test Loss: 0.4077, Test Accuracy: 0.8528\n"
     ]
    }
   ],
   "source": [
    "# Create DataLoader with the loaded batch size\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Define the number of epochs if you want to continue training\n",
    "final_epochs = 300  # Set to 0 if you only want to evaluate\n",
    "\n",
    "history = {\n",
    "        'train_loss': [],\n",
    "        'train_accuracy': [],\n",
    "        'test_loss': [],\n",
    "        'test_accuracy': []\n",
    "    }\n",
    "print(f\"Best epoch from best model:{start_epoch+1}\")\n",
    "\n",
    "start_epoch = 0\n",
    "\n",
    "# Continue training from the last epoch if needed\n",
    "for epoch in range(start_epoch, start_epoch + final_epochs):\n",
    "    train_loss, train_accuracy = train(best_model, train_loader, optimizer, criterion, device, l1_lambda)\n",
    "    test_loss, test_accuracy = evaluate(best_model, test_loader, criterion, device)    \n",
    "    print(f'Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')\n",
    "    # Store in history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_accuracy'].append(train_accuracy)\n",
    "    history['test_loss'].append(test_loss)\n",
    "    history['test_accuracy'].append(test_accuracy)\n",
    "    # Optionally save the model if it improves\n",
    "    if test_accuracy > best_accuracy:\n",
    "        best_accuracy = test_accuracy\n",
    "        print(f\"New best accuracy with continue training: {best_accuracy:.4f}\")\n",
    "        print(f\"New best epoch with continue training: {epoch+1}\" )\n",
    "\n",
    "# Final Evaluation\n",
    "if final_epochs == 0:\n",
    "    test_loss, test_accuracy = evaluate(best_model, test_loader, criterion, device)\n",
    "    print(f\"Final Test Loss: {test_loss:.4f}, Final Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b73f7a0d-db54-46f7-9d20-0cdc24546888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(plot_training_history(history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "24a2d3d3-db59-458a-9815-2b1766523535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Size: 6\n",
      "Best batch size: 64\n",
      "Best epoch: 116\n",
      "Best accuracy: 0.8715\n",
      "Best loss: 0.3443\n",
      "Best loss std: 0.0505\n",
      "Best hyperparameters found were:\n",
      "Input Size: 37\n",
      "Number of GCN layers: 4\n",
      "  GCN Layer 1:\n",
      "    Units: 75\n",
      "    Skip Connections: True\n",
      "    Batch Norm Momentum: 0.8218\n",
      "    Batch Norm Epsilon: 0.0056\n",
      "    Activation: softplus\n",
      "    Dropout: 0.1959\n",
      "  GCN Layer 2:\n",
      "    Units: 38\n",
      "    Skip Connections: True\n",
      "    Batch Norm Momentum: 0.8370\n",
      "    Batch Norm Epsilon: 0.0015\n",
      "    Activation: gelu\n",
      "  GCN Layer 3:\n",
      "    Units: 203\n",
      "    Skip Connections: False\n",
      "    Activation: gelu\n",
      "  GCN Layer 4:\n",
      "    Units: 216\n",
      "    Skip Connections: True\n",
      "    Batch Norm Momentum: 0.7816\n",
      "    Batch Norm Epsilon: 0.0076\n",
      "    Activation: elu\n",
      "Pooling Method: max\n",
      "Number of Dense layers: 2\n",
      "  Dense Layer 1:\n",
      "    Units: 195\n",
      "    Activation: relu\n",
      "  Dense Layer 2:\n",
      "    Units: 211\n",
      "    Batch Norm Momentum: 0.7313\n",
      "    Batch Norm Epsilon: 0.0026\n",
      "    Activation: tanh\n",
      "    Dropout: 0.2265\n",
      "Optimizer: Adam\n",
      "  Learning Rate (Adam): 0.0038\n",
      "  Beta 1 (Adam): 0.8848\n",
      "  Beta 2 (Adam): 0.9765\n",
      "  Weight Decay(Adam): 0.0008\n",
      "Learning Rate Schedule: OneCycleLR\n",
      "  Max_lr: 0.0791\n",
      "  Total_steps: 5670\n",
      "  Pct_start: 0.3595\n",
      "Loss function: CrossEntropyLoss()\n",
      "l1 lambda: 0.0001\n"
     ]
    }
   ],
   "source": [
    "print_best_hp_gcn(\"GCNModel\", model_save_path, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f4506d66-25bf-4dc5-aeea-41ce5d2a6899",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def f1_eva(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            event_data, labels = batch\n",
    "            event_data = event_data.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            output = model(event_data)\n",
    "            loss = criterion(output, labels)\n",
    "            total_loss += loss.item() * labels.size(0)\n",
    "            \n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += pred.eq(labels).sum().item()\n",
    "            \n",
    "            all_preds.extend(pred.cpu().numpy())  # Store predictions\n",
    "            all_labels.extend(labels.cpu().numpy())  # Store true labels\n",
    "    \n",
    "    accuracy = correct / len(loader.dataset)\n",
    "    loss = total_loss / len(loader.dataset)\n",
    "    \n",
    "    return loss, accuracy, all_preds, all_labels\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b896f8d2-27f6-4730-a1f9-29644cc01e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Loss: 0.4077, Final Test Accuracy: 0.8528\n",
      "Confusion Matrix:\n",
      "[[ 92   0   0   0   0   0]\n",
      " [  0 166   0   0   8   0]\n",
      " [  0   0   5   0   0   0]\n",
      " [  0   0   1  20   0   0]\n",
      " [  0   0   0   0  32   0]\n",
      " [  0  43   0   1  10  50]]\n",
      "\n",
      "Classification Report (with F1 scores for each class):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        92\n",
      "           1       0.79      0.95      0.87       174\n",
      "           2       0.83      1.00      0.91         5\n",
      "           3       0.95      0.95      0.95        21\n",
      "           4       0.64      1.00      0.78        32\n",
      "           5       1.00      0.48      0.65       104\n",
      "\n",
      "    accuracy                           0.85       428\n",
      "   macro avg       0.87      0.90      0.86       428\n",
      "weighted avg       0.89      0.85      0.84       428\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation to get predictions and labels\n",
    "test_loss, test_accuracy, all_preds, all_labels = f1_eva(best_model, test_loader, criterion, device)\n",
    "\n",
    "# Print final evaluation metrics\n",
    "print(f\"Final Test Loss: {test_loss:.4f}, Final Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Generate confusion matrix and classification report (which includes F1 scores per class)\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "class_report = classification_report(all_labels, all_preds)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nClassification Report (with F1 scores for each class):\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebcaa32-a7c0-4ff5-9a03-733b6f1fc9a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
